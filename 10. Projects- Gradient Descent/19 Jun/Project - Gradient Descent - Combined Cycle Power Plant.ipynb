{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent - Combined Cycle Power Plant\n",
    "Combined Cycle Power Plant dataset contains 9568 data points collected from a Combined Cycle Power Plant over 6 years (2006-2011), when the power plant was set to work with full load. Features consist of hourly average ambient variables Temperature (T), Ambient Pressure (AP), Relative Humidity (RH) and Exhaust Vacuum (V) to predict the net hourly electrical energy output (EP) of the plant.\n",
    "You are given:\n",
    "    1. A Readme file for more details on dataset. \n",
    "    2. A Training dataset csv file with X train and Y train data\n",
    "    3. A X test File and you have to predict and submit predictions for this file.\n",
    "Your task is to:\n",
    "    1. Code Gradient Descent for N features and come with predictions.\n",
    "    2. Try and test with various combinations of learning rates and number of iterations.\n",
    "    3. Try using Feature Scaling, and see if it helps you in getting better results. \n",
    "Read Instructions carefully -\n",
    "    1. Use Gradient Descent as a training algorithm and submit results predicted.\n",
    "    2. Files are in csv format, you can use genfromtxt function in numpy to load data from csv file. Similarly you can use savetxt function to save data into a file.\n",
    "    3. Submit a csv file with only predictions for X test data. File should not have any headers and should only have one column i.e. predictions. Also predictions shouldn't be in exponential form.\n",
    "    4. Your score is based on coefficient of determination. So it can be possible that nobody gets full score.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 T            V           AP           RH           EP\n",
      "count  7176.000000  7176.000000  7176.000000  7176.000000  7176.000000\n",
      "mean     19.629712    54.288154  1013.263032    73.275818   454.431293\n",
      "std       7.475256    12.751468     5.964863    14.625093    17.134571\n",
      "min       1.810000    25.360000   992.890000    25.560000   420.260000\n",
      "25%      13.470000    41.740000  1009.010000    63.202500   439.737500\n",
      "50%      20.315000    52.050000  1012.910000    74.895000   451.740000\n",
      "75%      25.720000    66.540000  1017.302500    84.925000   468.667500\n",
      "max      35.770000    81.560000  1033.300000   100.160000   495.760000\n",
      "(7176, 4)\n",
      "(7176,)\n",
      "                0            1            2            3\n",
      "count  2392.00000  2392.000000  2392.000000  2392.000000\n",
      "mean     19.71579    54.358754  1013.247216    73.408457\n",
      "std       7.38488    12.578763     5.861068    14.528135\n",
      "min       3.38000    25.360000   993.740000    26.670000\n",
      "25%      13.66000    41.730000  1009.300000    63.615000\n",
      "50%      20.45000    52.750000  1013.025000    75.090000\n",
      "75%      25.67250    66.490000  1017.172500    84.497500\n",
      "max      37.11000    80.250000  1033.290000   100.130000\n",
      "(2392, 4)\n"
     ]
    }
   ],
   "source": [
    "# Loading Datasets\n",
    "\n",
    "train_dataset = np.genfromtxt(\"../training_ccpp_x_y_train.csv\", names = True, delimiter = \",\")\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "print(train_df.describe())\n",
    "num_cols = len(train_df.columns)\n",
    "X_train = train_df.values[:, 0: num_cols -1 ]\n",
    "Y_train = train_df.values[:, num_cols - 1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "\n",
    "test_dataset = np.genfromtxt(\"../test_ccpp_x_test.csv\", names = None, delimiter = \",\")\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "print(test_df.describe())\n",
    "num_cols = len(test_df.columns)\n",
    "X_test = test_df.values\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def single_step(X, Y, m, alpha):\n",
    "    n_1 = len(m)\n",
    "    num_eg = len(X)\n",
    "    slope_m = np.zeros(n_1) \n",
    "    \n",
    "    for j in range(n_1):\n",
    "        for i in range(num_eg) :\n",
    "            slope_m[j] += (-2/num_eg)* ((Y[i] - (m *(X[i])).sum() ) * X[i][j] )    \n",
    "    #for j in range(n_1):\n",
    "            m[j] -= alpha*slope_m[j]\n",
    "    return m\n",
    "\n",
    "def cost(X, Y, m):\n",
    "    cost = 0\n",
    "    num_eg = len(X)\n",
    "    for i in range(num_eg) :\n",
    "        cost += ((Y[i] - (m * X[i]).sum())**2 )/num_eg\n",
    "    return cost\n",
    "\n",
    "def gd(X, Y, alpha, num_iters):\n",
    "    num_eg = len(X)\n",
    "    X = np.c_[X, np.ones(X.shape[0])]\n",
    "    m = np.zeros(len(X[0]))\n",
    "    costs = {}\n",
    "    print(len(m))\n",
    "    for i in range(num_iters):\n",
    "        m = single_step(X, Y, m, alpha)\n",
    "        if i % 10 == 0 :\n",
    "            costs[i] = cost(X, Y, m)\n",
    "            print(i, \" \", costs[i])\n",
    "    import matplotlib.pyplot as plt\n",
    "    keys = [key for key in costs]\n",
    "    values = [costs[key] for key in costs]\n",
    "    plt.plot(keys, values)\n",
    "    plt.show()\n",
    "    return m\n",
    "\n",
    "def predict(X, m) :\n",
    "    X = np.c_[X, np.ones(X.shape[0])]\n",
    "    Y = np.array([])\n",
    "    for i in range(len(X)):\n",
    "        Y_i = (X[i] * m).sum()\n",
    "        Y = np.append(Y, Y_i)\n",
    "    return Y\n",
    "\n",
    "def scale_features(X_train) :\n",
    "    import copy\n",
    "    X = copy.deepcopy(X_train)\n",
    "    means = np.array([X[:, i].mean() for i in range(X.shape[1])])\n",
    "    stds = np.array([X[:, i].std() for i in range(X.shape[1])])\n",
    "    \n",
    "    for i in range(X.shape[0]) :\n",
    "        X[i, :] = (X[i, :] - means)/stds\n",
    "    return X\n",
    "def score(Y_true, Y_pred) :\n",
    "    mean = Y_true.mean()\n",
    "    u = ((Y_true - Y_pred)**2).sum()\n",
    "    v = ((Y_true - mean)**2).sum() \n",
    "    return 1 - (u/v)\n",
    "# Introduce more features\n",
    "def add_more_features (X_train, imp_cols_indices):\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    num_f = len(X_train_df.columns)\n",
    "    col_names = X_train_df.columns\n",
    "    new_df = X_train_df.copy()\n",
    "    num_imp_cols = len(imp_col_indices)\n",
    "    for i1 in range(num_imp_cols) :\n",
    "        for j1 in range(i1, num_imp_cols):\n",
    "            i = imp_cols_indices[i1]\n",
    "            j = imp_cols_indices[j1]\n",
    "            new_df[ str(col_names[i]) + \"_\" + str(col_names[j])] = X_train_df[i] * X_train_df[j]\n",
    "    print(new_df.describe())\n",
    "    return new_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "0   90591.80233102819\n",
      "10   46.77036812916915\n",
      "20   21.895014946021092\n",
      "30   21.335081104861604\n",
      "40   21.096249938308816\n",
      "50   20.993545477327483\n",
      "60   20.94954844158342\n",
      "70   20.930835051525754\n",
      "80   20.922967432544496\n",
      "90   20.919721623007565\n",
      "100   20.91842474531468\n",
      "110   20.917935844440983\n",
      "120   20.917772506605832\n",
      "130   20.917733857735275\n",
      "140   20.917738352447603\n",
      "150   20.917754328847824\n",
      "160   20.917770509939896\n",
      "170   20.91778362851404\n",
      "180   20.917793340138825\n",
      "190   20.917800203382715\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPQwHSVIPw0GS1MNwkCT1MBwkST3+Px4vFG3Whoo4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1d27e938e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.49020056e+01 -2.84263610e+00  3.58853572e-01 -2.38253498e+00\n",
      "  4.54458749e+02]\n",
      "Duration:  47.90234041213989 second\n"
     ]
    }
   ],
   "source": [
    "imp_col_indices = [0, 1, 2, 3]\n",
    "import time\n",
    "s_t = time.time()\n",
    "#X_train_new = add_more_features(X_train, imp_col_indices)\n",
    "X_train_scaled = scale_features(X_train)\n",
    "m = gd(X_train_scaled, Y_train, 0.00005, 200)\n",
    "print(m)\n",
    "e_t = time.time()\n",
    "print(\"Duration: \",e_t-s_t, \"second\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9287425715704402\n"
     ]
    }
   ],
   "source": [
    "#X_test_new = add_more_features(X_test, imp_col_indices)\n",
    "X_test_scaled = scale_features(X_test)\n",
    "Y_pred = predict(X_test_scaled, m)\n",
    "np.savetxt(\"ccpp_dataset_pred.csv\", Y_pred, '%.5f')\n",
    "print(score(Y_train, predict(X_train_scaled, m)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
