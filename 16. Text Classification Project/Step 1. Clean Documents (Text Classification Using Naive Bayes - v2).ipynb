{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using Naive Bayes\n",
    "### Your task is to:\n",
    "    1. Perform Test Classification using Multinomial Naive Bayes(already implemented in sklearn).\n",
    "    2. Implement Naive Bayes on your own from scratch for text classification. \n",
    "    3. Compare Results of your implementation of Naive Bayes with one in Sklearn.\n",
    "#### Dataset - \n",
    "    http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups\n",
    "#### Comments : \n",
    "    Your code must have proper comments for better understanding.\n",
    "#### Score : \n",
    "    Score will be given by the TA based on your submission.\n",
    "#### Submission : \n",
    "    You have to upload zipped file which has python notebook with implementation and dataset used.\n",
    "#### Your project will be evaluated on following parameters -\n",
    "    1. Correctness of Code - Own Implementation Naive Bayes (Max Score 50)\n",
    "    2. Comparison (Max Score 10)\n",
    "    3. Commenting (Max Score 10)\n",
    "    4. Correctness of Code - Sklearn Naive Bayes (Max Score 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xref:', 'Path:', 'From:', 'Newsgroups:', 'Subject:', 'FAQ:', 'Message-ID:', 'Date:', 'Expires:', 'Followup-To:', 'Distribution:', 'Organization:', 'Approved:', 'Supersedes:', 'Archive-name:', 'Alt-atheism-archive-name:', 'Last-modified:', 'Write to:', 'Summary:', 'Keywords:', 'Version:', 'Lines:', 'Telephone:', 'or:', 'Telephone:', 'Fax:']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "headers_list = []\n",
    "s = \"Xref: \\\n",
    "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!uunet!pipex!ibmpcug!mantis!mathew \\\n",
    "From: mathew <mathew@mantis.co.uk> \\\n",
    "Newsgroups: alt.atheism,alt.atheism.moderated,news.answers,alt.answers \\\n",
    "Subject: Alt.Atheism FAQ: Atheist Resources \\\n",
    "Message-ID: <19930329115719@mantis.co.uk> \\\n",
    "Date: Mon, 29 Mar 1993  GMT \\\n",
    "Expires: Thu, 29 Apr 1993 11 GMT \\\n",
    "Followup-To: alt.atheism \\\n",
    "Distribution: world \\\n",
    "Organization: Mantis Consultants, Cambridge. UK. \\\n",
    "Approved: news-answers-request@mit.edu \\\n",
    "Supersedes: <19930301143317@mantis.co.uk \\\n",
    "Archive-name: atheism/resources \\\n",
    "Alt-atheism-archive-name: resources \\\n",
    "Last-modified: 11 December 1992 \\\n",
    "Writeto:  FFRF, P.O. Box 750, Madison, WI 53701. \\\n",
    "Summary: Books, addresses, music -- anything related to atheism \\\n",
    "Keywords: FAQ, atheism, books, music, fiction, addresses, contacts \\\n",
    "Version: 1.0 \\\n",
    "Lines: 290 \\\n",
    "Telephone: (608) 256-8900 \\\n",
    "or:  7215 Cameron Road, Austin, TX 78752-2973. \\\n",
    "Telephone: (512) 458-1244 \\\n",
    "Fax:       (512) 467-9525 \"\n",
    "\n",
    "words = s.split(' ')\n",
    "\n",
    "for word in words :\n",
    "    if re.search(\"\\w\\:\", word) != None:\n",
    "        headers_list.append(word)\n",
    "headers_list[headers_list.index('Writeto:')] = 'Write to:'\n",
    "print(headers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus, headers_list):\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "    ENGLISH_STOP_WORDS_LIST = list(ENGLISH_STOP_WORDS)\n",
    "    STOP_WORDS_LIST = list(STOP_WORDS)\n",
    "\n",
    "    stop_words = list(set(stopwords.words('english') + ENGLISH_STOP_WORDS_LIST + STOP_WORDS_LIST))\n",
    "    \"\"\"\n",
    "    #print(stop_words)\n",
    "    headers_removed_corpus = []\n",
    "    for line in corpus:\n",
    "        #line = line.lower()\n",
    "        line = line.strip()\n",
    "        if line == '' :\n",
    "            continue\n",
    "        is_header = False\n",
    "        for header in headers_list:\n",
    "            if header in line:\n",
    "                is_header = True\n",
    "        if not is_header :\n",
    "            headers_removed_corpus.append(line)\n",
    "        #else:\n",
    "        #    print(line)\n",
    "    #pprint(headers_removed_corpus)\n",
    "    \"\"\" \n",
    "    import copy\n",
    "    headers_removed_corpus = copy.deepcopy(corpus)\n",
    "    import string\n",
    "    def to_english(s):\n",
    "        arr = re.sub('\\s', ' ', s)\n",
    "        arr = arr.split(' ')\n",
    "        retval = []\n",
    "        for word in arr:\n",
    "            if word.translate(string.punctuation).isalnum() : \n",
    "                retval.append(word.strip())\n",
    "        return ' '.join(retval)\n",
    "\n",
    "    non_english_and_punct_removed = []\n",
    "    for line in headers_removed_corpus:\n",
    "        clean_line = []\n",
    "        #print(line)\n",
    "        line = re.sub(\"[:,-]\", ' ', line) #,'!\"#$%&()*,-.:;<=>?@^_`{|}~'\n",
    "        line = re.sub(\"[!\\\"#$%&\\'()\\*\\+,\\-\\./:;<=>?@\\[\\\\\\]^_`{|}~]\", ' ', line) #,'!\"#$%&()*,-.:;<=>?@^_`{|}~'\n",
    "        #print(line)\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            clean_line.append(to_english(word).strip())\n",
    "        clean_line = (' '.join(clean_line)).strip()\n",
    "        clean_line = re.sub('\\s +', ' ', clean_line)\n",
    "\n",
    "        if clean_line != '':\n",
    "            non_english_and_punct_removed.append(clean_line)\n",
    "    #pprint(non_english_and_punct_removed)\n",
    "\n",
    "    # remove stopwords\n",
    "\n",
    "    stop_words_removed = []\n",
    "    for line in non_english_and_punct_removed:\n",
    "        words = line.split(' ')\n",
    "        new_line = []\n",
    "        for word in words:\n",
    "            word = re.sub(\"[0-9]+\", '', word)\n",
    "            word = re.sub(\"\\s\", ' ', word)\n",
    "            word = word.strip().lower()\n",
    "            if word == '' :\n",
    "                continue\n",
    "            if word not in stop_words:\n",
    "                new_line.append(word)\n",
    "        new_line = ' '.join(new_line)\n",
    "        if new_line != '' :\n",
    "            stop_words_removed.append(new_line)\n",
    "    #pprint(stop_words_removed)\n",
    "\n",
    "    final_data = '.'.join(stop_words_removed)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'file': '49960', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51060', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51119', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51120', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51121', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51122', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51123', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51124', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51125', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51126', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51127', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51128', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51129', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51130', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51131', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51132', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51133', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51134', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51135', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51136', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51137', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51138', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51139', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51140', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51141', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51142', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51143', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51144', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51145', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51146', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51147', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51148', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51149', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51150', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51151', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51152', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51153', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51154', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51155', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51156', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51157', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51158', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51159', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51160', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51161', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51162', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51163', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51164', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51165', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51166', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51167', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51168', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51169', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51170', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51171', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51172', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51173', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51174', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51175', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51176', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51177', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51178', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51179', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51180', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51181', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51182', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51183', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51184', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51185', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51186', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51187', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51188', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51189', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51190', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51191', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51192', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51193', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51194', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51195', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51196', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51197', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51198', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51199', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51200', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51201', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51202', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51203', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51204', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51205', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51206', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51207', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51208', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51209', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51210', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51211', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51212', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51213', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51214', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51215', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51216', 'root': '.\\\\20_newsgroups\\\\alt.atheism'}]\n"
     ]
    }
   ],
   "source": [
    "document_paths = []\n",
    "from pprint import pprint\n",
    "import os\n",
    "walk = os.walk('.\\\\20_newsgroups', topdown = False)\n",
    "for root, dirs, files in walk :\n",
    "    for file in files:\n",
    "        doc = {}\n",
    "        doc['root'] = root\n",
    "        doc['file'] = file\n",
    "        document_paths.append(doc)\n",
    "pprint(document_paths[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Files Processed in 9.946960926055908 sec\n",
      "1000 Files Processed in 9.583010911941528 sec\n",
      "1500 Files Processed in 8.551152467727661 sec\n",
      "2000 Files Processed in 9.55315637588501 sec\n",
      "2500 Files Processed in 8.824671268463135 sec\n",
      "3000 Files Processed in 9.561097621917725 sec\n",
      "3500 Files Processed in 8.5254647731781 sec\n",
      "4000 Files Processed in 9.537110567092896 sec\n",
      "4500 Files Processed in 9.063798427581787 sec\n",
      "5000 Files Processed in 10.288093090057373 sec\n",
      "5500 Files Processed in 15.47367548942566 sec\n",
      "6000 Files Processed in 12.05720829963684 sec\n",
      "6500 Files Processed in 11.774779081344604 sec\n",
      "7000 Files Processed in 8.843207836151123 sec\n",
      "7500 Files Processed in 8.858887195587158 sec\n",
      "8000 Files Processed in 8.154688119888306 sec\n",
      "8500 Files Processed in 8.03833818435669 sec\n",
      "9000 Files Processed in 7.866506099700928 sec\n",
      "9500 Files Processed in 8.678372144699097 sec\n",
      "10000 Files Processed in 9.002585649490356 sec\n",
      "10500 Files Processed in 9.519327878952026 sec\n",
      "11000 Files Processed in 8.987866401672363 sec\n",
      "11500 Files Processed in 11.245179891586304 sec\n",
      "12000 Files Processed in 9.181025266647339 sec\n",
      "12500 Files Processed in 10.466933965682983 sec\n",
      "13000 Files Processed in 9.52691912651062 sec\n",
      "13500 Files Processed in 13.018617868423462 sec\n",
      "14000 Files Processed in 10.861255884170532 sec\n",
      "14500 Files Processed in 13.835196495056152 sec\n",
      "15000 Files Processed in 11.656157493591309 sec\n",
      "15500 Files Processed in 9.64409613609314 sec\n",
      "16000 Files Processed in 10.36475920677185 sec\n",
      "16500 Files Processed in 10.875372648239136 sec\n",
      "17000 Files Processed in 11.38947606086731 sec\n",
      "17500 Files Processed in 13.330979824066162 sec\n",
      "18000 Files Processed in 12.5743989944458 sec\n",
      "18500 Files Processed in 10.937407970428467 sec\n",
      "19000 Files Processed in 10.79400110244751 sec\n",
      "19500 Files Processed in 9.34481954574585 sec\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "i = 0\n",
    "import time\n",
    "st = time.time()\n",
    "new_paths = []\n",
    "for doc_path in document_paths:\n",
    "    #if i == 2 :\n",
    "    #    break\n",
    "    path = doc_path['root'] + \"\\\\\" + doc_path['file']\n",
    "    with open(path) as doc :\n",
    "        data = doc.readlines()\n",
    "        i += 1\n",
    "        clean_corpus = preprocess_corpus(data, headers_list)\n",
    "        clean_data_file_root = doc_path['root'].replace('.\\\\','.\\\\clean_data\\\\')\n",
    "        os.makedirs(clean_data_file_root, exist_ok = True)\n",
    "        clean_data_file_path = clean_data_file_root + \"\\\\\" +doc_path['file'] + '.txt'\n",
    "        with open(clean_data_file_path, 'wb') as file_clean_data :\n",
    "            file_clean_data.write(bytes(clean_corpus,'utf8'))\n",
    "            file_clean_data.close()\n",
    "        doc.close()\n",
    "        if i%500 == 0 :\n",
    "            print( i, \"Files Processed in\", time.time() - st, \"sec\")\n",
    "            st = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pprint(new_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
