{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\tLevel  0\n",
    "2.\tCount of  0(False)  =  1\n",
    "3.\tCount of  1(True)  =  3\n",
    "4.\tCurrent Entropy  is =  0.811278124459\n",
    "5.\tSplitting on feature  X1  with gain ratio  0.311278124459\n",
    "\n",
    "*************************************************************\n",
    "\n",
    "1.\tLevel  1\n",
    "2.\tCount of  0  =  1\n",
    "3.\tCount of  1  =  1\n",
    "4.\tCurrent Entropy is =  1.0\n",
    "5.\tSplitting on feature  X2  with gain ratio  1.0\n",
    "\n",
    "*************************************************************\n",
    "\n",
    "1.\tLevel  2\n",
    "2.\tCount of  0  =  1\n",
    "3.\tCurrent Entropy  is =  0.0\n",
    "4.\tReached leaf Node\n",
    "\n",
    "*************************************************************\n",
    "\n",
    "1.\tLevel  2\n",
    "2.\tCount of  1  =  1\n",
    "3.\tCurrent Entropy  is =  0.0\n",
    "4.\tReached leaf Node\n",
    "\n",
    "*************************************************************\n",
    "\n",
    "1.\tLevel  1\n",
    "2.\tCount of  1  =  2\n",
    "3.\tCurrent Entropy  is =  0.0\n",
    "4.\tReached leaf Node\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def level(X):\n",
    "    mean = X.mean()\n",
    "    one_third_value = mean/2\n",
    "    two_third_value = 1.5 * mean\n",
    "    for i in range(len(X)):\n",
    "        if X[i] < one_third_value:\n",
    "            X[i] = 1\n",
    "        elif X[i] < mean:\n",
    "            X[i] = 2\n",
    "        elif X[i] < two_third_value:\n",
    "            X[i] = 3\n",
    "        else:\n",
    "            X[i] = 4\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_dataset = datasets.load_iris()\n",
    "X = iris_dataset.data\n",
    "Y = iris_dataset.target\n",
    "\n",
    "for i in range(X.shape[1]):\n",
    "    X[:, i] = level(X[:, i])\n",
    "    \n",
    "features = iris_dataset.feature_names\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0\n",
      "Count of 0 = 39\n",
      "Count of 1 = 35\n",
      "Count of 2 = 38\n",
      "Current Entropy is = 1.09756708182\n",
      "Splitting on feature 1 with gain ratio 0.941219930005\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 6\n",
      "Count of 1 = 28\n",
      "Count of 2 = 22\n",
      "Current Entropy is = 0.952937100125\n",
      "Splitting on feature 0 with gain ratio 0.731161514591\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 6\n",
      "Count of 1 = 16\n",
      "Count of 2 = 2\n",
      "Current Entropy is = 0.823959216501\n",
      "Splitting on feature 2 with gain ratio 0.232549970212\n",
      "\n",
      "Level 3\n",
      "Count of 0 = 6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 1 = 5\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 1 = 11\n",
      "Count of 2 = 2\n",
      "Current Entropy is = 0.429323021931\n",
      "Splitting on feature 3 with gain ratio 0.250063825686\n",
      "\n",
      "Level 4\n",
      "Count of 1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 1 = 9\n",
      "Count of 2 = 1\n",
      "Current Entropy is = 0.325082973391\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 1 = 12\n",
      "Count of 2 = 20\n",
      "Current Entropy is = 0.661563238158\n",
      "Splitting on feature 2 with gain ratio 0.560775861765\n",
      "\n",
      "Level 3\n",
      "Count of 1 = 12\n",
      "Count of 2 = 14\n",
      "Current Entropy is = 0.690185676019\n",
      "Splitting on feature 3 with gain ratio 0.288693705887\n",
      "\n",
      "Level 4\n",
      "Count of 1 = 12\n",
      "Count of 2 = 3\n",
      "Current Entropy is = 0.500402423538\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 2 = 11\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 2 = 6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of 0 = 33\n",
      "Count of 1 = 7\n",
      "Count of 2 = 16\n",
      "Current Entropy is = 0.929502759885\n",
      "Splitting on feature 0 with gain ratio 0.25238529227\n",
      "\n",
      "Level 2\n",
      "Count of 0 = 33\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of 1 = 7\n",
      "Count of 2 = 16\n",
      "Current Entropy is = 0.614503320311\n",
      "Splitting on feature 2 with gain ratio 0.450602158248\n",
      "\n",
      "Level 3\n",
      "Count of 1 = 7\n",
      "Count of 2 = 8\n",
      "Current Entropy is = 0.690923309314\n",
      "Splitting on feature 3 with gain ratio 0.209299257506\n",
      "\n",
      "Level 4\n",
      "Count of 1 = 6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of 1 = 1\n",
      "Count of 2 = 8\n",
      "Current Entropy is = 0.348832095843\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of 2 = 8\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "def entropy(Y, possible_classes):\n",
    "    entropy = 0\n",
    "    total_count = len(Y)\n",
    "    for y in possible_classes :\n",
    "        count_y = (Y == y).sum()\n",
    "        p_i = count_y/total_count\n",
    "        entropy -=  p_i * np.log(p_i)\n",
    "    return entropy\n",
    "\n",
    "def split(X, Y, feature):\n",
    "    splits = np.zeros(len(Y))\n",
    "    possible_values_current_feature = list(set( X[:, feature] ))\n",
    "\n",
    "    group_label = 0\n",
    "    for value in possible_values_current_feature :\n",
    "        splits[ X[:, feature] == value ] = group_label\n",
    "        group_label += 1\n",
    "    return splits\n",
    "\n",
    "def info_gain_on_f(X, Y, feature):\n",
    "    info_gain = 0\n",
    "    split_info = 0\n",
    "    mod_Y = len(Y)\n",
    "    \n",
    "    splits = split(X, Y, feature)\n",
    "    \n",
    "    #print(splits)\n",
    "    \n",
    "    unique_splits = list(set(splits))\n",
    "    \n",
    "    for s in unique_splits:\n",
    "        \n",
    "        indices = (splits == s)\n",
    "        \n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        \n",
    "        #print([X_split_i, Y_split_i])\n",
    "        \n",
    "        mod_Y_i = len(Y_split_i)\n",
    "\n",
    "        ratio_mod_Y_i_to_mod_Y = (mod_Y_i/mod_Y)\n",
    "        possible_classes_Y_i = list(set(Y_split_i))\n",
    "        info_gain += ((ratio_mod_Y_i_to_mod_Y) * entropy( Y_split_i, possible_classes_Y_i))\n",
    "        split_info -= (ratio_mod_Y_i_to_mod_Y * np.log(ratio_mod_Y_i_to_mod_Y))\n",
    "        \n",
    "    return info_gain, split_info\n",
    "    \n",
    "def decision_tree(X, Y, features, level):\n",
    "    print(\"\\nLevel\", level)\n",
    "    possible_classes = list(set(Y))\n",
    "    max_count = -np.inf\n",
    "    max_class = possible_classes[0]\n",
    "    for y in possible_classes:\n",
    "        count_y = (Y == y).sum()\n",
    "        print(\"Count of\", y, \"=\", count_y)\n",
    "        if count_y > max_count :\n",
    "            max_count = count_y\n",
    "            max_class = y   \n",
    "    current_entropy = entropy(Y, possible_classes)\n",
    "    print(\"Current Entropy is =\", current_entropy)\n",
    "    \n",
    "    if len(possible_classes) == 1 or len(features) == 0:\n",
    "        print(\"Reached leaf Node\")\n",
    "        return max_class\n",
    "    selected_feature = None\n",
    "    max_info_gain = -np.inf\n",
    "    for f in features:\n",
    "        info_gain, split_info = info_gain_on_f(X, Y, f)\n",
    "        #print(\"info_gain, split_info\", info_gain, split_info)\n",
    "        #print(\"gain ratio\", info_gain/split_info)\n",
    "\n",
    "        if info_gain > max_info_gain:\n",
    "            selected_feature = f\n",
    "            max_info_gain = info_gain\n",
    "            \n",
    "    print(\"Splitting on feature\", selected_feature,\"with gain ratio\", max_info_gain)\n",
    "    splits = split(X, Y, selected_feature)\n",
    "    unique_splits = list(set(splits))\n",
    "    \n",
    "    selected_feature_index = np.argwhere(features == selected_feature)\n",
    "    features =  np.delete(features, selected_feature_index)\n",
    "    \n",
    "    for s in unique_splits:\n",
    "        indices = (splits == s)\n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        decision_tree(X_split_i, Y_split_i, features, level + 1)\n",
    "        \n",
    "features = np.arange(len(X[0]))\n",
    "\n",
    "max_class = decision_tree(X_train, Y_train, features, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(Y, possible_classes):\n",
    "    entropy = 0\n",
    "    total_count = len(Y)\n",
    "    for y in possible_classes :\n",
    "        count_y = (Y == y).sum()\n",
    "        p_i = count_y/total_count\n",
    "        entropy -=  p_i * np.log(p_i)\n",
    "    return entropy\n",
    "\n",
    "def split(X, Y, feature):\n",
    "    splits = np.zeros(len(Y))\n",
    "    possible_values_current_feature = list(set( X[:, feature] ))\n",
    "\n",
    "    group_label = 0\n",
    "    for value in possible_values_current_feature :\n",
    "        splits[ X[:, feature] == value ] = group_label\n",
    "        group_label += 1\n",
    "    return splits\n",
    "\n",
    "def info_gain_on_f(X, Y, feature):\n",
    "    info_gain = 0\n",
    "    split_info = 0\n",
    "    mod_Y = len(Y)\n",
    "    \n",
    "    splits = split(X, Y, feature)\n",
    "    \n",
    "    #print(splits)\n",
    "    \n",
    "    unique_splits = list(set(splits))\n",
    "    \n",
    "    for s in unique_splits:\n",
    "        \n",
    "        indices = (splits == s)\n",
    "        \n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        \n",
    "        #print([X_split_i, Y_split_i])\n",
    "        \n",
    "        mod_Y_i = len(Y_split_i)\n",
    "\n",
    "        ratio_mod_Y_i_to_mod_Y = (mod_Y_i/mod_Y)\n",
    "        possible_classes_Y_i = list(set(Y_split_i))\n",
    "        info_gain += ((ratio_mod_Y_i_to_mod_Y) * entropy( Y_split_i, possible_classes_Y_i))\n",
    "        split\n",
    "        features[]_info -= (ratio_mod_Y_i_to_mod_Y * np.log(ratio_mod_Y_i_to_mod_Y))\n",
    "        \n",
    "    return info_gain, split_info\n",
    "    \n",
    "def decision_tree(X, Y, features, level = 0):\n",
    "    print(\"Level\",  + 1l\n",
    "    possible_classes = list(set(Y))\n",
    "    max_count = -np.inf\n",
    "    max_class = possible_classes[0]\n",
    "    for y in possible_classes:\n",
    "        count_y = (Y == y).sum()\n",
    "        print(\"Count of\", y, \"=\", count_y)\n",
    "        if count_y > max_count :\n",
    "            max_count = count_y\n",
    "            max_class = y   \n",
    "    current_entropy = entropy(Y, possible_classes)\n",
    "    print(\"Current Entropy is =\", current_entropy)\n",
    "    \n",
    "    if len(possible_classes) == 1 or len(features) == 0:\n",
    "        print(\"Reached leaf Node\")\n",
    "        return max_class\n",
    "    selected_feature = None\n",
    "    max_info_gain = -np.inf\n",
    "    for f in features:\n",
    "        info_gain, split_info = info_gain_on_f(X, Y, f)\n",
    "        print(\"info_gain, split_info\", info_gain, split_info)\n",
    "        print(\"gain ratio\", info_gain/split_info)\n",
    "        \n",
    "        if info_gain > info_gain:\n",
    "            selected_feature = f\n",
    "            max_info_gain = info_gain\n",
    "    print(\"Splitting on feature\", selected_feature,\"with gain ratio\", max_info_gain)\n",
    "    splits = split(X, Y, selected_feature)\n",
    "    unique_splits = list(set(splits))\n",
    "    del features[selected_feature]\n",
    "    for s in unique_splits:\n",
    "        indices = (splits == s)\n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        decision_tree(X_split_i, Y_split_i, features, level + 1)\n",
    "        \n",
    "features = np.arange(len(X[0]))\n",
    "max_class = decision_tree(X_train, Y_train, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(Y, possible_classes):\n",
    "    entropy = 0\n",
    "    total_count = len(Y)\n",
    "    for y in possible_classes :\n",
    "        count_y = (Y == y).sum()\n",
    "        p_i = count_y/total_count\n",
    "        entropy -=  p_i * np.log(p_i)\n",
    "    return entropy\n",
    "\n",
    "def split(X, Y, feature):\n",
    "    splits = np.zeros(len(Y))\n",
    "    possible_values_current_feature = list(set( X[:, feature] ))\n",
    "\n",
    "    group_label = 0\n",
    "    for value in possible_values_current_feature :\n",
    "        splits[ X[:, feature] == value ] = group_label\n",
    "        group_label += 1\n",
    "    return splits\n",
    "\n",
    "def info_gain_on_f(X, Y, feature):\n",
    "    info_gain = 0\n",
    "    split_info = 0\n",
    "    mod_Y = len(Y)\n",
    "    \n",
    "    splits = split(X, Y, feature)\n",
    "    \n",
    "    print(splits)\n",
    "    \n",
    "    unique_splits = list(set(splits))\n",
    "    \n",
    "    for s in unique_splits:\n",
    "        \n",
    "        indices = (splits == s)\n",
    "        \n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        \n",
    "        #print([X_split_i, Y_split_i])\n",
    "        \n",
    "        mod_Y_i = len(Y_split_i)\n",
    "\n",
    "        ratio_mod_Y_i_to_mod_Y = (mod_Y_i/mod_Y)\n",
    "        possible_classes_Y_i = list(set(Y_split_i))\n",
    "        info_gain += ((ratio_mod_Y_i_to_mod_Y) * entropy( Y_split_i, possible_classes_Y_i))\n",
    "        split_info -= (ratio_mod_Y_i_to_mod_Y * np.log(ratio_mod_Y_i_to_mod_Y))\n",
    "        \n",
    "    return info_gain, split_info\n",
    "    \n",
    "def decision_tree(X, Y, features, level = 0):\n",
    "    print(\"Level\",  + 1l\n",
    "    possible_classes = list(set(Y))\n",
    "    max_count = -np.inf\n",
    "    max_class = possible_classes[0]\n",
    "    for y in possible_classes:\n",
    "        count_y = (Y == y).sum()\n",
    "        print(\"Count of\", y, \"=\", count_y)\n",
    "        if count_y > max_count :\n",
    "            max_count = count_y\n",
    "            max_class = y   \n",
    "    current_entropy = entropy(Y, possible_classes)\n",
    "    print(\"Current Entropy is =\", current_entropy)\n",
    "    \n",
    "    if len(possible_classes) == 1 or len(features) == 0:\n",
    "        print(\"Reached leaf Node\")\n",
    "        return max_class\n",
    "    selected_feature = None\n",
    "    max_info_gain = -np.inf\n",
    "    for f in features:\n",
    "        info_gain, split_info = info_gain_on_f(X, Y, f)\n",
    "        print(\"info_gain, split_info\", info_gain, split_info)\n",
    "        print(\"gain ratio\", info_gain/split_info)\n",
    "        \n",
    "        if info_gain > info_gain:\n",
    "            selected_feature = f\n",
    "            max_info_gain = info_gain\n",
    "    print(\"Splitting on feature\", selected_feature,\"with gain ratio\", max_info_gain)\n",
    "    splits = split(X, Y, selected_feature)\n",
    "    unique_splits = list(set(splits))\n",
    "    for s in unique_splits:\n",
    "        indices = (splits == s)\n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        decision_tree(X, Y, features, level + 1)\n",
    "        \n",
    "features = np.arange(len(X[0]))\n",
    "max_class = decision_tree(X_train, Y_train, features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
