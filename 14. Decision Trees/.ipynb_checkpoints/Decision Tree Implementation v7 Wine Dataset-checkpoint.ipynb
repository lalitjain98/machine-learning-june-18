{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wine Data Database\n",
      "====================\n",
      "\n",
      "Notes\n",
      "-----\n",
      "Data Set Characteristics:\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- 1) Alcohol\n",
      " \t\t- 2) Malic acid\n",
      " \t\t- 3) Ash\n",
      "\t\t- 4) Alcalinity of ash  \n",
      " \t\t- 5) Magnesium\n",
      "\t\t- 6) Total phenols\n",
      " \t\t- 7) Flavanoids\n",
      " \t\t- 8) Nonflavanoid phenols\n",
      " \t\t- 9) Proanthocyanins\n",
      "\t\t- 10)Color intensity\n",
      " \t\t- 11)Hue\n",
      " \t\t- 12)OD280/OD315 of diluted wines\n",
      " \t\t- 13)Proline\n",
      "        \t- class:\n",
      "                - class_0\n",
      "                - class_1\n",
      "                - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[http://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      "References\n",
      "----------\n",
      "(1) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "Comparison of Classifiers in High Dimensional Settings, \n",
      "Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Technometrics). \n",
      "\n",
      "The data was used with many others for comparing various \n",
      "classifiers. The classes are separable, though only RDA \n",
      "has achieved 100% correct classification. \n",
      "(RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "(All results using the leave-one-out technique) \n",
      "\n",
      "(2) \n",
      "S. Aeberhard, D. Coomans and O. de Vel, \n",
      "\"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "Mathematics and Statistics, James Cook University of North Queensland. \n",
      "(Also submitted to Journal of Chemometrics). \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load the Dataset\n",
    "\n",
    "\"\"\"\n",
    "dataset = datasets.load_wine()\n",
    "\n",
    "\n",
    "X = dataset.data\n",
    "Y = dataset.target\n",
    "\n",
    "feature_names = dataset.feature_names\n",
    "\n",
    "\n",
    "class_names = dataset.target_names\n",
    "\n",
    "class_dict = {i : class_names[i] for i in range(len(class_names))}\n",
    "\n",
    "print(dataset.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Dictionary {0: 'class_0', 1: 'class_1', 2: 'class_2'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Split Dataset into Training and Testing sets\n",
    "\"\"\"\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 1)\n",
    "\n",
    "\n",
    "print(\"Class Dictionary\", class_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>178.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.000618</td>\n",
       "      <td>2.336348</td>\n",
       "      <td>2.366517</td>\n",
       "      <td>19.494944</td>\n",
       "      <td>99.741573</td>\n",
       "      <td>2.295112</td>\n",
       "      <td>2.029270</td>\n",
       "      <td>0.361854</td>\n",
       "      <td>1.590899</td>\n",
       "      <td>5.058090</td>\n",
       "      <td>0.957449</td>\n",
       "      <td>2.611685</td>\n",
       "      <td>746.893258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.811827</td>\n",
       "      <td>1.117146</td>\n",
       "      <td>0.274344</td>\n",
       "      <td>3.339564</td>\n",
       "      <td>14.282484</td>\n",
       "      <td>0.625851</td>\n",
       "      <td>0.998859</td>\n",
       "      <td>0.124453</td>\n",
       "      <td>0.572359</td>\n",
       "      <td>2.318286</td>\n",
       "      <td>0.228572</td>\n",
       "      <td>0.709990</td>\n",
       "      <td>314.907474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>11.030000</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>1.280000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>1.270000</td>\n",
       "      <td>278.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.362500</td>\n",
       "      <td>1.602500</td>\n",
       "      <td>2.210000</td>\n",
       "      <td>17.200000</td>\n",
       "      <td>88.000000</td>\n",
       "      <td>1.742500</td>\n",
       "      <td>1.205000</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>3.220000</td>\n",
       "      <td>0.782500</td>\n",
       "      <td>1.937500</td>\n",
       "      <td>500.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.050000</td>\n",
       "      <td>1.865000</td>\n",
       "      <td>2.360000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>2.355000</td>\n",
       "      <td>2.135000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>1.555000</td>\n",
       "      <td>4.690000</td>\n",
       "      <td>0.965000</td>\n",
       "      <td>2.780000</td>\n",
       "      <td>673.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>13.677500</td>\n",
       "      <td>3.082500</td>\n",
       "      <td>2.557500</td>\n",
       "      <td>21.500000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>2.875000</td>\n",
       "      <td>0.437500</td>\n",
       "      <td>1.950000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>1.120000</td>\n",
       "      <td>3.170000</td>\n",
       "      <td>985.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>14.830000</td>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.230000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>3.880000</td>\n",
       "      <td>5.080000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>3.580000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.710000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1680.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2           3           4           5   \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean    13.000618    2.336348    2.366517   19.494944   99.741573    2.295112   \n",
       "std      0.811827    1.117146    0.274344    3.339564   14.282484    0.625851   \n",
       "min     11.030000    0.740000    1.360000   10.600000   70.000000    0.980000   \n",
       "25%     12.362500    1.602500    2.210000   17.200000   88.000000    1.742500   \n",
       "50%     13.050000    1.865000    2.360000   19.500000   98.000000    2.355000   \n",
       "75%     13.677500    3.082500    2.557500   21.500000  107.000000    2.800000   \n",
       "max     14.830000    5.800000    3.230000   30.000000  162.000000    3.880000   \n",
       "\n",
       "               6           7           8           9           10          11  \\\n",
       "count  178.000000  178.000000  178.000000  178.000000  178.000000  178.000000   \n",
       "mean     2.029270    0.361854    1.590899    5.058090    0.957449    2.611685   \n",
       "std      0.998859    0.124453    0.572359    2.318286    0.228572    0.709990   \n",
       "min      0.340000    0.130000    0.410000    1.280000    0.480000    1.270000   \n",
       "25%      1.205000    0.270000    1.250000    3.220000    0.782500    1.937500   \n",
       "50%      2.135000    0.340000    1.555000    4.690000    0.965000    2.780000   \n",
       "75%      2.875000    0.437500    1.950000    6.200000    1.120000    3.170000   \n",
       "max      5.080000    0.660000    3.580000   13.000000    1.710000    4.000000   \n",
       "\n",
       "                12  \n",
       "count   178.000000  \n",
       "mean    746.893258  \n",
       "std     314.907474  \n",
       "min     278.000000  \n",
       "25%     500.500000  \n",
       "50%     673.500000  \n",
       "75%     985.000000  \n",
       "max    1680.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(X)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Level 0\n",
      "Count of class_0 = 43\n",
      "Count of class_1 = 50\n",
      "Count of class_2 = 40\n",
      "Current Entropy is = 1.09419925295\n",
      "Splitting on feature 'ash' with gain ratio 2.75780832355\n",
      "\n",
      "Level 1\n",
      "Count of class_1 = 15\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 1\n",
      "Count of class_0 = 43\n",
      "Count of class_1 = 35\n",
      "Count of class_2 = 40\n",
      "Current Entropy is = 1.09505779996\n",
      "Splitting on feature 'magnesium' with gain ratio 1.99956536449\n",
      "\n",
      "Level 2\n",
      "Count of class_1 = 16\n",
      "Count of class_2 = 6\n",
      "Current Entropy is = 0.585952618304\n",
      "Splitting on feature 'nonflavanoid_phenols' with gain ratio 0.684349156268\n",
      "\n",
      "Level 3\n",
      "Count of class_1 = 11\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.286835983056\n",
      "Splitting on feature 'alcohol' with gain ratio 0.28297812007\n",
      "\n",
      "Level 4\n",
      "Count of class_1 = 9\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of class_1 = 2\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.636514168295\n",
      "Splitting on feature 'malic_acid' with gain ratio 0.0\n",
      "\n",
      "Level 5\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of class_1 = 5\n",
      "Count of class_2 = 5\n",
      "Current Entropy is = 0.69314718056\n",
      "Splitting on feature 'total_phenols' with gain ratio 1.90186958267\n",
      "\n",
      "Level 4\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of class_1 = 5\n",
      "Count of class_2 = 4\n",
      "Current Entropy is = 0.686961576597\n",
      "Splitting on feature 'malic_acid' with gain ratio 0.768497242548\n",
      "\n",
      "Level 5\n",
      "Count of class_1 = 4\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.500402423538\n",
      "Splitting on feature 'alcohol' with gain ratio 0.411967408316\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 3\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.69314718056\n",
      "Splitting on feature 'alcalinity_of_ash' with gain ratio 0.0\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 3\n",
      "Current Entropy is = 0.562335144619\n",
      "Splitting on feature 'alcohol' with gain ratio 0.5\n",
      "\n",
      "Level 6\n",
      "Count of class_2 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.69314718056\n",
      "Splitting on feature 'alcalinity_of_ash' with gain ratio 0.0\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 2\n",
      "Count of class_0 = 43\n",
      "Count of class_1 = 19\n",
      "Count of class_2 = 34\n",
      "Current Entropy is = 1.04797107255\n",
      "Splitting on feature 'nonflavanoid_phenols' with gain ratio 1.33369398547\n",
      "\n",
      "Level 3\n",
      "Count of class_0 = 41\n",
      "Count of class_1 = 12\n",
      "Count of class_2 = 11\n",
      "Current Entropy is = 0.90181773128\n",
      "Splitting on feature 'malic_acid' with gain ratio 1.41609653799\n",
      "\n",
      "Level 4\n",
      "Count of class_0 = 35\n",
      "Count of class_1 = 12\n",
      "Count of class_2 = 3\n",
      "Current Entropy is = 0.760985029116\n",
      "Splitting on feature 'proanthocyanins' with gain ratio 3.75858129025\n",
      "\n",
      "Level 5\n",
      "Count of class_2 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of class_0 = 35\n",
      "Count of class_1 = 12\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.657533053625\n",
      "Splitting on feature 'hue' with gain ratio 1.78248506786\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 3\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.562335144619\n",
      "Splitting on feature 'total_phenols' with gain ratio 0.5\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.69314718056\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 8\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 8\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_0 = 35\n",
      "Count of class_1 = 9\n",
      "Current Entropy is = 0.506639557824\n",
      "Splitting on feature 'total_phenols' with gain ratio 1.55849472894\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 3\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_0 = 35\n",
      "Count of class_1 = 6\n",
      "Current Entropy is = 0.416310140668\n",
      "Splitting on feature 'od280/od315_of_diluted_wines' with gain ratio 1.36935431514\n",
      "\n",
      "Level 8\n",
      "Count of class_0 = 1\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.636514168295\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 9\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 9\n",
      "Count of class_0 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 8\n",
      "Count of class_0 = 34\n",
      "Count of class_1 = 4\n",
      "Current Entropy is = 0.336495757584\n",
      "Splitting on feature 'flavanoids' with gain ratio 0.985811855683\n",
      "\n",
      "Level 9\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 9\n",
      "Count of class_0 = 34\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.214559155176\n",
      "Splitting on feature 'proline' with gain ratio 0.235910709924\n",
      "\n",
      "Level 10\n",
      "Count of class_0 = 6\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.562335144619\n",
      "Splitting on feature 'alcalinity_of_ash' with gain ratio 0.360801204395\n",
      "\n",
      "Level 11\n",
      "Count of class_0 = 5\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 11\n",
      "Count of class_0 = 1\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.636514168295\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 12\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 12\n",
      "Count of class_0 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 10\n",
      "Count of class_0 = 28\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of class_0 = 6\n",
      "Count of class_2 = 8\n",
      "Current Entropy is = 0.6829081047\n",
      "Splitting on feature 'alcohol' with gain ratio 0.88608392451\n",
      "\n",
      "Level 5\n",
      "Count of class_0 = 3\n",
      "Count of class_2 = 8\n",
      "Current Entropy is = 0.585952618304\n",
      "Splitting on feature 'alcalinity_of_ash' with gain ratio 0.443991715948\n",
      "\n",
      "Level 6\n",
      "Count of class_0 = 3\n",
      "Count of class_2 = 2\n",
      "Current Entropy is = 0.673011667009\n",
      "Splitting on feature 'proline' with gain ratio 0.899012663676\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_0 = 3\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.562335144619\n",
      "Splitting on feature 'total_phenols' with gain ratio 0.0\n",
      "\n",
      "Level 8\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 8\n",
      "Count of class_0 = 3\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_2 = 6\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of class_0 = 3\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 3\n",
      "Count of class_0 = 2\n",
      "Count of class_1 = 7\n",
      "Count of class_2 = 23\n",
      "Current Entropy is = 0.74310989121\n",
      "Splitting on feature 'malic_acid' with gain ratio 1.08204119017\n",
      "\n",
      "Level 4\n",
      "Count of class_0 = 2\n",
      "Count of class_1 = 3\n",
      "Count of class_2 = 3\n",
      "Current Entropy is = 1.08219553004\n",
      "Splitting on feature 'alcalinity_of_ash' with gain ratio 1.25855224732\n",
      "\n",
      "Level 5\n",
      "Count of class_0 = 1\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.636514168295\n",
      "Splitting on feature 'hue' with gain ratio 0.725982457879\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_0 = 1\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.69314718056\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_0 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of class_0 = 1\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 3\n",
      "Current Entropy is = 0.950270539233\n",
      "Splitting on feature 'total_phenols' with gain ratio 0.979429340549\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.69314718056\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_0 = 1\n",
      "Count of class_2 = 2\n",
      "Current Entropy is = 0.636514168295\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 7\n",
      "Count of class_0 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 4\n",
      "Count of class_1 = 4\n",
      "Count of class_2 = 20\n",
      "Current Entropy is = 0.450561208866\n",
      "Splitting on feature 'alcalinity_of_ash' with gain ratio 2.1424213116\n",
      "\n",
      "Level 5\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 5\n",
      "Count of class_1 = 3\n",
      "Count of class_2 = 20\n",
      "Current Entropy is = 0.387212375186\n",
      "Splitting on feature 'total_phenols' with gain ratio 0.660220474052\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 19\n",
      "Current Entropy is = 0.198515243346\n",
      "Splitting on feature 'proanthocyanins' with gain ratio 0.221273959217\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 14\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 1\n",
      "Count of class_2 = 5\n",
      "Current Entropy is = 0.450561208866\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 8\n",
      "Count of class_1 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 8\n",
      "Count of class_2 = 5\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 6\n",
      "Count of class_1 = 2\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.636514168295\n",
      "Splitting on feature 'alcohol' with gain ratio 0.0\n",
      "\n",
      "Level 7\n",
      "Count of class_1 = 2\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n",
      "\n",
      "Level 7\n",
      "Count of class_2 = 1\n",
      "Current Entropy is = 0.0\n",
      "Reached leaf Node\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Entropy function takes as input, list of labels Y and a list of all possible classes \n",
    "It returns the entropy of the current data subset.\n",
    "\"\"\"\n",
    "\n",
    "def entropy(Y, possible_classes):\n",
    "    entropy = 0\n",
    "    total_count = len(Y)\n",
    "    for y in possible_classes :\n",
    "        count_y = (Y == y).sum()\n",
    "        p_i = count_y/total_count\n",
    "        entropy -=  p_i * np.log(p_i)\n",
    "    return entropy\n",
    "\n",
    "\"\"\"\n",
    "info_gain_for_split return inforamation gain of the current split of Y with list of integers splits\n",
    "ith value of list splits means the ith Y value belongs to that split\n",
    "\n",
    "lengths of Y and splits are equal\n",
    "\n",
    "e.g. say Y = 1.2 4.5 3.2 2.3\n",
    "    splits = 0 1 0 1 \n",
    "    then 1.2 and 3.2 belong to same group, 4.5 and  2.3 belong to same group\n",
    "\"\"\"\n",
    "\n",
    "def info_gain_split_info_for_split(Y, splits):\n",
    "    \n",
    "    #initialize info_gain and split_info values\n",
    "    info_gain = 0\n",
    "    split_info = 0    \n",
    "    \n",
    "    # mod_Y is number of examples\n",
    "    mod_Y = len(Y)\n",
    "    \n",
    "    # unique splits are number of groups in which data is divided\n",
    "    unique_splits = list(set(splits))\n",
    "    \n",
    "    \n",
    "    for s in unique_splits:\n",
    "        \n",
    "        # find indices of examples in group s\n",
    "        indices = (splits == s)\n",
    "        Y_split_i = Y[indices]\n",
    "                \n",
    "        #number of examples in current group s\n",
    "        mod_Y_i = len(Y_split_i)\n",
    "        \n",
    "        \"\"\"\n",
    "                                           |Yi|\n",
    "         ratio_mod_Y_i_to_mod_Y, ratio =   ----\n",
    "                                           |Y|\n",
    "        \"\"\"\n",
    "        ratio_mod_Y_i_to_mod_Y = (mod_Y_i/mod_Y)\n",
    "        \n",
    "        # list of all possible classes in group s\n",
    "        possible_classes_Y_i = list(set(Y_split_i))\n",
    "        \n",
    "        # update info gain and split info values\n",
    "        info_gain += ((ratio_mod_Y_i_to_mod_Y) * entropy( Y_split_i, possible_classes_Y_i))\n",
    "        split_info -= (ratio_mod_Y_i_to_mod_Y * np.log(ratio_mod_Y_i_to_mod_Y))\n",
    "    \n",
    "    return info_gain, split_info\n",
    "\n",
    "\"\"\"\n",
    "Considering input data to be continious, split method takes as input X - the data, Y - the labels, \n",
    "and feature index on which to split the data\n",
    "\n",
    "1. find the set of unique values of feature f and sort it\n",
    "2. build list of mid values ie mean of each pair of adjacent values\n",
    "3. for each mid value\n",
    "    3.1 split data into two parts\n",
    "    3.2 find information gain\n",
    "    3.3 keep the best split\n",
    "returns min_info_gain: information gain for best split\n",
    "        min_split_info : split info for best split\n",
    "        best_split_labels : list of labels for each example\n",
    "        mid_value_for_min_info_gain : the mid value for which best split on feature f was made\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def split(X, Y, feature):\n",
    "    # find the set of unique values of feature f and sort it\n",
    "    possible_values_current_feature = list(set( X[:, feature] ))\n",
    "    pvcf = possible_values_current_feature\n",
    "    pvcf.sort()\n",
    "    \n",
    "    \n",
    "    # build list of mid values ie mean of each pair of adjacent values\n",
    "    mid_values = []\n",
    "    for i in range(len(possible_values_current_feature) -1 ):\n",
    "        mid_values.append((pvcf[i] + pvcf[i+1])/2)\n",
    "    \n",
    "    # initialize variables\n",
    "    min_info_gain = np.inf\n",
    "    mid_value_for_min_info_gain = 0\n",
    "    min_split_info = 0\n",
    "    best_split_labels = np.array([])\n",
    "    \n",
    "    # iterate over list of mid values\n",
    "    for value in mid_values:\n",
    "        current_split_labels = np.ones(len(Y))\n",
    "        \n",
    "        # splitting data into two parts, one group belongs to split 0 and other to split 1\n",
    "        current_split_labels[ X[:, feature] <= value ] = 0\n",
    "        \n",
    "        # find information gain and split info for current split\n",
    "        current_split_information_gain, current_split_split_info = info_gain_split_info_for_split(Y, current_split_labels)\n",
    "        \n",
    "        # keep the best split\n",
    "        if current_split_information_gain < min_info_gain :\n",
    "            min_info_gain = current_split_information_gain\n",
    "            mid_value_for_min_info_gain = value\n",
    "            min_split_info = current_split_split_info\n",
    "            best_split_labels = current_split_labels\n",
    "    \n",
    "    return min_info_gain, min_split_info, best_split_labels.astype(int), mid_value_for_min_info_gain\n",
    "\n",
    "\"\"\"\n",
    "decision_tree:\n",
    "    Input:\n",
    "        X : list of examples\n",
    "        Y : list of labels\n",
    "        features : list of indices of features; after each split, one element is removed from this list\n",
    "        feature_names: list of feature names\n",
    "        class_dict : dictionary of possible classes indices mapped to class names\n",
    "        level : level in recursion tree (only used for printing steps)\n",
    "    \n",
    "    \n",
    "    \n",
    "    Output:\n",
    "        dictionary of nodes where each node is a decision node used for prediction\n",
    "\"\"\"\n",
    "    \n",
    "def decision_tree(X, Y, features, feature_names, class_dict, level):\n",
    "    # current decision node dictionary\n",
    "    node = {}\n",
    "    \n",
    "    #\n",
    "    node[\"level\"] = level\n",
    "    \n",
    "    # dictionary of classes mapped to respective counts in Y\n",
    "    class_counts = {}\n",
    "    print(\"\\nLevel\", level)\n",
    "    possible_classes = list(set(Y))\n",
    "    \n",
    "    # max_class is majority class, max_count is count of majority class\n",
    "    max_count = -np.inf\n",
    "    max_class = possible_classes[0]\n",
    "    \n",
    "    # add key value pairs of classes and their counts in class_counts dictionary\n",
    "    # also find the majority class \n",
    "    for y in possible_classes:\n",
    "        count_y = (Y == y).sum()\n",
    "        class_counts[class_dict[y]] = count_y\n",
    "        print(\"Count of\", class_dict[y], \"=\", count_y)\n",
    "        if count_y > max_count :\n",
    "            max_count = count_y\n",
    "            max_class = y   \n",
    "    \n",
    "    # find current entropy\n",
    "    current_entropy = entropy(Y, possible_classes)\n",
    "    print(\"Current Entropy is =\", current_entropy)\n",
    "    \n",
    "    # add the class_counts dictionary to node dictionary\n",
    "    node['class_counts'] = class_counts\n",
    "    \n",
    "    # add entropy value to node dictionary\n",
    "    node[\"Entropy\"] = current_entropy\n",
    "    \n",
    "    \"\"\"\n",
    "    check for base case, ie either all the examples are marked with a single class\n",
    "    or\n",
    "    there is no more feature to split current data\n",
    "    \n",
    "    mark this decision node as leaf node\n",
    "    add the value of predict class to this node\n",
    "    \n",
    "    return the node\n",
    "    \"\"\"\n",
    "    if len(possible_classes) == 1 or len(features) == 0:\n",
    "        print(\"Reached leaf Node\")\n",
    "        node[\"is_leaf\"] = True\n",
    "        node[\"predict_class\"] = max_class\n",
    "        return node\n",
    "    \n",
    "    \"\"\"\n",
    "    else\n",
    "    this node is NOT a leaf node and splitting can be done\n",
    "    \n",
    "    \"\"\"\n",
    "    node[\"is_leaf\"] = False\n",
    "    \n",
    "    \"\"\" initialize few variables\n",
    "    \n",
    "    selected_feature : index of selected feature to make split on\n",
    "    \n",
    "    max_info_gain : information gain on splitting using the selected_feature\n",
    "    \n",
    "    max_split_info : split info on splitting using the selected_feature\n",
    "    \n",
    "    best_split_labels : labels assigned to examples\n",
    "    \n",
    "    best_split_mid_value : mid value of selected feature to use for prediction\n",
    "    \n",
    "    \"\"\"\n",
    "    selected_feature = None\n",
    "    max_info_gain = -np.inf\n",
    "    max_split_info = -np.inf\n",
    "    best_split_labels = None\n",
    "    best_split_mid_value = None\n",
    "    \n",
    "    # iterate over all available features\n",
    "    for f in features:\n",
    "        \n",
    "        # find info gain\n",
    "        # split info\n",
    "        # current split labels for best split on curent feature \n",
    "        # mid value for current feature\n",
    "        info_gain, split_info, current_split, current_mid_value_for_f = split(X, Y, f)\n",
    "        #print(\"info_gain, split_info\", info_gain, split_info)\n",
    "        #print(\"gain ratio\", info_gain/split_info)\n",
    "\n",
    "        # keep feature that gives maximum gain\n",
    "        if info_gain > max_info_gain and info_gain < np.inf:\n",
    "            selected_feature = f\n",
    "            max_info_gain = info_gain\n",
    "            max_split_info = split_info\n",
    "            best_split_labels = current_split\n",
    "            best_split_mid_value = current_mid_value_for_f\n",
    "\n",
    "    \"\"\"\n",
    "    add index, name of selected feature \n",
    "    information gain\n",
    "    mid value of selected feature\n",
    "    number of examples at current decision\n",
    "    to node dictionary\n",
    "    \"\"\"\n",
    "    node[\"selected_feature\"] = feature_names[selected_feature]\n",
    "    node[\"selected_feature_index\"] = selected_feature\n",
    "    node[\"max_info_gain\"] = max_info_gain\n",
    "    node[\"best_split_mid_value\"] = best_split_mid_value\n",
    "    node[\"num_of_examples\"] = len(Y)\n",
    "    \n",
    "    if max_split_info != 0 :\n",
    "        print(\"Splitting on feature\", \"\\'\" + feature_names[selected_feature] + \"\\'\",\"with gain ratio\", max_info_gain/max_split_info)\n",
    "    else :\n",
    "        print(\"Splitting on feature\", \"\\'\" + feature_names[selected_feature] + \"\\'\",\"with gain ratio inf\")\n",
    "    #splits = split(X, Y, selected_feature)\n",
    "    \n",
    "    # find list of groups in which current dataset is divided\n",
    "    unique_splits = list(set(best_split_labels))\n",
    "    \n",
    "    # remove index of selected feature\n",
    "    selected_feature_index = np.argwhere(features == selected_feature)\n",
    "    features =  np.delete(features, selected_feature_index)\n",
    "    \n",
    "    \"\"\"\n",
    "    recursively call decision tree on 'split' datasets\n",
    "    \"\"\"\n",
    "    for s in unique_splits:\n",
    "        # find indices of examples that belong to split s\n",
    "        indices = (best_split_labels == s)\n",
    "        X_split_i = X[indices, :]\n",
    "        Y_split_i = Y[indices]\n",
    "        # store the output dictionaries of child splits in current node dictionary\n",
    "        node[s] = decision_tree(X_split_i, Y_split_i, features, feature_names, class_dict, level + 1)\n",
    "    \"\"\"\n",
    "    return the \"decision tree\" (dictionary)\n",
    "    \"\"\"\n",
    "    return node\n",
    "\n",
    "features = np.arange(len(feature_names))\n",
    "tree_dict = decision_tree(X_train, Y_train, features, feature_names, class_dict, level = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def predict_single(X, tree_dict):\n",
    "    if tree_dict['is_leaf']:\n",
    "        return tree_dict[\"predict_class\"]\n",
    "    index = tree_dict[\"selected_feature_index\"]\n",
    "    feature_value = tree_dict[\"best_split_mid_value\"]\n",
    "\n",
    "    if X[index] <= feature_value :\n",
    "        #print(X[index], \"<=\" ,feature_value)\n",
    "        return predict_single(X, tree_dict[0])\n",
    "    else:\n",
    "        #print(X[index], \">\" ,feature_value)\n",
    "        return predict_single(X, tree_dict[1])\n",
    "    \n",
    "def predict(X, tree_dict):\n",
    "    Y_pred = []\n",
    "    for i in range(len(X)):\n",
    "        Y_pred.append(predict_single(X[i], tree_dict))\n",
    "    return Y_pred\n",
    "\n",
    "def print_dict(dictionary):\n",
    "    for key in dictionary:\n",
    "        if isinstance(dictionary[key], dict) :\n",
    "            print(key, end = \" \")\n",
    "            print_dict(dictionary[key])\n",
    "        else:\n",
    "            print(key, dictionary[key])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0\n",
      "class_counts class_0 43\n",
      "class_1 50\n",
      "class_2 40\n",
      "Entropy 1.09419925295\n",
      "is_leaf False\n",
      "selected_feature ash\n",
      "selected_feature_index 2\n",
      "max_info_gain 0.971555040567\n",
      "best_split_mid_value 2.02\n",
      "num_of_examples 133\n",
      "0 level 1\n",
      "class_counts class_1 15\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 1\n",
      "class_counts class_0 43\n",
      "class_1 35\n",
      "class_2 40\n",
      "Entropy 1.09505779996\n",
      "is_leaf False\n",
      "selected_feature magnesium\n",
      "selected_feature_index 4\n",
      "max_info_gain 0.961832038709\n",
      "best_split_mid_value 88.5\n",
      "num_of_examples 118\n",
      "0 level 2\n",
      "class_counts class_1 16\n",
      "class_2 6\n",
      "Entropy 0.585952618304\n",
      "is_leaf False\n",
      "selected_feature nonflavanoid_phenols\n",
      "selected_feature_index 7\n",
      "max_info_gain 0.471522891012\n",
      "best_split_mid_value 0.46\n",
      "num_of_examples 22\n",
      "0 level 3\n",
      "class_counts class_1 11\n",
      "class_2 1\n",
      "Entropy 0.286835983056\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.159128542074\n",
      "best_split_mid_value 12.77\n",
      "num_of_examples 12\n",
      "0 level 4\n",
      "class_counts class_1 9\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 4\n",
      "class_counts class_1 2\n",
      "class_2 1\n",
      "Entropy 0.636514168295\n",
      "is_leaf False\n",
      "selected_feature malic_acid\n",
      "selected_feature_index 1\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 2.515\n",
      "num_of_examples 3\n",
      "0 level 5\n",
      "class_counts class_1 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 5\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 3\n",
      "class_counts class_1 5\n",
      "class_2 5\n",
      "Entropy 0.69314718056\n",
      "is_leaf False\n",
      "selected_feature total_phenols\n",
      "selected_feature_index 5\n",
      "max_info_gain 0.618265418938\n",
      "best_split_mid_value 1.33\n",
      "num_of_examples 10\n",
      "0 level 4\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 4\n",
      "class_counts class_1 5\n",
      "class_2 4\n",
      "Entropy 0.686961576597\n",
      "is_leaf False\n",
      "selected_feature malic_acid\n",
      "selected_feature_index 1\n",
      "max_info_gain 0.527928077352\n",
      "best_split_mid_value 2.225\n",
      "num_of_examples 9\n",
      "0 level 5\n",
      "class_counts class_1 4\n",
      "class_2 1\n",
      "Entropy 0.500402423538\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.277258872224\n",
      "best_split_mid_value 12.255\n",
      "num_of_examples 5\n",
      "0 level 6\n",
      "class_counts class_1 3\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 6\n",
      "class_counts class_1 1\n",
      "class_2 1\n",
      "Entropy 0.69314718056\n",
      "is_leaf False\n",
      "selected_feature alcalinity_of_ash\n",
      "selected_feature_index 3\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 20.0\n",
      "num_of_examples 2\n",
      "0 level 7\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 7\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 5\n",
      "class_counts class_1 1\n",
      "class_2 3\n",
      "Entropy 0.562335144619\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.34657359028\n",
      "best_split_mid_value 12.96\n",
      "num_of_examples 4\n",
      "0 level 6\n",
      "class_counts class_2 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 6\n",
      "class_counts class_1 1\n",
      "class_2 1\n",
      "Entropy 0.69314718056\n",
      "is_leaf False\n",
      "selected_feature alcalinity_of_ash\n",
      "selected_feature_index 3\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 21.0\n",
      "num_of_examples 2\n",
      "0 level 7\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 7\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 2\n",
      "class_counts class_0 43\n",
      "class_1 19\n",
      "class_2 34\n",
      "Entropy 1.04797107255\n",
      "is_leaf False\n",
      "selected_feature nonflavanoid_phenols\n",
      "selected_feature_index 7\n",
      "max_info_gain 0.848915117923\n",
      "best_split_mid_value 0.425\n",
      "num_of_examples 96\n",
      "0 level 3\n",
      "class_counts class_0 41\n",
      "class_1 12\n",
      "class_2 11\n",
      "Entropy 0.90181773128\n",
      "is_leaf False\n",
      "selected_feature malic_acid\n",
      "selected_feature_index 1\n",
      "max_info_gain 0.7439057019\n",
      "best_split_mid_value 2.72\n",
      "num_of_examples 64\n",
      "0 level 4\n",
      "class_counts class_0 35\n",
      "class_1 12\n",
      "class_2 3\n",
      "Entropy 0.760985029116\n",
      "is_leaf False\n",
      "selected_feature proanthocyanins\n",
      "selected_feature_index 8\n",
      "max_info_gain 0.63123173148\n",
      "best_split_mid_value 1.11\n",
      "num_of_examples 50\n",
      "0 level 5\n",
      "class_counts class_2 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 5\n",
      "class_counts class_0 35\n",
      "class_1 12\n",
      "class_2 1\n",
      "Entropy 0.657533053625\n",
      "is_leaf False\n",
      "selected_feature hue\n",
      "selected_feature_index 10\n",
      "max_info_gain 0.511280856723\n",
      "best_split_mid_value 0.83\n",
      "num_of_examples 48\n",
      "0 level 6\n",
      "class_counts class_1 3\n",
      "class_2 1\n",
      "Entropy 0.562335144619\n",
      "is_leaf False\n",
      "selected_feature total_phenols\n",
      "selected_feature_index 5\n",
      "max_info_gain 0.34657359028\n",
      "best_split_mid_value 2.38\n",
      "num_of_examples 4\n",
      "0 level 7\n",
      "class_counts class_1 1\n",
      "class_2 1\n",
      "Entropy 0.69314718056\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 12.475\n",
      "num_of_examples 2\n",
      "0 level 8\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 8\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 7\n",
      "class_counts class_1 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 6\n",
      "class_counts class_0 35\n",
      "class_1 9\n",
      "Entropy 0.506639557824\n",
      "is_leaf False\n",
      "selected_feature total_phenols\n",
      "selected_feature_index 5\n",
      "max_info_gain 0.38792535835\n",
      "best_split_mid_value 2.1\n",
      "num_of_examples 44\n",
      "0 level 7\n",
      "class_counts class_1 3\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 7\n",
      "class_counts class_0 35\n",
      "class_1 6\n",
      "Entropy 0.416310140668\n",
      "is_leaf False\n",
      "selected_feature od280/od315_of_diluted_wines\n",
      "selected_feature_index 11\n",
      "max_info_gain 0.358448324221\n",
      "best_split_mid_value 2.64\n",
      "num_of_examples 41\n",
      "0 level 8\n",
      "class_counts class_0 1\n",
      "class_1 2\n",
      "Entropy 0.636514168295\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 13.15\n",
      "num_of_examples 3\n",
      "0 level 9\n",
      "class_counts class_1 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 9\n",
      "class_counts class_0 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 8\n",
      "class_counts class_0 34\n",
      "class_1 4\n",
      "Entropy 0.336495757584\n",
      "is_leaf False\n",
      "selected_feature flavanoids\n",
      "selected_feature_index 6\n",
      "max_info_gain 0.203266568062\n",
      "best_split_mid_value 2.165\n",
      "num_of_examples 38\n",
      "0 level 9\n",
      "class_counts class_1 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 9\n",
      "class_counts class_0 34\n",
      "class_1 2\n",
      "Entropy 0.214559155176\n",
      "is_leaf False\n",
      "selected_feature proline\n",
      "selected_feature_index 12\n",
      "max_info_gain 0.124963365471\n",
      "best_split_mid_value 987.5\n",
      "num_of_examples 36\n",
      "0 level 10\n",
      "class_counts class_0 6\n",
      "class_1 2\n",
      "Entropy 0.562335144619\n",
      "is_leaf False\n",
      "selected_feature alcalinity_of_ash\n",
      "selected_feature_index 3\n",
      "max_info_gain 0.238692813111\n",
      "best_split_mid_value 19.7\n",
      "num_of_examples 8\n",
      "0 level 11\n",
      "class_counts class_0 5\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 11\n",
      "class_counts class_0 1\n",
      "class_1 2\n",
      "Entropy 0.636514168295\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 13.235\n",
      "num_of_examples 3\n",
      "0 level 12\n",
      "class_counts class_1 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 12\n",
      "class_counts class_0 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 10\n",
      "class_counts class_0 28\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 4\n",
      "class_counts class_0 6\n",
      "class_2 8\n",
      "Entropy 0.6829081047\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.460391342953\n",
      "best_split_mid_value 13.57\n",
      "num_of_examples 14\n",
      "0 level 5\n",
      "class_counts class_0 3\n",
      "class_2 8\n",
      "Entropy 0.585952618304\n",
      "is_leaf False\n",
      "selected_feature alcalinity_of_ash\n",
      "selected_feature_index 3\n",
      "max_info_gain 0.305914394095\n",
      "best_split_mid_value 18.9\n",
      "num_of_examples 11\n",
      "0 level 6\n",
      "class_counts class_0 3\n",
      "class_2 2\n",
      "Entropy 0.673011667009\n",
      "is_leaf False\n",
      "selected_feature proline\n",
      "selected_feature_index 12\n",
      "max_info_gain 0.449868115695\n",
      "best_split_mid_value 677.5\n",
      "num_of_examples 5\n",
      "0 level 7\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 7\n",
      "class_counts class_0 3\n",
      "class_2 1\n",
      "Entropy 0.562335144619\n",
      "is_leaf False\n",
      "selected_feature total_phenols\n",
      "selected_feature_index 5\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 1.895\n",
      "num_of_examples 4\n",
      "0 level 8\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 8\n",
      "class_counts class_0 3\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 6\n",
      "class_counts class_2 6\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 5\n",
      "class_counts class_0 3\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 3\n",
      "class_counts class_0 2\n",
      "class_1 7\n",
      "class_2 23\n",
      "Entropy 0.74310989121\n",
      "is_leaf False\n",
      "selected_feature malic_acid\n",
      "selected_feature_index 1\n",
      "max_info_gain 0.608469789159\n",
      "best_split_mid_value 2.295\n",
      "num_of_examples 32\n",
      "0 level 4\n",
      "class_counts class_0 2\n",
      "class_1 3\n",
      "class_2 3\n",
      "Entropy 1.08219553004\n",
      "is_leaf False\n",
      "selected_feature alcalinity_of_ash\n",
      "selected_feature_index 3\n",
      "max_info_gain 0.832611900131\n",
      "best_split_mid_value 19.5\n",
      "num_of_examples 8\n",
      "0 level 5\n",
      "class_counts class_0 1\n",
      "class_1 2\n",
      "Entropy 0.636514168295\n",
      "is_leaf False\n",
      "selected_feature hue\n",
      "selected_feature_index 10\n",
      "max_info_gain 0.462098120373\n",
      "best_split_mid_value 1.135\n",
      "num_of_examples 3\n",
      "0 level 6\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 6\n",
      "class_counts class_0 1\n",
      "class_1 1\n",
      "Entropy 0.69314718056\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 13.46\n",
      "num_of_examples 2\n",
      "0 level 7\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 7\n",
      "class_counts class_0 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 5\n",
      "class_counts class_0 1\n",
      "class_1 1\n",
      "class_2 3\n",
      "Entropy 0.950270539233\n",
      "is_leaf False\n",
      "selected_feature total_phenols\n",
      "selected_feature_index 5\n",
      "max_info_gain 0.659167373201\n",
      "best_split_mid_value 2.365\n",
      "num_of_examples 5\n",
      "0 level 6\n",
      "class_counts class_1 1\n",
      "class_2 1\n",
      "Entropy 0.69314718056\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 12.185\n",
      "num_of_examples 2\n",
      "0 level 7\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 7\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 6\n",
      "class_counts class_0 1\n",
      "class_2 2\n",
      "Entropy 0.636514168295\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 13.265\n",
      "num_of_examples 3\n",
      "0 level 7\n",
      "class_counts class_0 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 0\n",
      "1 level 7\n",
      "class_counts class_2 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 4\n",
      "class_counts class_1 4\n",
      "class_2 20\n",
      "Entropy 0.450561208866\n",
      "is_leaf False\n",
      "selected_feature alcalinity_of_ash\n",
      "selected_feature_index 3\n",
      "max_info_gain 0.37107852622\n",
      "best_split_mid_value 18.25\n",
      "num_of_examples 24\n",
      "0 level 5\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 5\n",
      "class_counts class_1 3\n",
      "class_2 20\n",
      "Entropy 0.387212375186\n",
      "is_leaf False\n",
      "selected_feature total_phenols\n",
      "selected_feature_index 5\n",
      "max_info_gain 0.255645537904\n",
      "best_split_mid_value 2.125\n",
      "num_of_examples 23\n",
      "0 level 6\n",
      "class_counts class_1 1\n",
      "class_2 19\n",
      "Entropy 0.198515243346\n",
      "is_leaf False\n",
      "selected_feature proanthocyanins\n",
      "selected_feature_index 8\n",
      "max_info_gain 0.13516836266\n",
      "best_split_mid_value 1.385\n",
      "num_of_examples 20\n",
      "0 level 7\n",
      "class_counts class_2 14\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 7\n",
      "class_counts class_1 1\n",
      "class_2 5\n",
      "Entropy 0.450561208866\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 12.795\n",
      "num_of_examples 6\n",
      "0 level 8\n",
      "class_counts class_1 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 8\n",
      "class_counts class_2 5\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n",
      "1 level 6\n",
      "class_counts class_1 2\n",
      "class_2 1\n",
      "Entropy 0.636514168295\n",
      "is_leaf False\n",
      "selected_feature alcohol\n",
      "selected_feature_index 0\n",
      "max_info_gain 0.0\n",
      "best_split_mid_value 12.77\n",
      "num_of_examples 3\n",
      "0 level 7\n",
      "class_counts class_1 2\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 1\n",
      "1 level 7\n",
      "class_counts class_2 1\n",
      "Entropy 0.0\n",
      "is_leaf True\n",
      "predict_class 2\n"
     ]
    }
   ],
   "source": [
    "print_dict(tree_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 1\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 2\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 3\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 4\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 5\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 6\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 7\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 8\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 9\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 10\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 11\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 12\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 13\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 14\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 15\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 16\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 17\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 18\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 19\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 20\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 21\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 22\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 23\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 24\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 25\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 26\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 27\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 28\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 29\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 30\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 31\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 32\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 33\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 34\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 35\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 36\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 37\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_1\n",
      "Example 38\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 39\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 40\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 41\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 42\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 43\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 44\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 45\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 46\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 47\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 48\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 49\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 50\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 51\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 52\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 53\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 54\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 55\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 56\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 57\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 58\n",
      "\tActual Class: class_0\n",
      "\tPredicted Class: class_0\n",
      "Example 59\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 60\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 61\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 62\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 63\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 64\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 65\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 66\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 67\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 68\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 69\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 70\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 71\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 72\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 73\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 74\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 75\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 76\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 77\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 78\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 79\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 80\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 81\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 82\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 83\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 84\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 85\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 86\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 87\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 88\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 89\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 90\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 91\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 92\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 93\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 94\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_0\n",
      "Example 95\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 96\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 97\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 98\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 99\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 100\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 101\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 102\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 103\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 104\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 105\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 106\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 107\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 108\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 109\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 110\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 111\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 112\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_2\n",
      "Example 113\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 114\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 115\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 116\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 117\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 118\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 119\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 120\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 121\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_0\n",
      "Example 122\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 123\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_2\n",
      "Example 124\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 125\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 126\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 127\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 128\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 129\n",
      "\tActual Class: class_1\n",
      "\tPredicted Class: class_1\n",
      "Example 130\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 131\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 132\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 133\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 134\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 135\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 136\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 137\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 138\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 139\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 140\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 141\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 142\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 143\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 144\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 145\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 146\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 147\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 148\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 149\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 150\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 151\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 152\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 153\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 154\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 155\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 156\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 157\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 158\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 159\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 160\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 161\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 162\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 163\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 164\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_0\n",
      "Example 165\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 166\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 167\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 168\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 169\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 170\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 171\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 172\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 173\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 174\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 175\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 176\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n",
      "Example 177\n",
      "\tActual Class: class_2\n",
      "\tPredicted Class: class_2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    print(\"Example\", i)\n",
    "    pred = predict_single(X[i], tree_dict)\n",
    "\n",
    "    print(\"\\tActual Class:\", class_dict[Y[i]])\n",
    "    print(\"\\tPredicted Class:\", class_dict[pred])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAG5CAYAAADcTAMaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQEGbiIiISAT8P0YfZLG0lPnLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f8292cdf98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAG5CAYAAADcTAMaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nZjH4SqcBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f82bda6e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_lines(indices, Y_pred, Y):\n",
    "    lines = []\n",
    "    for i in indices :\n",
    "        if Y_pred[i] != Y[i] :\n",
    "            line = [[i, i], [Y_pred[i], Y[i]]]\n",
    "            lines.append(line)\n",
    "    return lines\n",
    "\n",
    "indices = np.arange(len(Y_train))\n",
    "Y_train_pred = predict(X_train, tree_dict)\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.title(\"Predicted vs Actual Class Labels\")\n",
    "plt.axis((-1,len(X_train), -1, len(class_dict)))\n",
    "plt.scatter(indices, Y_train_pred, c = 'r', label = \"Wrong Prediction\")\n",
    "plt.scatter(indices, Y_train, c = Y_train)\n",
    "plt.xlabel(\"Example Number\")\n",
    "plt.ylabel(\"Class\")\n",
    "lines = get_lines(indices, Y_train_pred, Y_train)\n",
    "\n",
    "for line in lines:\n",
    "    line_X = line[0]\n",
    "    line_Y = line[1]\n",
    "    plt.plot(line_X, line_Y, c = 'black', linestyle = \"dashed\")\n",
    "    \n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "indices = np.arange(len(Y_test))\n",
    "\n",
    "Y_test_pred = predict(X_test, tree_dict)\n",
    "plt.figure(figsize = (10, 7))\n",
    "plt.title(\"Predicted vs Actual Class Labels\")\n",
    "plt.axis((-1,len(X_test), -1, len(class_dict)))\n",
    "plt.scatter(indices, Y_test_pred, c = 'r', label = \"Wrong Prediction\")\n",
    "plt.scatter(indices, Y_test, c = Y_test)\n",
    "plt.xlabel(\"Example Number\")\n",
    "plt.ylabel(\"Class\")\n",
    "lines = get_lines(indices, Y_test_pred, Y_test)\n",
    "\n",
    "for line in lines:\n",
    "    line_X = line[0]\n",
    "    line_Y = line[1]\n",
    "    plt.plot(line_X, line_Y, c = 'black', linestyle = \"dashed\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for Y_train\n",
      " [[43  0  0]\n",
      " [ 0 50  0]\n",
      " [ 0  0 40]]\n",
      "Confusion Matrix for Y_test\n",
      " [[15  1  0]\n",
      " [ 2 17  2]\n",
      " [ 1  0  7]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(\"Confusion Matrix for Y_train\\n\", confusion_matrix(Y_train, Y_train_pred))\n",
    "print(\"Confusion Matrix for Y_test\\n\", confusion_matrix(Y_test, Y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'value' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-8516f619710c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mprint_tree_level_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-16-8516f619710c>\u001b[0m in \u001b[0;36mprint_tree_level_order\u001b[1;34m(tree_dict)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mprint_node\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mtree_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"is_leaf\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-16-8516f619710c>\u001b[0m in \u001b[0;36mprint_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\":\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mprint_tree_level_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtree_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'value' is not defined"
     ]
    }
   ],
   "source": [
    "# Level order traversal\n",
    "\n",
    "def print_node(node):\n",
    "    for key, val in node.items() :\n",
    "        if not isinstance(val, dict) :\n",
    "            print(key, \":\", val)\n",
    "    \n",
    "def print_tree_level_order(tree_dict):\n",
    "    q = list()\n",
    "    q.append(tree_dict)\n",
    "    while len(q)!= 0 :\n",
    "        print_node(q[0])\n",
    "        if not tree_dict[\"is_leaf\"] :\n",
    "            q.append(tree_dict[0])\n",
    "            q.append(tree_dict[1])\n",
    "        del q[0]\n",
    "    \n",
    "\n",
    "print_tree_level_order(tree_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
