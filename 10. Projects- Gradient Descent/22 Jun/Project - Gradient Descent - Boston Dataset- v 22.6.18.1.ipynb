{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Descent - Boston Dataset\n",
    "Boston dataset is one of the datasets available in sklearn.\n",
    "You are given a Training dataset csv file with X train and Y train data. As studied in lecture, your task is to come up with Gradient Descent algorithm and thus predictions for the test dataset given.\n",
    "Your task is to:\n",
    "    1. Code Gradient Descent for N features and come with predictions.\n",
    "    2. Try and test with various combinations of learning rates and number of iterations.\n",
    "    3. Try using Feature Scaling, and see if it helps you in getting better results. \n",
    "Read Instructions carefully -\n",
    "    1. Use Gradient Descent as a training algorithm and submit results predicted.\n",
    "    2. Files are in csv format, you can use genfromtxt function in numpy to load data from csv file. Similarly you can use savetxt function to save data into a file.\n",
    "    3. Submit a csv file with only predictions for X test data. File name should not have spaces. File should not have any headers and should only have one column i.e. predictions. Also predictions shouldn't be in exponential form. \n",
    "    4. Your score is based on coefficient of determination.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
      "count  379.000000  379.000000  379.000000  379.000000  379.000000  379.000000   \n",
      "mean     0.019628    0.002455    0.036170    0.028955    0.028775    0.032202   \n",
      "std      1.067490    1.000813    1.017497    1.048995    0.999656    1.001174   \n",
      "min     -0.417713   -0.487722   -1.516987   -0.272599   -1.465882   -3.880249   \n",
      "25%     -0.408171   -0.487722   -0.867691   -0.272599   -0.878475   -0.571480   \n",
      "50%     -0.383729   -0.487722   -0.180458   -0.272599   -0.144217   -0.103479   \n",
      "75%      0.055208    0.156071    1.015999   -0.272599    0.628913    0.529069   \n",
      "max      9.941735    3.804234    2.422565    3.668398    2.732346    3.555044   \n",
      "\n",
      "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
      "count  379.000000  379.000000  379.000000  379.000000  379.000000  379.000000   \n",
      "mean     0.038395   -0.001288    0.043307    0.043786    0.019218   -0.015785   \n",
      "std      0.985209    1.027803    1.016265    1.019974    1.000296    1.015797   \n",
      "min     -2.335437   -1.267069   -0.982843   -1.313990   -2.707379   -3.883072   \n",
      "25%     -0.768994   -0.829872   -0.637962   -0.755697   -0.488039    0.197588   \n",
      "50%      0.338718   -0.329213   -0.523001   -0.440915    0.297977    0.374827   \n",
      "75%      0.911243    0.674172    1.661245    1.530926    0.806576    0.429868   \n",
      "max      1.117494    3.960518    1.661245    1.798194    1.638828    0.441052   \n",
      "\n",
      "            LSTAT           Y  \n",
      "count  379.000000  379.000000  \n",
      "mean     0.018418   22.609499  \n",
      "std      1.015377    9.389647  \n",
      "min     -1.531127    5.000000  \n",
      "25%     -0.828856   16.700000  \n",
      "50%     -0.161629   21.100000  \n",
      "75%      0.647173   25.750000  \n",
      "max      3.409999   50.000000  \n",
      "(379, 13)\n",
      "(379,)\n",
      "               0           1           2           3           4           5   \\\n",
      "count  127.000000  127.000000  127.000000  127.000000  127.000000  127.000000   \n",
      "mean    -0.058575   -0.007327   -0.107939   -0.086410   -0.085871   -0.096098   \n",
      "std      0.769837    1.005445    0.945672    0.839435    1.003998    0.998196   \n",
      "min     -0.417173   -0.487722   -1.557842   -0.272599   -1.431329   -3.058221   \n",
      "25%     -0.410832   -0.487722   -0.891036   -0.272599   -0.947582   -0.567918   \n",
      "50%     -0.398269   -0.487722   -0.375976   -0.272599   -0.299707   -0.127698   \n",
      "75%     -0.242900   -0.219475    1.015999   -0.272599    0.434551    0.283316   \n",
      "max      3.966816    3.589637    2.117615    3.668398    2.732346    3.476688   \n",
      "\n",
      "               6           7           8           9           10          11  \\\n",
      "count  127.000000  127.000000  127.000000  127.000000  127.000000  127.000000   \n",
      "mean    -0.114581    0.003845   -0.129240   -0.130670   -0.057350    0.047105   \n",
      "std      1.042254    0.920171    0.946051    0.933732    1.004824    0.957787   \n",
      "min     -2.225199   -1.263551   -0.982843   -1.308051   -2.707379   -3.907193   \n",
      "25%     -1.240171   -0.762417   -0.637962   -0.785394   -0.765457    0.246544   \n",
      "50%      0.111130   -0.202052   -0.523001   -0.601276    0.113032    0.396098   \n",
      "75%      0.898797    0.604198   -0.350561    0.072833    0.806576    0.441052   \n",
      "max      1.117494    3.287300    1.661245    1.530926    1.268938    0.441052   \n",
      "\n",
      "               12  \n",
      "count  127.000000  \n",
      "mean    -0.054965  \n",
      "std      0.958559  \n",
      "min     -1.496084  \n",
      "25%     -0.678870  \n",
      "50%     -0.283580  \n",
      "75%      0.389254  \n",
      "max      3.548771  \n",
      "(127, 13)\n"
     ]
    }
   ],
   "source": [
    "# Loading Datasets\n",
    "\n",
    "train_dataset = np.genfromtxt(\"../training_boston_x_y_train.csv\", names = True, delimiter = \",\")\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "print(train_df.describe())\n",
    "num_cols = len(train_df.columns)\n",
    "X_train = train_df.values[:, 0: num_cols -1 ]\n",
    "Y_train = train_df.values[:, num_cols - 1]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# print(X_train)\n",
    "# print(Y_train)\n",
    "\n",
    "test_dataset = np.genfromtxt(\"../test_boston_x_test.csv\", names = None, delimiter = \",\")\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "print(test_df.describe())\n",
    "num_cols = len(test_df.columns)\n",
    "X_test = test_df.values\n",
    "\n",
    "print(X_test.shape)\n",
    "\n",
    "# print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "def train_n_models(X_train, Y_train, X_test):\n",
    "    n = 500\n",
    "    sub_Size = 0.8\n",
    "    Y_pred = np.zeros(len(X_test))\n",
    "    Y_train_pred = np.zeros(int(sub_Size * len(X_train)))\n",
    "    num_s = 0\n",
    "    for i in range(n):\n",
    "        X1, X2, Y1, Y2 = model_selection.train_test_split(X_train, Y_train, test_size = 1 - sub_Size)\n",
    "        model = SGDRegressor()\n",
    "        model.fit(X1, Y1)\n",
    "        #print(\"Training Score : \", model.score(X_train, Y_train))\n",
    "        score = model.score(X1, Y1)\n",
    "        if score >= 0.89 :\n",
    "            print(num_s,\" Training Score : \", score)\n",
    "            Y_i_pred = model.predict(X_test)\n",
    "            Y_pred += Y_i_pred\n",
    "            Y_train_i_pred = model.predict(X1)\n",
    "            Y_train_pred += Y_train_i_pred\n",
    "            num_s += 1\n",
    "    Y_pred /= num_s\n",
    "    Y_train_pred /= num_s          \n",
    "    \n",
    "    #print(Y_pred, pred)\n",
    "    return Y_train_pred, Y_pred\n",
    "\n",
    "def add_more_features (X_train, imp_cols_indices = []):\n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    num_f = len(X_train_df.columns)\n",
    "    col_names = X_train_df.columns\n",
    "    if len(imp_cols_indices) == 0 :\n",
    "        imp_cols_indices = np.arange(num_f)\n",
    "        \n",
    "    new_df = X_train_df.copy()\n",
    "    num_imp_cols = len(imp_cols_indices)\n",
    "    for i1 in range(num_imp_cols) :\n",
    "        for j1 in range(i1, num_imp_cols):\n",
    "            i = imp_cols_indices[i1]\n",
    "            j = imp_cols_indices[j1]\n",
    "            new_df[ str(col_names[i]) + \"_\" + str(col_names[j])] = X_train_df[i] * X_train_df[j]\n",
    "    #print(new_df.describe())\n",
    "    return new_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(379, 104)\n",
      "(127, 104)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing as pps\n",
    "X_train_new = add_more_features(X_train)\n",
    "X_test_new = add_more_features(X_test)\n",
    "\n",
    "std_scaler = pps.StandardScaler()\n",
    "std_scaler.fit(X_train_new)\n",
    "\n",
    "X_train_scaled = std_scaler.transform(X_train_new)\n",
    "X_test_scaled = std_scaler.transform(X_test_new)\n",
    "\n",
    "import copy\n",
    "X_train_original = copy.deepcopy(X_train)\n",
    "X_test_original = copy.deepcopy(X_test)\n",
    "\n",
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDRegressor'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Training Score :  0.896694283581\n",
      "1  Training Score :  0.892462844009\n",
      "2  Training Score :  0.894575665737\n",
      "3  Training Score :  0.897426250229\n",
      "4  Training Score :  0.892706972696\n",
      "5  Training Score :  0.895909638754\n",
      "6  Training Score :  0.891294160385\n",
      "7  Training Score :  0.899083778556\n",
      "8  Training Score :  0.893380515617\n",
      "9  Training Score :  0.892198331418\n",
      "10  Training Score :  0.895044953822\n",
      "11  Training Score :  0.891258999367\n",
      "12  Training Score :  0.892327813692\n",
      "13  Training Score :  0.899515965688\n",
      "14  Training Score :  0.890829527446\n",
      "15  Training Score :  0.891553470144\n",
      "16  Training Score :  0.891559740882\n",
      "17  Training Score :  0.892563169187\n"
     ]
    }
   ],
   "source": [
    "Y_train_pred, Y_pred = train_n_models(X_train, Y_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(score(Y_train, Y_train_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"boston_dataset_pred.csv\", Y_pred, '%.5f')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
