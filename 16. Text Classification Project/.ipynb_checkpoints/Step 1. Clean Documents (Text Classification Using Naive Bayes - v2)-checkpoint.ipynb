{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using Naive Bayes\n",
    "### Your task is to:\n",
    "    1. Perform Test Classification using Multinomial Naive Bayes(already implemented in sklearn).\n",
    "    2. Implement Naive Bayes on your own from scratch for text classification. \n",
    "    3. Compare Results of your implementation of Naive Bayes with one in Sklearn.\n",
    "#### Dataset - \n",
    "    http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups\n",
    "#### Comments : \n",
    "    Your code must have proper comments for better understanding.\n",
    "#### Score : \n",
    "    Score will be given by the TA based on your submission.\n",
    "#### Submission : \n",
    "    You have to upload zipped file which has python notebook with implementation and dataset used.\n",
    "#### Your project will be evaluated on following parameters -\n",
    "    1. Correctness of Code - Own Implementation Naive Bayes (Max Score 50)\n",
    "    2. Comparison (Max Score 10)\n",
    "    3. Commenting (Max Score 10)\n",
    "    4. Correctness of Code - Sklearn Naive Bayes (Max Score 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xref:', 'Path:', 'From:', 'Newsgroups:', 'Subject:', 'FAQ:', 'Message-ID:', 'Date:', 'Expires:', 'Followup-To:', 'Distribution:', 'Organization:', 'Approved:', 'Supersedes:', 'Archive-name:', 'Alt-atheism-archive-name:', 'Last-modified:', 'Write to:', 'Summary:', 'Keywords:', 'Version:', 'Lines:', 'Telephone:', 'or:', 'Telephone:', 'Fax:']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "headers_list = []\n",
    "s = \"Xref: \\\n",
    "Path: cantaloupe.srv.cs.cmu.edu!crabapple.srv.cs.cmu.edu!bb3.andrew.cmu.edu!news.sei.cmu.edu!cis.ohio-state.edu!magnus.acs.ohio-state.edu!usenet.ins.cwru.edu!agate!spool.mu.edu!uunet!pipex!ibmpcug!mantis!mathew \\\n",
    "From: mathew <mathew@mantis.co.uk> \\\n",
    "Newsgroups: alt.atheism,alt.atheism.moderated,news.answers,alt.answers \\\n",
    "Subject: Alt.Atheism FAQ: Atheist Resources \\\n",
    "Message-ID: <19930329115719@mantis.co.uk> \\\n",
    "Date: Mon, 29 Mar 1993  GMT \\\n",
    "Expires: Thu, 29 Apr 1993 11 GMT \\\n",
    "Followup-To: alt.atheism \\\n",
    "Distribution: world \\\n",
    "Organization: Mantis Consultants, Cambridge. UK. \\\n",
    "Approved: news-answers-request@mit.edu \\\n",
    "Supersedes: <19930301143317@mantis.co.uk \\\n",
    "Archive-name: atheism/resources \\\n",
    "Alt-atheism-archive-name: resources \\\n",
    "Last-modified: 11 December 1992 \\\n",
    "Writeto:  FFRF, P.O. Box 750, Madison, WI 53701. \\\n",
    "Summary: Books, addresses, music -- anything related to atheism \\\n",
    "Keywords: FAQ, atheism, books, music, fiction, addresses, contacts \\\n",
    "Version: 1.0 \\\n",
    "Lines: 290 \\\n",
    "Telephone: (608) 256-8900 \\\n",
    "or:  7215 Cameron Road, Austin, TX 78752-2973. \\\n",
    "Telephone: (512) 458-1244 \\\n",
    "Fax:       (512) 467-9525 \"\n",
    "\n",
    "words = s.split(' ')\n",
    "\n",
    "for word in words :\n",
    "    if re.search(\"\\w\\:\", word) != None:\n",
    "        headers_list.append(word)\n",
    "headers_list[headers_list.index('Writeto:')] = 'Write to:'\n",
    "print(headers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess_corpus(corpus, headers_list):\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "    ENGLISH_STOP_WORDS_LIST = list(ENGLISH_STOP_WORDS)\n",
    "    STOP_WORDS_LIST = list(STOP_WORDS)\n",
    "\n",
    "    stop_words = list(set(stopwords.words('english') + ENGLISH_STOP_WORDS_LIST + STOP_WORDS_LIST))\n",
    "    \n",
    "    #print(stop_words)\n",
    "    headers_removed_corpus = []\n",
    "    for line in corpus:\n",
    "        #line = line.lower()\n",
    "        line = line.strip()\n",
    "        if line == '' :\n",
    "            continue\n",
    "        is_header = False\n",
    "        for header in headers_list:\n",
    "            if header in line:\n",
    "                is_header = True\n",
    "        if not is_header :\n",
    "            headers_removed_corpus.append(line)\n",
    "        #else:\n",
    "        #    print(line)\n",
    "    #pprint(headers_removed_corpus)\n",
    "\n",
    "    import string\n",
    "    def to_english(s):\n",
    "        arr = re.sub('\\s', ' ', s)\n",
    "        arr = arr.split(' ')\n",
    "        retval = []\n",
    "        for word in arr:\n",
    "            if word.translate(string.punctuation).isalnum() : \n",
    "                retval.append(word.strip())\n",
    "        return ' '.join(retval)\n",
    "\n",
    "    non_english_and_punct_removed = []\n",
    "    for line in headers_removed_corpus:\n",
    "        clean_line = []\n",
    "        #print(line)\n",
    "        line = re.sub(\"[:,-]\", ' ', line) #,'!\"#$%&()*,-.:;<=>?@^_`{|}~'\n",
    "        line = re.sub(\"[!\\\"#$%&\\'()\\*\\+,\\-\\./:;<=>?@\\[\\\\\\]^_`{|}~]\", ' ', line) #,'!\"#$%&()*,-.:;<=>?@^_`{|}~'\n",
    "        #print(line)\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            clean_line.append(to_english(word).strip())\n",
    "        clean_line = (' '.join(clean_line)).strip()\n",
    "        clean_line = re.sub('\\s +', ' ', clean_line)\n",
    "\n",
    "        if clean_line != '':\n",
    "            non_english_and_punct_removed.append(clean_line)\n",
    "    #pprint(non_english_and_punct_removed)\n",
    "\n",
    "    # remove stopwords\n",
    "\n",
    "    stop_words_removed = []\n",
    "    for line in non_english_and_punct_removed:\n",
    "        words = line.split(' ')\n",
    "        new_line = []\n",
    "        for word in words:\n",
    "            word = re.sub(\"[0-9]+\", '', word)\n",
    "            word = re.sub(\"\\s\", ' ', word)\n",
    "            word = word.strip().lower()\n",
    "            if word == '' :\n",
    "                continue\n",
    "            if word not in stop_words:\n",
    "                new_line.append(word)\n",
    "        new_line = ' '.join(new_line)\n",
    "        if new_line != '' :\n",
    "            stop_words_removed.append(new_line)\n",
    "    #pprint(stop_words_removed)\n",
    "\n",
    "    final_data = '.'.join(stop_words_removed)\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'file': '49960', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51060', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51119', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51120', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51121', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51122', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51123', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51124', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51125', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51126', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51127', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51128', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51129', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51130', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51131', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51132', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51133', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51134', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51135', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51136', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51137', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51138', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51139', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51140', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51141', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51142', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51143', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51144', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51145', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51146', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51147', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51148', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51149', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51150', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51151', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51152', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51153', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51154', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51155', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51156', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51157', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51158', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51159', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51160', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51161', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51162', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51163', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51164', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51165', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51166', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51167', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51168', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51169', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51170', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51171', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51172', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51173', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51174', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51175', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51176', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51177', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51178', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51179', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51180', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51181', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51182', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51183', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51184', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51185', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51186', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51187', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51188', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51189', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51190', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51191', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51192', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51193', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51194', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51195', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51196', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51197', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51198', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51199', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51200', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51201', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51202', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51203', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51204', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51205', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51206', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51207', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51208', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51209', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51210', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51211', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51212', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51213', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51214', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51215', 'root': '.\\\\20_newsgroups\\\\alt.atheism'},\n",
      " {'file': '51216', 'root': '.\\\\20_newsgroups\\\\alt.atheism'}]\n"
     ]
    }
   ],
   "source": [
    "document_paths = []\n",
    "from pprint import pprint\n",
    "import os\n",
    "walk = os.walk('.\\\\20_newsgroups', topdown = False)\n",
    "for root, dirs, files in walk :\n",
    "    for file in files:\n",
    "        doc = {}\n",
    "        doc['root'] = root\n",
    "        doc['file'] = file\n",
    "        document_paths.append(doc)\n",
    "pprint(document_paths[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500 Files Processed in 7.826490879058838 sec\n",
      "1000 Files Processed in 4.345705032348633 sec\n",
      "1500 Files Processed in 3.8503570556640625 sec\n",
      "2000 Files Processed in 4.5203633308410645 sec\n",
      "2500 Files Processed in 3.7407877445220947 sec\n",
      "3000 Files Processed in 3.806091070175171 sec\n",
      "3500 Files Processed in 3.9357569217681885 sec\n",
      "4000 Files Processed in 3.6571595668792725 sec\n",
      "4500 Files Processed in 3.0576839447021484 sec\n",
      "5000 Files Processed in 3.7632272243499756 sec\n",
      "5500 Files Processed in 4.857261657714844 sec\n",
      "6000 Files Processed in 3.8596413135528564 sec\n",
      "6500 Files Processed in 3.215991735458374 sec\n",
      "7000 Files Processed in 3.1957223415374756 sec\n",
      "7500 Files Processed in 3.436443328857422 sec\n",
      "8000 Files Processed in 3.63386869430542 sec\n",
      "8500 Files Processed in 3.8422906398773193 sec\n",
      "9000 Files Processed in 2.948340654373169 sec\n",
      "9500 Files Processed in 3.7869699001312256 sec\n",
      "10000 Files Processed in 3.245535373687744 sec\n",
      "10500 Files Processed in 4.172236919403076 sec\n",
      "11000 Files Processed in 3.9837777614593506 sec\n",
      "11500 Files Processed in 4.48654317855835 sec\n",
      "12000 Files Processed in 3.4826266765594482 sec\n",
      "12500 Files Processed in 3.689692497253418 sec\n",
      "13000 Files Processed in 3.197934865951538 sec\n",
      "13500 Files Processed in 4.370866298675537 sec\n",
      "14000 Files Processed in 4.059325456619263 sec\n",
      "14500 Files Processed in 3.9740827083587646 sec\n",
      "15000 Files Processed in 3.8176662921905518 sec\n",
      "15500 Files Processed in 4.165326833724976 sec\n",
      "16000 Files Processed in 4.522106647491455 sec\n",
      "16500 Files Processed in 4.71171760559082 sec\n",
      "17000 Files Processed in 4.649077415466309 sec\n",
      "17500 Files Processed in 5.313408136367798 sec\n",
      "18000 Files Processed in 5.428598165512085 sec\n",
      "18500 Files Processed in 4.879893064498901 sec\n",
      "19000 Files Processed in 4.551470756530762 sec\n",
      "19500 Files Processed in 4.261327028274536 sec\n"
     ]
    }
   ],
   "source": [
    "corpus = \"\"\n",
    "i = 0\n",
    "import time\n",
    "st = time.time()\n",
    "new_paths = []\n",
    "for doc_path in document_paths:\n",
    "    #if i == 2 :\n",
    "    #    break\n",
    "    path = doc_path['root'] + \"\\\\\" + doc_path['file']\n",
    "    with open(path) as doc :\n",
    "        data = doc.readlines()\n",
    "        i += 1\n",
    "        clean_corpus = preprocess_corpus(data, headers_list)\n",
    "        clean_data_file_root = doc_path['root'].replace('.\\\\','.\\\\clean_data\\\\')\n",
    "        os.makedirs(clean_data_file_root, exist_ok = True)\n",
    "        clean_data_file_path = clean_data_file_root + \"\\\\\" +doc_path['file'] + '.txt'\n",
    "        with open(clean_data_file_path, 'wb') as file_clean_data :\n",
    "            file_clean_data.write(bytes(clean_corpus,'utf8'))\n",
    "            file_clean_data.close()\n",
    "        doc.close()\n",
    "        if i%500 == 0 :\n",
    "            print( i, \"Files Processed in\", time.time() - st, \"sec\")\n",
    "            st = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "pprint(new_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
