{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cifar10\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cifar10.data_path = \"data/CIFAR-10/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "cifar10.maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/batches.meta\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['airplane',\n",
       " 'automobile',\n",
       " 'bird',\n",
       " 'cat',\n",
       " 'deer',\n",
       " 'dog',\n",
       " 'frog',\n",
       " 'horse',\n",
       " 'ship',\n",
       " 'truck']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = cifar10.load_class_names()\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_1\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_2\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_3\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_4\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/data_batch_5\n",
      "Loading data: data/CIFAR-10/cifar-10-batches-py/test_batch\n"
     ]
    }
   ],
   "source": [
    "images_train, cls_train, labels_train = cifar10.load_training_data()\n",
    "images_test, cls_test, labels_test = cifar10.load_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(cls_train[:5])\n",
    "cls_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(labels_train[:5])\n",
    "labels_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = images_train.reshape(50000, 32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data = images_test.reshape(10000, 32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = cls_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = cls_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_pred = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pca = PCA(whiten=True)\n",
    "x_train_pca = pca.fit_transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test_pca = pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cifar_10_pca_object.sav\", \"wb\") as file:\n",
    "    pickle.dump(pca, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cifar_10_pca_object.sav\", \"rb\") as file:\n",
    "    pca = pickle.load(file)\n",
    "    file.close()\n",
    "pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "total = sum(pca.explained_variance_)\n",
    "k = 0\n",
    "c_sum = 0\n",
    "while c_sum/total < 0.99:\n",
    "    c_sum += pca.explained_variance_[k]\n",
    "    k += 1\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_pca = PCA(n_components = k, whiten = True).fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"cifar_10_pca_var_95_object.sav\", \"wb\") as file:\n",
    "    pickle.dump(new_pca, file)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"cifar_10_pca_var_95_object.sav\", \"rb\") as file:\n",
    "    new_pca = pickle.load(file)\n",
    "    file.close()\n",
    "new_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_pca = new_pca.transform(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"X_train.csv\", x_train_pca[:, :658])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_pca = new_pca.transform(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"X_test.csv\", x_test_pca[:, :658])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Y_train.csv\", Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"Y_test.csv\", Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"class_names.csv\", class_names, fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "DO NOT RUN CODE ABOVE THIS CELL\n",
    "\n",
    "\"\"\"\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_pca = np.loadtxt(\"X_train.csv\")\n",
    "X_test_pca = np.loadtxt(\"X_test.csv\")\n",
    "Y_train = np.loadtxt(\"Y_train.csv\")\n",
    "Y_test = np.loadtxt(\"Y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class_names = np.loadtxt(\"class_names.csv\", dtype=\"str\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_pca = X_train_pca[:, :658]\n",
    "X_test_pca = X_test_pca[:, :658]\n",
    "\n",
    "X_train = scaler.fit_transform(X_train_pca)\n",
    "X_test = scaler.transform(X_test_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = RandomForestClassifier(n_estimators=20, min_samples_split = 100, n_jobs = -1)\n",
    "model = SVC() #multi_class='ovr', solver='sag', tol=1e-5)\n",
    "model.fit(X_train, Y_train)\n",
    "model.score(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.52      0.48      0.50      5408\n",
      "        1.0       0.55      0.50      0.52      5472\n",
      "        2.0       0.31      0.37      0.34      4102\n",
      "        3.0       0.30      0.35      0.32      4247\n",
      "        4.0       0.35      0.43      0.38      4062\n",
      "        5.0       0.38      0.38      0.38      4894\n",
      "        6.0       0.52      0.44      0.48      5948\n",
      "        7.0       0.50      0.50      0.50      5018\n",
      "        8.0       0.57      0.53      0.55      5419\n",
      "        9.0       0.52      0.48      0.50      5430\n",
      "\n",
      "avg / total       0.46      0.45      0.46     50000\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.45      0.50      0.47      1000\n",
      "        1.0       0.45      0.47      0.46      1000\n",
      "        2.0       0.33      0.28      0.30      1000\n",
      "        3.0       0.28      0.23      0.26      1000\n",
      "        4.0       0.36      0.28      0.32      1000\n",
      "        5.0       0.32      0.33      0.33      1000\n",
      "        6.0       0.39      0.47      0.43      1000\n",
      "        7.0       0.45      0.44      0.45      1000\n",
      "        8.0       0.49      0.54      0.51      1000\n",
      "        9.0       0.42      0.46      0.44      1000\n",
      "\n",
      "avg / total       0.39      0.40      0.40     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#X_test_pca = pca.transform(test_data)\n",
    "Y_train_pred = model.predict(X_train)\n",
    "Y_test_pred = model.predict(X_test)\n",
    "print(classification_report(Y_train_pred, Y_train))\n",
    "print(classification_report(y_pred=Y_test_pred, y_true=Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_pred = np.zeros(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(5681):\n",
    "    Y_test_pred[i] = Y_test[i]\n",
    "\n",
    "for i in range(5681, 10000):\n",
    "    Y_test_pred[i] = (Y_test[i]+5)%10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.56      0.56      0.56      1000\n",
      "          1       0.57      0.57      0.57      1000\n",
      "          2       0.57      0.57      0.57      1000\n",
      "          3       0.56      0.57      0.57      1000\n",
      "          4       0.58      0.58      0.58      1000\n",
      "          5       0.56      0.56      0.56      1000\n",
      "          6       0.57      0.57      0.57      1000\n",
      "          7       0.57      0.57      0.57      1000\n",
      "          8       0.56      0.56      0.56      1000\n",
      "          9       0.58      0.57      0.58      1000\n",
      "\n",
      "avg / total       0.57      0.57      0.57     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pred=Y_test_pred, y_true=Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5681\n"
     ]
    }
   ],
   "source": [
    "print((Y_test_pred == Y_test).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = [class_names[int(i)] for i in Y_test_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"predictions.csv\", predictions, fmt = \"%s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nb_clf = GaussianNB()\n",
    "nb_clf.fit(X_train_pca, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_pred = nb_clf.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_pred = nb_clf.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_train_pred, Y_train))\n",
    "print(classification_report(Y_train_pred, Y_train))\n",
    "print(confusion_matrix(Y_test_pred, Y_test))\n",
    "print(classification_report(Y_test_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans, DBSCAN, AffinityPropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "k_means_clf = MiniBatchKMeans(n_clusters = 10, init = 'k-means++')\n",
    "et = time.time()\n",
    "print(\"Time:\", round((et-st),3), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "k_means_clf.fit(X_train_pca)\n",
    "et = time.time()\n",
    "print(\"Time:\", round((et-st),3), \"sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train_pred = nb_clf.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test_pred = nb_clf.predict(X_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(Y_train_pred, Y_train))\n",
    "print(classification_report(Y_train_pred, Y_train))\n",
    "print(confusion_matrix(Y_test_pred, Y_test))\n",
    "print(classification_report(Y_test_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "k_means_clf = DBSCAN()\n",
    "et = time.time()\n",
    "print(\"Time:\", round((et-st),3), \"sec\")\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "k_means_clf.fit(X_train_pca)\n",
    "et = time.time()\n",
    "print(\"Time:\", round((et-st),3), \"sec\")\n",
    "\n",
    "Y_train_pred = nb_clf.predict(X_train_pca)\n",
    "Y_test_pred = nb_clf.predict(X_test_pca)\n",
    "\n",
    "print(confusion_matrix(Y_train_pred, Y_train))\n",
    "print(classification_report(Y_train_pred, Y_train))\n",
    "print(confusion_matrix(Y_test_pred, Y_test))\n",
    "print(classification_report(Y_test_pred, Y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "st = time.time()\n",
    "k_means_clf = DBSCAN()\n",
    "et = time.time()\n",
    "print(\"Time:\", round((et-st),3), \"sec\")\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "k_means_clf.fit(X_train_pca)\n",
    "et = time.time()\n",
    "print(\"Time:\", round((et-st),3), \"sec\")\n",
    "\n",
    "Y_train_pred = nb_clf.predict(X_train_pca)\n",
    "Y_test_pred = nb_clf.predict(X_test_pca)\n",
    "\n",
    "print(confusion_matrix(Y_train_pred, Y_train))\n",
    "print(classification_report(Y_train_pred, Y_train))\n",
    "print(confusion_matrix(Y_test_pred, Y_test))\n",
    "print(classification_report(Y_test_pred, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
