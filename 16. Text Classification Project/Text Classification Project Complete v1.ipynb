{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Classification Using Naive Bayes\n",
    "### Your task is to:\n",
    "    1. Perform Test Classification using Multinomial Naive Bayes(already implemented in sklearn).\n",
    "    2. Implement Naive Bayes on your own from scratch for text classification. \n",
    "    3. Compare Results of your implementation of Naive Bayes with one in Sklearn.\n",
    "#### Dataset - \n",
    "    http://archive.ics.uci.edu/ml/datasets/Twenty+Newsgroups\n",
    "#### Comments : \n",
    "    Your code must have proper comments for better understanding.\n",
    "#### Score : \n",
    "    Score will be given by the TA based on your submission.\n",
    "#### Submission : \n",
    "    You have to upload zipped file which has python notebook with implementation and dataset used.\n",
    "#### Your project will be evaluated on following parameters -\n",
    "    1. Correctness of Code - Own Implementation Naive Bayes (Max Score 50)\n",
    "    2. Comparison (Max Score 10)\n",
    "    3. Commenting (Max Score 10)\n",
    "    4. Correctness of Code - Sklearn Naive Bayes (Max Score 30\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Xref:', 'Path:', 'From:', 'Newsgroups:', 'Subject:', 'FAQ:', 'Message-ID:', 'Date:', 'Expires:', 'Followup-To:', 'Distribution:', 'Organization:', 'Approved:', 'Supersedes:', 'Archive-name:', 'Alt-atheism-archive-name:', 'Last-modified:', 'Write to:', 'Summary:', 'Keywords:', 'Version:', 'Lines:', 'Telephone:', 'or:', 'Telephone:', 'Fax:']\n",
      "1000 Files Processed in 11.51 sec\n",
      "2000 Files Processed in 10.51 sec\n",
      "3000 Files Processed in 10.463 sec\n",
      "4000 Files Processed in 9.705 sec\n",
      "5000 Files Processed in 9.235 sec\n",
      "6000 Files Processed in 11.338 sec\n",
      "7000 Files Processed in 8.598 sec\n",
      "8000 Files Processed in 9.473 sec\n",
      "9000 Files Processed in 9.383 sec\n",
      "10000 Files Processed in 9.46 sec\n",
      "11000 Files Processed in 10.538 sec\n",
      "12000 Files Processed in 11.244 sec\n",
      "13000 Files Processed in 9.819 sec\n",
      "14000 Files Processed in 10.386 sec\n",
      "15000 Files Processed in 8.194 sec\n",
      "16000 Files Processed in 8.907 sec\n",
      "17000 Files Processed in 8.337 sec\n",
      "18000 Files Processed in 11.146 sec\n",
      "19000 Files Processed in 10.101 sec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "# Data Cleaning\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "# headers_list contains header words like Xref, Path, From etc. \n",
    "# colected them from some of the files\n",
    "\n",
    "headers_list = []\n",
    "\n",
    "s = \"\"\n",
    "\n",
    "with open(\"headers_info.txt\") as headers_file :\n",
    "    s += ''.join(headers_file.readlines())\n",
    "\n",
    "words = s.split(' ')\n",
    "\n",
    "for word in words :\n",
    "    if re.search(\"\\w\\:\", word) != None:\n",
    "        headers_list.append(word)\n",
    "headers_list[headers_list.index('Writeto:')] = 'Write to:'\n",
    "print(headers_list)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "the function takes a string corpus of a single document, and the headers_list\n",
    "Steps in preprocessing:\n",
    "    1. remove sentences containing headers\n",
    "    2. remove numbers, punctuations\n",
    "    3. remove stopwords: imported lists of stopwords from 3 libraries\n",
    "    \n",
    "\"\"\"\n",
    "def preprocess_corpus(corpus, headers_list, remove_headers = True):\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    from spacy.lang.en.stop_words import STOP_WORDS\n",
    "    from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "\n",
    "    ENGLISH_STOP_WORDS_LIST = list(ENGLISH_STOP_WORDS)\n",
    "    STOP_WORDS_LIST = list(STOP_WORDS)\n",
    "\n",
    "    #final list of stop words by merging lists from all three sources\n",
    "    stop_words = list(set(stopwords.words('english') + ENGLISH_STOP_WORDS_LIST + STOP_WORDS_LIST))\n",
    "    \n",
    "    #print(stop_words)\n",
    "    \n",
    "    if remove_headers :    \n",
    "        \"\"\"\n",
    "        identify lines containing a header and remove them\n",
    "        \"\"\"\n",
    "        headers_removed_corpus = []\n",
    "        for line in corpus:\n",
    "            #line = line.lower()\n",
    "            line = line.strip()\n",
    "            if line == '' :\n",
    "                continue\n",
    "            is_header = False\n",
    "            for header in headers_list:\n",
    "                if header in line:\n",
    "                    is_header = True\n",
    "            if not is_header :\n",
    "                headers_removed_corpus.append(line)\n",
    "            #else:\n",
    "            #    print(line)\n",
    "        #pprint(headers_removed_corpus)\n",
    "    else:\n",
    "        headers_removed_corpus = corpus \n",
    "    \"\"\"\n",
    "    to_english removes non-english words from input string\n",
    "    \"\"\"\n",
    "    import string    \n",
    "    def to_english(s):\n",
    "        # remove extra spaces\n",
    "        arr = re.sub('\\s', ' ', s)\n",
    "        arr = arr.split(' ')\n",
    "        retval = []\n",
    "        for word in arr:\n",
    "            #check word for alphanumeric characters by removing punctuations\n",
    "            if word.translate(string.punctuation).isalnum() : \n",
    "                retval.append(word.strip())\n",
    "        return ' '.join(retval)\n",
    "\n",
    "    \"\"\"\n",
    "    Removing non english words and punctuations\n",
    "    \"\"\"\n",
    "    non_english_and_punct_removed = []\n",
    "    for line in headers_removed_corpus:\n",
    "        clean_line = []\n",
    "        #print(line)\n",
    "        #remove punctuations using regex\n",
    "        line = re.sub(\"[:,-]\", ' ', line) \n",
    "        line = re.sub(\"[!\\\"#$%&\\'()\\*\\+,\\-\\./:;<=>?@\\[\\\\\\]^_`{|}~]\", ' ', line) #,'!\"#$%&()*,-.:;<=>?@^_`{|}~'\n",
    "        #print(line)\n",
    "        words = line.split(' ')\n",
    "        for word in words:\n",
    "            clean_line.append(to_english(word).strip())\n",
    "        clean_line = (' '.join(clean_line)).strip()\n",
    "        # remove extra spaces\n",
    "        clean_line = re.sub('\\s +', ' ', clean_line)\n",
    "        #filter empty strings\n",
    "        if clean_line != '':\n",
    "            non_english_and_punct_removed.append(clean_line)\n",
    "    #pprint(non_english_and_punct_removed)\n",
    "\n",
    "    \"\"\"\n",
    "    remove stopwords\n",
    "    \"\"\"\n",
    "    stop_words_removed = []\n",
    "    \n",
    "    for line in non_english_and_punct_removed:\n",
    "        words = line.split(' ')\n",
    "        new_line = []\n",
    "        for word in words:\n",
    "            # remove numbers\n",
    "            word = re.sub(\"[0-9]+\", '', word)\n",
    "            # remove extra spaces\n",
    "            word = re.sub(\"\\s\", ' ', word)\n",
    "            #convert word to lawer case\n",
    "            word = word.strip().lower()\n",
    "            if word == '' :\n",
    "                continue\n",
    "            if word not in stop_words:\n",
    "                new_line.append(word)\n",
    "        new_line = ' '.join(new_line)\n",
    "        if new_line != '' :\n",
    "            stop_words_removed.append(new_line)\n",
    "    #pprint(stop_words_removed)\n",
    "    \n",
    "    final_data = '.'.join(stop_words_removed)\n",
    "    return final_data\n",
    "\n",
    "\"\"\"\n",
    "dummy function to find paths of all files in data files folder\n",
    "\"\"\"\n",
    "def find_all_paths():\n",
    "    document_paths = []\n",
    "    from pprint import pprint\n",
    "    import os\n",
    "    walk = os.walk('.\\\\20_newsgroups', topdown = False)\n",
    "    for root, dirs, files in walk :\n",
    "        for file in files:\n",
    "            doc = {}\n",
    "            doc['root'] = root # path to folder containing the data files\n",
    "            doc['file'] = file # file name\n",
    "            document_paths.append(doc)\n",
    "    return document_paths\n",
    "#pprint(document_paths[0:100])\n",
    "\n",
    "\"\"\"\n",
    "dummy function to preprocess all the data files and create new clean data files\n",
    "\n",
    "\"\"\"\n",
    "def clean_all_docs(document_paths, remove_headers = True) :\n",
    "    corpus = \"\"\n",
    "    i = 0\n",
    "    import time\n",
    "    st = time.time()\n",
    "    new_paths = []\n",
    "    for doc_path in document_paths:\n",
    "        #if i == 2 :\n",
    "        #    break\n",
    "        path = doc_path['root'] + \"\\\\\" + doc_path['file']\n",
    "        with open(path) as doc :\n",
    "            data = doc.readlines()\n",
    "            i += 1\n",
    "            # preprocess data of currnt file\n",
    "            clean_corpus = preprocess_corpus(data, headers_list, remove_headers)\n",
    "            \n",
    "            clean_data_file_root = doc_path['root'].replace('.\\\\','.\\\\clean_data\\\\')\n",
    "            \n",
    "            # create directory if does not already exist\n",
    "            os.makedirs(clean_data_file_root, exist_ok = True)\n",
    "            # actual path of clean data file \n",
    "            clean_data_file_path = clean_data_file_root + \"\\\\\" +doc_path['file'] + '.txt'\n",
    "            # write to clean data file\n",
    "            with open(clean_data_file_path, 'wb') as file_clean_data :\n",
    "                file_clean_data.write(bytes(clean_corpus,'utf8'))\n",
    "                file_clean_data.close()\n",
    "            doc.close()\n",
    "            \n",
    "            #verbose\n",
    "            if i % 1000 == 0 :\n",
    "                print( i, \"Files Processed in\", round(time.time() - st, 3), \"sec\")\n",
    "                st = time.time()\n",
    "\n",
    "\n",
    "document_paths = find_all_paths()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Option to remove headers since for this dataset, removing headers actually decreases accuracy of classifier\n",
    "\n",
    "\"\"\"\n",
    "clean_all_docs(document_paths, remove_headers = True)\n",
    "#pprint(new_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rec.motorcycles',\n",
      " 'sci.crypt',\n",
      " 'alt.atheism',\n",
      " 'sci.med',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'talk.religion.misc',\n",
      " 'sci.electronics',\n",
      " 'comp.windows.x',\n",
      " 'talk.politics.misc',\n",
      " 'soc.religion.christian',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'misc.forsale',\n",
      " 'sci.space',\n",
      " 'talk.politics.guns',\n",
      " 'rec.sport.hockey',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'talk.politics.mideast',\n",
      " 'comp.graphics',\n",
      " 'rec.autos',\n",
      " 'rec.sport.baseball']\n",
      "{0: 'rec.motorcycles',\n",
      " 1: 'sci.crypt',\n",
      " 2: 'alt.atheism',\n",
      " 3: 'sci.med',\n",
      " 4: 'comp.sys.ibm.pc.hardware',\n",
      " 5: 'talk.religion.misc',\n",
      " 6: 'sci.electronics',\n",
      " 7: 'comp.windows.x',\n",
      " 8: 'talk.politics.misc',\n",
      " 9: 'soc.religion.christian',\n",
      " 10: 'comp.sys.mac.hardware',\n",
      " 11: 'misc.forsale',\n",
      " 12: 'sci.space',\n",
      " 13: 'talk.politics.guns',\n",
      " 14: 'rec.sport.hockey',\n",
      " 15: 'comp.os.ms-windows.misc',\n",
      " 16: 'talk.politics.mideast',\n",
      " 17: 'comp.graphics',\n",
      " 18: 'rec.autos',\n",
      " 19: 'rec.sport.baseball'}\n",
      "0    .\\clean_data\\20_newsgroups\\alt.atheism\\49960.txt\n",
      "1    .\\clean_data\\20_newsgroups\\alt.atheism\\51060.txt\n",
      "2    .\\clean_data\\20_newsgroups\\alt.atheism\\51119.txt\n",
      "3    .\\clean_data\\20_newsgroups\\alt.atheism\\51120.txt\n",
      "4    .\\clean_data\\20_newsgroups\\alt.atheism\\51121.txt\n",
      "Name: path, dtype: object\n",
      "0    2\n",
      "1    2\n",
      "2    2\n",
      "3    2\n",
      "4    2\n",
      "Name: class, dtype: int64\n",
      "(14997,)\n",
      "(5000,)\n",
      "(14997,)\n",
      "(5000,)\n",
      "1000 Files Processed in 1.849 millisec\n",
      "2000 Files Processed in 1.907 millisec\n",
      "3000 Files Processed in 2.11 millisec\n",
      "4000 Files Processed in 1.893 millisec\n",
      "5000 Files Processed in 1.944 millisec\n",
      "6000 Files Processed in 2.058 millisec\n",
      "7000 Files Processed in 1.882 millisec\n",
      "8000 Files Processed in 2.01 millisec\n",
      "9000 Files Processed in 1.837 millisec\n",
      "10000 Files Processed in 1.795 millisec\n",
      "11000 Files Processed in 1.8 millisec\n",
      "12000 Files Processed in 1.782 millisec\n",
      "13000 Files Processed in 1.815 millisec\n",
      "14000 Files Processed in 1.747 millisec\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "from nltk.corpus import words as nltk_words\n",
    "\n",
    "#english dictionary contains english words from NLTK, dictionary for fast access\n",
    "english_dictionary = {word : True for word in list(set(nltk_words.words()))}\n",
    "\n",
    "\"\"\"\n",
    "check if input word is an english word \n",
    "\"\"\"\n",
    "\n",
    "def is_in_english(word):\n",
    "    try:\n",
    "        return english_dictionary[word]\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "\"\"\"\n",
    "Build Dictionary of Words\n",
    "\"\"\"\n",
    "\n",
    "# document paths stores paths to all clean data files \n",
    "document_paths = []\n",
    "\n",
    "# pretty print module for better output format\n",
    "from pprint import pprint\n",
    "import os\n",
    "# find all file paths in clean data folder\n",
    "walk = os.walk('.\\\\clean_data\\\\20_newsgroups', topdown = False)\n",
    "for root, dirs, files in walk :\n",
    "    for file in files:\n",
    "        doc = {}\n",
    "        dir_ = root.split('\\\\')[-1]\n",
    "        doc['path'] = root+\"\\\\\"+file\n",
    "        doc['target'] = dir_\n",
    "        document_paths.append(doc)\n",
    "#pprint(document_paths[0:10000:100])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(document_paths)\n",
    "#df.head()\n",
    "\n",
    "# targets is list of all class names\n",
    "targets = list(set(df['target'].values))\n",
    "pprint(targets)\n",
    "\n",
    "# class_dict contains indices mapped to actual class names\n",
    "class_dict = { i : targets[i] for i in range(len(targets))}\n",
    "pprint(class_dict)\n",
    "\n",
    "# class is numeric representation for class name\n",
    "# categry is the actual class name\n",
    "class_df = pd.DataFrame()\n",
    "class_df['class'] = class_dict\n",
    "class_df['category'] = [class_dict[key] for key in class_dict]\n",
    "class_df.to_csv(\"class_dict.csv\", index = False)\n",
    "\n",
    "df['class'] = [targets.index(target) for target in df['target'].values]\n",
    "\n",
    "df.head()\n",
    "\n",
    "X = df['path']\n",
    "Y = df['class']\n",
    "print(X[0:5])\n",
    "print(Y[0:5])\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Split the final data files into training and testing datasets(actually containing the file paths)\n",
    "\"\"\"\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, random_state = 0) \n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_train.shape)\n",
    "print(Y_test.shape)\n",
    "\n",
    "train_df = pd.DataFrame()\n",
    "train_df['path'] = X_train\n",
    "train_df['class'] = Y_train\n",
    "\n",
    "#save file storing the paths to train files\n",
    "train_df.to_csv(\"train_files.csv\", index = False)\n",
    "\n",
    "#save file storing the paths to test files\n",
    "test_df = pd.DataFrame()\n",
    "test_df['path'] = X_test\n",
    "test_df['class'] = Y_test\n",
    "test_df.to_csv(\"test_files.csv\", index = False)\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "train_df.head()\n",
    "\n",
    "test_df.head()\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Build Master Dictionary that is used to decide the features \n",
    "\n",
    "master_dictionary is mapping of each english word with its count\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "master_dictionary = {}\n",
    "\n",
    "i = 0\n",
    "import time\n",
    "st = time.time()\n",
    "new_paths = []\n",
    "for doc_path in X_train:\n",
    "    #if i == 1 :\n",
    "    #    break\n",
    "    path = doc_path\n",
    "    with open(path) as doc :\n",
    "        num_tokens_in_doc = 0\n",
    "        data = ''.join(doc.readlines()).split('.')\n",
    "        for line in data:\n",
    "            for word in line.split():\n",
    "                # non english words can't be used as features for this dataset\n",
    "                if not is_in_english(word):\n",
    "                    continue\n",
    "                #print(word)\n",
    "                # using try/catch approach for very fast search\n",
    "                try:\n",
    "                    master_dictionary[word] += 1\n",
    "                except KeyError:\n",
    "                    master_dictionary[word] = 1\n",
    "                    continue\n",
    "        doc.close()\n",
    "        i += 1\n",
    "        # verbose\n",
    "        if i % 1000 == 0 :\n",
    "            print( i, \"Files Processed in\", round((time.time() - st), 3) , \"sec\")\n",
    "            st = time.time()\n",
    "#print(master_dictionary)\n",
    "\n",
    "import numpy as np\n",
    "keys = list(master_dictionary)\n",
    "freq = np.array([ master_dictionary[key] for key in keys])\n",
    "\n",
    "words_df = pd.DataFrame()\n",
    "words_df['word'] = keys\n",
    "words_df['frequency'] = freq\n",
    "\n",
    "# all words csv contains master dictionary\n",
    "words_df.to_csv('all_words.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9923\n",
      "5445\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMgAkqVMGgCR1ygCQpE4ZAJLUqf8H3O16jwS6lwUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd861fac88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of common words :  0\n",
      "No. of rare words :  15799\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd3dddd860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['article', 'branch', 'reality', 'likely', 'gotten', 'highly', 'happen', 'forget', 'cult', 'responsible', 'expect', 'sole', 'responsibility', 'trial', 'following', 'right', 'continue', 'believe', 'worship', 'sabbath', 'best', 'known', 'seventh', 'day', 'argue', 'act', 'regular', 'service', 'special', 'meeting', 'cor', 'explicitly', 'observe', 'god', 'kind', 'power', 'cause', 'affected', 'equipment', 'couple', 'sound', 'kicking', 'stereo', 'direct', 'mighty', 'strong', 'powerful', 'car', 'engine', 'battery', 'lot', 'like', 'radio', 'actually', 'shut', 'completely', 'goes', 'suspect', 'voltage', 'far', 'try', 'vehicle', 'idle', 'low', 'start', 'extra', 'current', 'drawn', 'speed', 'drop', 'compensate', 'resolution', 'problem', 'matter', 'company', 'ultimately', 'resolve', 'pay', 'attention', 'citizen', 'send', 'apply', 'talking', 'help', 'able', 'install', 'filtering', 'panel', 'recommend', 'type', 'licensed', 'transmitter', 'going', 'affecting', 'house', 'unfortunately', 'fair', 'chance', 'signal', 'picked', 'wiring', 'simple', 'filter', 'need', 'heavy', 'duty', 'probably', 'solve', 'interference', 'internal', 'regularly', 'street', 'question', 'watch', 'trucks', 'big', 'driving', 'time', 'identify', 'contact', 'owner', 'person', 'amateur', 'willing', 'explain', 'causing', 'posting', 'host', 'sale', 'plus', 'shipping', 'body', 'count', 'row', 'waking', 'temple', 'dog', 'music', 'factory', 'eye', 'darkness', 'jet', 'fighter', 'ancient', 'social', 'history', 'sell', 'encyclopedia', 'physics', 'yes', 'mail', 'file', 'think', 'sender', 'spray', 'chain', 'wax', 'seen', 'wear', 'stuff', 'bike', 'stays', 'check', 'thousand', 'subject', 'endless', 'dealer', 'master', 'links', 'later', 'wide', 'glide', 'red', 'lady', 'baby', 'disclaimer', 'needs', 'agree', 'raised', 'pack', 'wild', 'corn', 'currently', 'trouble', 'true', 'blue', 'model', 'display', 'readable', 'yellow', 'window', 'ghost', 'image', 'background', 'little', 'read', 'ago', 'thought', 'hook', 'mac', 'screen', 'sync', 'green', 'hardware', 'diode', 'solution', 'somebody', 'post', 'checked', 'miss', 'sure', 'good', 'thing', 'thanks', 'university', 'steel', 'research', 'group', 'finland', 'beaten', 'th', 'pool', 'certainly', 'meet', 'canada', 'final', 'look', 'situation', 'kick', 'world', 'cup', 'eventually', 'lost', 'reply', 'joke', 'fascist', 'million', 'people', 'fully', 'extermination', 'criminal', 'elderly', 'soviet', 'entire', 'population', 'result', 'genocide', 'nearly', 'lived', 'homeland', 'oppressive', 'government', 'carried', 'remainder', 'driven', 'safe', 'heaven', 'today', 'return', 'crime', 'making', 'demand', 'determine', 'future', 'nation', 'anniversary', 'come', 'unity', 'desire', 'pursue', 'struggle', 'appeal', 'united', 'participate', 'en', 'cultural', 'political', 'closed', 'mountain', 'serve', 'ways', 'escape', 'work', 'longer', 'single', 'easily', 'written', 'handed', 'manner', 'boiling', 'surface', 'accept', 'attempt', 'foster', 'rest', 'fun', 'flame', 'express', 'opinion', 'intended', 'human', 'advanced', 'religious', 'planet', 'mental', 'perfectly', 'content', 'point', 'scream', 'animal', 'religion', 'address', 'biological', 'aspect', 'life', 'structure', 'biology', 'needless', 'disagree', 'underlying', 'infectious', 'hope', 'purpose', 'safety', 'hide', 'moral', 'standard', 'eternal', 'shown', 'persistent', 'belief', 'spite', 'past', 'demonstrate', 'workable', 'individual', 'source', 'hidden', 'distinction', 'given', 'loss', 'control', 'finally', 'appropriate', 'reason', 'inadequate', 'save', 'merely', 'real', 'living', 'doctrine', 'generally', 'live', 'according', 'friend', 'set', 'ministry', 'said', 'spread', 'concerned', 'priority', 'rightly', 'gave', 'normally', 'understood', 'preach', 'word', 'convert', 'cost', 'repeat', 'new', 'ad', 'respecting', 'demonstration', 'non', 'seek', 'ask', 'radical', 'quickly', 'occur', 'personal', 'exist', 'evaluate', 'easy', 'harm', 'gain', 'long', 'view', 'incorporate', 'worse', 'conversion', 'open', 'taken', 'advantage', 'spirit', 'conviction', 'wrong', 'let', 'sleep', 'food', 'eat', 'reproduce', 'die', 'capable', 'vision', 'humanity', 'limited', 'pray', 'someday', 'reflection', 'variety', 'learn', 'language', 'organize', 'blatant', 'physically', 'relationship', 'characterize', 'close', 'use', 'emotional', 'upper', 'foundation', 'millions', 'small', 'guilty', 'blind', 'truth', 'realize', 'mask', 'prophet', 'large', 'influence', 'sort', 'element', 'appear', 'amazing', 'certainty', 'conclusion', 'sack', 'gone', 'assert', 'know', 'noise', 'delete', 'lots', 'legality', 'abortion', 'universal', 'health', 'care', 'program', 'covered', 'pro', 'choice', 'anti', 'example', 'net', 'illegal', 'immediately', 'flamed', 'impose', 'morals', 'support', 'away', 'supporting', 'feel', 'saying', 'tough', 'paying', 'mutually', 'exclusive', 'issue', 'main', 'argument', 'forcing', 'respect', 'greatly', 'order', 'tax', 'money', 'case', 'unable', 'afford', 'blocked', 'place', 'want', 'assumed', 'requirement', 'delivery', 'include', 'suppose', 'instead', 'remove', 'restriction', 'legal', 'surgery', 'desired', 'insist', 'complain', 'bunch', 'related', 'majority', 'win', 'candidate', 'fact', 'number', 'important', 'personally', 'stupid', 'vote', 'stance', 'consider', 'way', 'perception', 'economy', 'apparent', 'liberal', 'awfully', 'nice', 'poll', 'unbiased', 'middle', 'tricky', 'wording', 'course', 'country', 'left', 'ralph', 'answer', 'president', 'institute', 'conservative', 'policy', 'review', 'contrary', 'understanding', 'position', 'prior', 'election', 'object', 'rob', 'news', 'disgusting', 'office', 'immediate', 'guess', 'sex', 'stealing', 'breaking', 'entering', 'national', 'starting', 'secret', 'kill', 'pathetic', 'calling', 'obvious', 'challenge', 'present', 'evidence', 'stole', 'mind', 'broke', 'building', 'draw', 'absolutely', 'culture', 'wait', 'till', 'settled', 'works', 'love', 'law', 'familiar', 'commentary', 'humor', 'interested', 'trying', 'method', 'state', 'went', 'doctor', 'minute', 'interview', 'scratches', 'leading', 'allergic', 'week', 'shot', 'month', 'rare', 'garbage', 'somewhat', 'disappointed', 'getting', 'public', 'library', 'consumer', 'allergy', 'page', 'reading', 'necessarily', 'common', 'successful', 'workplace', 'previous', 'wrote', 'cliff', 'difference', 'helpful', 'hint', 'running', 'possible', 'mode', 'dos', 'ability', 'run', 'added', 'everybody', 'box', 'raise', 'picture', 'mike', 'development', 'official', 'spokesman', 'wonder', 'hard', 'add', 'design', 'saver', 'feature', 'built', 'consumption', 'automatically', 'machine', 'apple', 'sun', 'agreed', 'saving', 'require', 'monitor', 'outlet', 'quote', 'note', 'substantial', 'especially', 'factor', 'reduced', 'load', 'air', 'study', 'simply', 'night', 'greater', 'double', 'seeing', 'leave', 'home', 'potential', 'cut', 'based', 'data', 'encouraging', 'leaving', 'pointed', 'switch', 'indication', 'rear', 'designed', 'tolerate', 'worth', 'deeply', 'shed', 'light', 'widely', 'knocking', 'lamp', 'blame', 'wake', 'discussion', 'proper', 'watching', 'tonight', 'outside', 'compound', 'independent', 'different', 'hurt', 'hardly', 'claim', 'dangerous', 'paranoid', 'fan', 'ahead', 'boy', 'stood', 'tell', 'job', 'preservation', 'speak', 'cheap', 'thug', 'barrel', 'yeah', 'interpret', 'constitution', 'expressed', 'seriously', 'major', 'hold', 'network', 'guy', 'came', 'repeated', 'private', 'insurance', 'cover', 'travel', 'buy', 'local', 'coming', 'stuck', 'hill', 'mount', 'fall', 'ill', 'extent', 'affect', 'list', 'necessary', 'thinking', 'practice', 'hospital', 'figure', 'arrange', 'advance', 'applied', 'style', 'treatment', 'brother', 'town', 'table', 'dinner', 'book', 'depend', 'downtown', 'mile', 'boston', 'ugly', 'adequate', 'market', 'size', 'equivalent', 'provide', 'prospect', 'partly', 'province', 'smaller', 'attract', 'fed', 'free', 'bob', 'anybody', 'compete', 'offer', 'basic', 'remember', 'hear', 'recently', 'routine', 'effort', 'optional', 'isolated', 'particular', 'scientist', 'negative', 'north', 'turns', 'offering', 'cartel', 'turn', 'figured', 'sister', 'pat', 'chamber', 'commerce', 'scratch', 'western', 'miracle', 'nationalism', 'la', 'cooper', 'tower', 'store', 'catch', 'urban', 'angel', 'lit', 'business', 'old', 'trade', 'agreement', 'saw', 'odd', 'labour', 'establishment', 'preserve', 'traditional', 'administration', 'high', 'percentage', 'knew', 'commission', 'initiative', 'head', 'society', 'hire', 'squad', 'portion', 'press', 'hostile', 'regardless', 'globe', 'letter', 'heart', 'worried', 'seize', 'proof', 'vital', 'recall', 'physician', 'deliberate', 'hit', 'function', 'tight', 'fist', 'period', 'nature', 'mob', 'patch', 'opposed', 'insured', 'infrastructure', 'dealing', 'correct', 'fixed', 'monopoly', 'steady', 'bad', 'bought', 'socialist', 'deal', 'medical', 'resource', 'rate', 'sick', 'luck', 'sudden', 'wave', 'training', 'tend', 'prescription', 'cold', 'medicine', 'education', 'dollar', 'threshold', 'buffalo', 'cherry', 'feed', 'replacement', 'game', 'coverage', 'cleaning', 'spending', 'sad', 'story', 'leader', 'grant', 'campaign', 'sorry', 'neo', 'considered', 'employer', 'contribute', 'discourage', 'lower', 'drain', 'met', 'mean', 'create', 'decide', 'approach', 'second', 'sufficient', 'shea', 'indicate', 'competition', 'west', 'great', 'pretty', 'bigger', 'detailed', 'atlas', 'better', 'flight', 'lake', 'amazed', 'increase', 'density', 'region', 'clinic', 'alternative', 'invest', 'end', 'choose', 'spend', 'directly', 'involved', 'provision', 'military', 'native', 'term', 'facility', 'tech', 'boat', 'comes', 'concern', 'violate', 'offended', 'cash', 'anyways', 'stopped', 'stopping', 'thank', 'goodness', 'hockey', 'told', 'partnership', 'injured', 'knee', 'belong', 'manager', 'bank', 'provincial', 'length', 'harder', 'certain', 'access', 'bet', 'trash', 'talk', 'cable', 'chest', 'dare', 'lengthy', 'robin', 'lane', 'typical', 'criticism', 'inaccurate', 'historical', 'document', 'insight', 'historian', 'appreciate', 'event', 'fox', 'recent', 'search', 'drive', 'write', 'session', 'capability', 'looking', 'directory', 'burned', 'change', 'disc', 'older', 'taking', 'multiple', 'van', 'interactive', 'media', 'installation', 'enter', 'totally', 'screwed', 'graphics', 'functional', 'exit', 'alt', 'tried', 'reinstall', 'halfway', 'process', 'complete', 'working', 'diamond', 'stealth', 'video', 'stacker', 'worked', 'fairly', 'wife', 'sugar', 'eaten', 'reaction', 'seizure', 'associate', 'artificial', 'intelligence', 'phone', 'newsreader', 'logically', 'subset', 'girl', 'writing', 'carefully', 'entirely', 'valid', 'piece', 'logical', 'statement', 'similarly', 'interpretation', 'hi', 'popular', 'presentation', 'tomorrow', 'enhanced', 'got', 'location', 'enterprise', 'pressure', 'precision', 'digit', 'meter', 'measuring', 'extremely', 'shape', 'stand', 'brass', 'fitting', 'useful', 'lab', 'al', 'connected', 'frequency', 'expensive', 'card', 'mono', 'line', 'respond', 'site', 'faster', 'message', 'gateway', 'bit', 'account', 'forward', 'excellent', 'price', 'park', 'schedule', 'finance', 'presidential', 'ticket', 'fast', 'oh', 'speeding', 'hate', 'beautiful', 'mark', 'singer', 'motif', 'featured', 'plotting', 'tool', 'version', 'collectively', 'compile', 'fine', 'test', 'summary', 'blurb', 'available', 'anonymous', 'transfer', 'provided', 'allow', 'sending', 'tested', 'indigo', 'binary', 'begun', 'initial', 'target', 'explicit', 'led', 'postscript', 'driver', 'remain', 'replace', 'text', 'posted', 'alan', 'user', 'adobe', 'font', 'freely', 'pattern', 'presently', 'import', 'generic', 'reader', 'turner', 'center', 'land', 'margin', 'graduate', 'properly', 'sample', 'exact', 'economic', 'rail', 'growth', 'traffic', 'understand', 'stop', 'intermediate', 'train', 'twice', 'gas', 'prove', 'proven', 'bed', 'strictly', 'judge', 'condemn', 'satan', 'defeat', 'maybe', 'neat', 'opening', 'brief', 'moment', 'healing', 'rose', 'dead', 'sword', 'flesh', 'compare', 'chose', 'shame', 'false', 'fulfill', 'fate', 'mankind', 'sentence', 'hell', 'refer', 'bush', 'fighting', 'oil', 'plain', 'lee', 'lose', 'police', 'reveal', 'tap', 'positive', 'step', 'relevant', 'federal', 'notify', 'days', 'clause', 'ex', 'showing', 'opposition', 'obviously', 'involve', 'notice', 'competent', 'jurisdiction', 'serving', 'directed', 'select', 'rough', 'min', 'august', 'alliance', 'church', 'slow', 'tad', 'rely', 'recognize', 'differential', 'curiosity', 'aware', 'constantly', 'scan', 'caught', 'guard', 'plan', 'blow', 'assume', 'scary', 'dont', 'fault', 'thats', 'proved', 'ideally', 'supposed', 'passing', 'dumb', 'drew', 'begin', 'mu', 'um', 'truck', 'rode', 'clutch', 'shift', 'lightning', 'quick', 'smooth', 'shifting', 'tin', 'telephone', 'bar', 'unit', 'connection', 'external', 'supply', 'closure', 'summarize', 'query', 'dan', 'math', 'specific', 'os', 'peter', 'defend', 'burning', 'preferred', 'death', 'door', 'credible', 'lie', 'ass', 'convenient', 'plastic', 'share', 'surprising', 'vary', 'information', 'funny', 'latest', 'proclaiming', 'department', 'scroll', 'printing', 'print', 'horizontal', 'bug', 'stated', 'digital', 'corporation', 'project', 'presume', 'idea', 'encryption', 'transmit', 'key', 'cat', 'computer', 'archive', 'login', 'code', 'commonly', 'dictionary', 'meaning', 'wondering', 'extension', 'clue', 'se', 'fi', 'chevy', 'astronomy', 'gif', 'format', 'comfort', 'description', 'connect', 'server', 'patient', 'gopher', 'enjoy', 'walker', 'motorcycle', 'imply', 'investigate', 'previously', 'impossible', 'produce', 'signature', 'measure', 'bound', 'difficult', 'uncomfortable', 'edition', 'theory', 'tissue', 'associated', 'inflammatory', 'response', 'reject', 'stay', 'charter', 'member', 'dying', 'brave', 'international', 'chocolate', 'chips', 'action', 'ultra', 'workshop', 'handle', 'colors', 'color', 'error', 'correctly', 'frequently', 'graphical', 'man', 'listed', 'bibliography', 'corresponding', 'ship', 'moving', 'release', 'environment', 'ported', 'calendar', 'mime', 'contents', 'specification', 'interface', 'buttons', 'resize', 'edit', 'compatible', 'executable', 'conform', 'documentation', 'easiest', 'included', 'division', 'develop', 'application', 'technical', 'similar', 'programmer', 'shell', 'script', 'despite', 'unlike', 'hand', 'receive', 'build', 'year', 'class', 'generate', 'management', 'presumably', 'product', 'ongoing', 'fit', 'commercial', 'sold', 'reasonably', 'volume', 'improving', 'converting', 'essentially', 'badly', 'level', 'functionality', 'simultaneously', 'manual', 'performance', 'suitable', 'remains', 'ordinary', 'party', 'lay', 'interaction', 'map', 'displayed', 'area', 'dragging', 'rectangle', 'arrow', 'derived', 'favorite', 'pin', 'rid', 'button', 'icon', 'alternatively', 'menu', 'click', 'title', 'dismiss', 'pop', 'terminal', 'section', 'input', 'setting', 'configuration', 'depending', 'copy', 'console', 'chuck', 'output', 'executed', 'compliant', 'default', 'root', 'profile', 'near', 'keyboard', 'careful', 'broken', 'strange', 'incorrect', 'warning', 'rarely', 'mouse', 'delay', 'experiment', 'sent', 'higher', 'injection', 'reference', 'differ', 'force', 'welcome', 'drawing', 'memory', 'shooting', 'configure', 'prepared', 'occasional', 'status', 'returned', 'blank', 'boring', 'effective', 'paste', 'adjust', 'short', 'copied', 'crossed', 'insert', 'drag', 'selection', 'pointer', 'cursor', 'holding', 'rifle', 'sight', 'dialogue', 'general', 'opposite', 'direction', 'meta', 'guide', 'listing', 'contain', 'vendor', 'license', 'separate', 'pressing', 'utility', 'publication', 'rendering', 'loading', 'sizes', 'alter', 'cache', 'loaded', 'parameter', 'variable', 'precisely', 'scale', 'entry', 'export', 'creation', 'base', 'frame', 'parent', 'path', 'core', 'suddenly', 'request', 'jumbo', 'undefined', 'link', 'item', 'ending', 'wish', 'space', 'times', 'quit', 'emulator', 'carry', 'authorization', 'ran', 'command', 'bizarre', 'chapter', 'fix', 'security', 'setup', 'disable', 'overnight', 'removing', 'communicate', 'administrator', 'skip', 'pick', 'flash', 'buffer', 'edge', 'property', 'editor', 'sh', 'prefer', 'flat', 'dump', 'actual', 'upgrade', 'soon', 'round', 'domain', 'layout', 'distribution', 'preceding', 'launch', 'altogether', 'satisfy', 'sense', 'vol', 'viewer', 'fish', 'disabled', 'sadly', 'remote', 'shipped', 'selected', 'distributor', 'id', 'effect', 'procedure', 'restart', 'push', 'hole', 'null', 'width', 'specify', 'convenience', 'nasty', 'er', 'wed', 'tue', 'marked', 'plausible', 'monochrome', 'serial', 'normal', 'series', 'frozen', 'companion', 'expanded', 'attribute', 'orange', 'fat', 'journal', 'morris', 'prentice', 'hall', 'miller', 'introduction', 'young', 'implementation', 'composite', 'tutorial', 'square', 'integration', 'paper', 'primarily', 'date', 'jeff', 'rick', 'larry', 'excuse', 'wasting', 'original', 'incident', 'repost', 'wing', 'suggestion', 'predict', 'ba', 'clearly', 'hitter', 'pinch', 'choke', 'basis', 'consistent', 'overall', 'matching', 'equal', 'success', 'swap', 'insult', 'incapable', 'topic', 'indicator', 'possibility', 'repeatedly', 'straightforward', 'honestly', 'debating', 'batting', 'average', 'significantly', 'prediction', 'rule', 'unlikely', 'joe', 'poorly', 'statistical', 'trend', 'league', 'consistency', 'deny', 'unwilling', 'suggest', 'valentine', 'faith', 'maintain', 'atheism', 'usually', 'accurate', 'representation', 'existence', 'skeptical', 'lack', 'creationist', 'disprove', 'evolution', 'establish', 'analogy', 'scientific', 'appearance', 'observation', 'earth', 'pink', 'correspondence', 'physical', 'pointless', 'debate', 'ground', 'phrase', 'clarification', 'defined', 'waste', 'definition', 'incomplete', 'convince', 'inappropriate', 'category', 'logic', 'realm', 'fallacy', 'assumption', 'follow', 'infer', 'assertion', 'concept', 'meaningful', 'naturally', 'conception', 'principle', 'leap', 'form', 'arrogant', 'player', 'season', 'informed', 'observer', 'decent', 'dean', 'permission', 'devoted', 'defence', 'salvation', 'natural', 'focus', 'keeping', 'disk', 'condition', 'track', 'quiet', 'bay', 'classic', 'parse', 'union', 'storage', 'undeclared', 'integer', 'cast', 'henry', 'perform', 'random', 'joint', 'beauty', 'kent', 'accuracy', 'witness', 'probability', 'hollow', 'eyewitness', 'author', 'largely', 'sea', 'strongly', 'reasonable', 'peace', 'strife', 'odds', 'winning', 'straight', 'beating', 'balanced', 'closer', 'record', 'team', 'rally', 'hot', 'room', 'harry', 'losing', 'play', 'summer', 'blown', 'bounce', 'admit', 'brought', 'coach', 'blues', 'deep', 'finish', 'st', 'po', 'lead', 'inflatable', 'outer', 'advertising', 'billboard', 'orbit', 'ozone', 'layer', 'furthermore', 'minimum', 'material', 'literally', 'studied', 'josh', 'pair', 'wore', 'perfect', 'selling', 'instruction', 'lock', 'locking', 'prevent', 'minimal', 'exclusion', 'finger', 'reset', 'fail', 'intense', 'suffering', 'strict', 'obedience', 'alive', 'accordance', 'shall', 'undoubtedly', 'advocate', 'lawful', 'bear', 'gun', 'imagination', 'essence', 'glove', 'accident', 'damages', 'carrying', 'automobile', 'armed', 'swiss', 'irrelevant', 'violent', 'easier', 'suggesting', 'chief', 'legalize', 'unarmed', 'liar', 'crazy', 'spot', 'flawed', 'believing', 'drivel', 'modern', 'mad', 'kept', 'hearing', 'son', 'fool', 'lunatic', 'boot', 'ami', 'bios', 'slip', 'mess', 'burst', 'floppy', 'primary', 'khan', 'sign', 'purchase', 'mailed', 'salesman', 'leather', 'worthless', 'superior', 'auto', 'regret', 'convertible', 'south', 'definitely', 'mailer', 'mon', 'baseball', 'rotation', 'spring', 'split', 'terry', 'divided', 'happy', 'fear', 'politics', 'blood', 'sucking', 'controller', 'height', 'watt', 'finished', 'plug', 'friendly', 'half', 'designing', 'compact', 'sedan', 'sized', 'growing', 'pardon', 'tartar', 'staged', 'struck', 'terror', 'hearts', 'war', 'operating', 'east', 'mercy', 'ease', 'volunteer', 'army', 'severe', 'withdraw', 'filled', 'relatively', 'primitive', 'produced', 'bring', 'usual', 'terrorism', 'existent', 'dictatorship', 'systematic', 'annihilation', 'murdering', 'paragraph', 'interesting', 'brand', 'brick', 'instance', 'century', 'conclude', 'ambassador', 'blooded', 'collaboration', 'erase', 'republic', 'minority', 'protect', 'took', 'turkey', 'liberty', 'fellow', 'exposed', 'alike', 'foreign', 'tradition', 'mathematical', 'tragedy', 'combined', 'separation', 'readily', 'turned', 'men', 'fight', 'civil', 'shaw', 'empire', 'reform', 'revolution', 'rise', 'organized', 'revolt', 'city', 'percent', 'slaughter', 'retreat', 'southern', 'justify', 'territorial', 'russia', 'fulfillment', 'regard', 'beginning', 'decision', 'revolutionary', 'refuse', 'assist', 'participation', 'invasion', 'eastern', 'degree', 'enemy', 'arrival', 'bureau', 'glorious', 'victory', 'flag', 'resurrection', 'protection', 'strike', 'confident', 'reach', 'horizon', 'independence', 'legion', 'flood', 'mid', 'crisis', 'pseudo', 'scholar', 'concentration', 'formed', 'grown', 'architect', 'council', 'berlin', 'endorsed', 'declared', 'super', 'race', 'conspiracy', 'admitted', 'allies', 'decided', 'oppose', 'civilian', 'effectively', 'murder', 'destruction', 'drove', 'scene', 'soldier', 'assigned', 'wired', 'discipline', 'nonsense', 'headquarters', 'spell', 'drawer', 'acting', 'supreme', 'innocent', 'clear', 'reliable', 'confirmed', 'commander', 'rape', 'aged', 'intervene', 'inform', 'specially', 'deliberately', 'burnt', 'apart', 'corps', 'rounded', 'road', 'thrown', 'torn', 'hung', 'hair', 'survive', 'inquisition', 'poverty', 'insane', 'hungry', 'worst', 'stone', 'submit', 'grief', 'meaningless', 'statistic', 'context', 'role', 'ridiculous', 'sat', 'grain', 'drug', 'probable', 'watched', 'abiding', 'lesson', 'tapping', 'supposedly', 'ice', 'equation', 'discovered', 'alright', 'technology', 'age', 'wanting', 'coast', 'stock', 'axe', 'ended', 'clone', 'define', 'feeling', 'exactly', 'nick', 'laboratory', 'mass', 'burn', 'father', 'bastard', 'heat', 'freedom', 'selective', 'soul', 'custom', 'resume', 'package', 'blah', 'sensible', 'objective', 'atom', 'atomic', 'particle', 'behavior', 'annoy', 'sharp', 'arc', 'update', 'bulb', 'heating', 'effects', 'strip', 'magazine', 'sons', 'temperature', 'oxygen', 'brain', 'waiting', 'elevator', 'mirror', 'lobby', 'choosing', 'biggest', 'martin', 'comprehend', 'visit', 'perspective', 'knowledge', 'experience', 'grace', 'aside', 'restricted', 'opt', 'listen', 'voice', 'maximum', 'tolerance', 'doubt', 'glory', 'implication', 'teach', 'sacred', 'taught', 'resort', 'literary', 'subjective', 'falling', 'infallible', 'timothy', 'genuine', 'divine', 'character', 'canon', 'threw', 'protest', 'catholic', 'holy', 'pope', 'learned', 'admittedly', 'warn', 'prophecy', 'tree', 'scripture', 'luke', 'genesis', 'song', 'testament', 'lift', 'spent', 'bolt', 'loose', 'clothes', 'face', 'suck', 'incorporated', 'proposal', 'fund', 'established', 'child', 'born', 'partner', 'citizenship', 'subsequent', 'critical', 'dissemination', 'fashioned', 'married', 'aa', 'bat', 'white', 'secretary', 'summit', 'implement', 'strategic', 'commitment', 'executive', 'reflect', 'congress', 'communist', 'democratic', 'unnecessarily', 'ordered', 'congressional', 'proceed', 'weigh', 'revision', 'remedy', 'eager', 'legislation', 'assured', 'trust', 'institution', 'committee', 'thorough', 'sensitive', 'improve', 'range', 'accelerated', 'nuclear', 'elimination', 'defense', 'seven', 'reduction', 'outlined', 'addition', 'accelerate', 'ban', 'early', 'consult', 'employed', 'comprehensive', 'enhance', 'stability', 'collision', 'ready', 'discuss', 'avoid', 'minister', 'late', 'prepare', 'authorized', 'inter', 'consideration', 'agenda', 'specifically', 'assemble', 'assistance', 'homosexuality', 'lev', 'pagan', 'surrounding', 'interact', 'sides', 'lord', 'dear', 'tired', 'finding', 'invite', 'bless', 'shuttle', 'rated', 'sophisticated', 'attack', 'basically', 'noted', 'failure', 'simulation', 'typically', 'loving', 'spencer', 'zoology', 'board', 'advice', 'ben', 'engineering', 'origin', 'black', 'spreading', 'gospel', 'band', 'poster', 'bookstore', 'frequent', 'jacket', 'felt', 'orthodox', 'slightly', 'drink', 'german', 'beer', 'steven', 'crew', 'foul', 'physicist', 'concentrated', 'galactic', 'phenomena', 'scattered', 'universe', 'cloud', 'energy', 'solar', 'parallax', 'bright', 'string', 'planetary', 'overly', 'star', 'attend', 'grandfather', 'treat', 'mary', 'cole', 'newsletter', 'gonorrhea', 'colorado', 'comparison', 'continued', 'report', 'analysis', 'disease', 'whites', 'proportional', 'highest', 'county', 'represent', 'sexually', 'syndrome', 'field', 'staff', 'gang', 'self', 'heterosexual', 'homosexual', 'family', 'virtually', 'fourth', 'ka', 'ne', 'surveillance', 'div', 'prevention', 'editorial', 'stable', 'explanation', 'sexual', 'outbreak', 'resistant', 'activity', 'hypothesis', 'examine', 'exchange', 'substantially', 'risk', 'variation', 'newspaper', 'promote', 'awareness', 'peer', 'educational', 'forum', 'community', 'cocaine', 'ann', 'healthy', 'promotion', 'effectiveness', 'injury', 'impact', 'adult', 'belt', 'restraint', 'motor', 'reduce', 'crash', 'usage', 'association', 'household', 'survey', 'module', 'representative', 'calculate', 'confidence', 'significant', 'island', 'secondary', 'enforcement', 'mandatory', 'violation', 'passenger', 'criteria', 'reportedly', 'consistently', 'chi', 'versus', 'declined', 'chronic', 'employ', 'exhibit', 'traveling', 'income', 'emphasize', 'likelihood', 'fatal', 'childhood', 'dis', 'transportation', 'highway', 'dot', 'assessment', 'progress', 'increasing', 'chapel', 'seat', 'hunt', 'triangle', 'voluntary', 'geographic', 'misuse', 'york', 'broad', 'birth', 'prevalence', 'collection', 'diagnostic', 'regional', 'alcohol', 'hip', 'diagnosis', 'pregnancy', 'unknown', 'environmental', 'exposure', 'gene', 'bases', 'jane', 'nancy', 'march', 'virus', 'weekly', 'statistics', 'index', 'identification', 'received', 'unusual', 'subsequently', 'importance', 'annual', 'inclusion', 'director', 'agency', 'toxic', 'organization', 'cox', 'clinical', 'monthly', 'copyright', 'tube', 'sperm', 'art', 'reproduction', 'resolved', 'realistic', 'exclusively', 'genetic', 'linked', 'considerable', 'professor', 'college', 'transferred', 'atmospheric', 'ensure', 'gift', 'occasionally', 'accomplished', 'utilize', 'costly', 'mild', 'male', 'comparable', 'incidence', 'limit', 'outcome', 'quality', 'cycle', 'opportunity', 'recognition', 'decrease', 'investigating', 'determined', 'proportion', 'accountable', 'recourse', 'contrast', 'excess', 'patent', 'technique', 'reducing', 'benefit', 'albeit', 'total', 'ethical', 'practical', 'combination', 'sub', 'barrier', 'inherent', 'chosen', 'packet', 'ax', 'honda', 'dealership', 'generation', 'japan', 'throw', 'password', 'generator', 'adopt', 'secure', 'riding', 'beat', 'helmet', 'wearing', 'smart', 'tire', 'fortunately', 'anecdotal', 'experienced', 'rider', 'gear', 'mechanic', 'registration', 'reserve', 'insure', 'liability', 'mileage', 'visiting', 'shopping', 'dod', 'device', 'priced', 'efficient', 'brett', 'collins', 'electronics', 'considering', 'communication', 'mobile', 'spectrum', 'kim', 'court', 'recording', 'ham', 'charge', 'hey', 'dealt', 'busy', 'nutrition', 'vitamin', 'kidney', 'magnesium', 'forming', 'suit', 'calcium', 'emphasis', 'amino', 'acid', 'production', 'dietary', 'intake', 'formation', 'dose', 'supplementation', 'speculation', 'route', 'diet', 'providing', 'instant', 'coffee', 'sweet', 'worry', 'protein', 'extended', 'coupled', 'presence', 'block', 'supplement', 'ratio', 'literature', 'pain', 'suffer', 'biochemistry', 'chairman', 'discourse', 'learning', 'wise', 'china', 'blanket', 'censorship', 'wrap', 'revealed', 'revealing', 'authentication', 'register', 'infinite', 'intent', 'ideology', 'importantly', 'hypothetical', 'gains', 'perry', 'nominal', 'fee', 'buggy', 'colour', 'polygon', 'robust', 'interlaced', 'refresh', 'poly', 'remind', 'sitting', 'rocket', 'correction', 'theistic', 'inspired', 'adequately', 'ate', 'bias', 'champaign', 'animation', 'raster', 'rapidly', 'rewrite', 'considerably', 'protocol', 'plane', 'client', 'ha', 'particularly', 'telling', 'spiritual', 'guilt', 'declare', 'shadow', 'gaining', 'devil', 'repent', 'saved', 'silent', 'lest', 'silence', 'prayer', 'demanding', 'horrible', 'practiced', 'motive', 'woman', 'disorder', 'abuse', 'mention', 'mechanism', 'female', 'resulting', 'concentrate', 'incredibly', 'perverse', 'gay', 'foot', 'honest', 'clean', 'semiconductor', 'gap', 'electron', 'visible', 'heck', 'narrow', 'solid', 'electronic', 'science', 'advertise', 'plenty', 'forgotten', 'chip', 'nifty', 'scholarly', 'praying', 'fallen', 'soil', 'happily', 'historic', 'revisionism', 'financial', 'governmental', 'diplomatic', 'contemporary', 'terrorist', 'systematically', 'wall', 'collapse', 'consequently', 'supportive', 'heinous', 'officially', 'adopted', 'unreliable', 'pursuit', 'necessity', 'risen', 'politically', 'mature', 'conscious', 'ranging', 'manuscript', 'victim', 'grew', 'inside', 'engaged', 'cannon', 'thermal', 'afternoon', 'kerosene', 'buried', 'bus', 'underground', 'engage', 'conversation', 'knowing', 'knock', 'raid', 'grenade', 'warrant', 'sealed', 'armor', 'throwing', 'safely', 'ring', 'bats', 'career', 'peak', 'pocket', 'pete', 'soft', 'curious', 'sooner', 'vastly', 'si', 'assuming', 'killing', 'explaining', 'stein', 'repentance', 'turning', 'unbelievable', 'fundamental', 'alas', 'giving', 'unto', 'wipe', 'cattle', 'severely', 'cried', 'verse', 'essential', 'grasp', 'firmly', 'carpenter', 'symbol', 'ignore', 'critique', 'behaviour', 'praise', 'sounding', 'forgiveness', 'sin', 'wisdom', 'justice', 'randy', 'architecture', 'duo', 'processor', 'depth', 'federally', 'propaganda', 'industry', 'reasoned', 'worthy', 'bell', 'imagine', 'surge', 'electricity', 'assure', 'yelling', 'lawn', 'howling', 'closely', 'clearing', 'observing', 'feared', 'intervention', 'intention', 'nationality', 'prison', 'smell', 'courtesy', 'tammy', 'stamp', 'aim', 'retain', 'uncommon', 'virtual', 'handy', 'identical', 'boulder', 'hubble', 'clip', 'cradle', 'angle', 'array', 'gamma', 'ray', 'observatory', 'explosive', 'partially', 'cruise', 'missile', 'standing', 'pound', 'originally', 'instrument', 'explorer', 'fuse', 'palmer', 'bird', 'sincerely', 'kit', 'lifetime', 'concerning', 'warranty', 'logos', 'mathematics', 'electrical', 'mellon', 'ave', 'pa', 'circuit', 'sing', 'loud', 'libertarian', 'speech', 'cite', 'rock', 'privacy', 'expression', 'battle', 'quietly', 'grip', 'societal', 'comment', 'scout', 'wood', 'credibility', 'cigarette', 'questionable', 'faced', 'lantern', 'possibly', 'mouth', 'clothing', 'accidentally', 'lying', 'screw', 'weak', 'dole', 'senate', 'backed', 'stimulus', 'tear', 'relation', 'inch', 'visual', 'lunar', 'exploration', 'crystal', 'conference', 'explore', 'hotel', 'federation', 'noon', 'morning', 'sessions', 'operational', 'mission', 'era', 'lunch', 'guest', 'speaker', 'assistant', 'technological', 'value', 'annoying', 'quantum', 'noisy', 'viola', 'ditto', 'pitcher', 'manage', 'grad', 'student', 'school', 'ford', 'discount', 'photo', 'mustang', 'oracle', 'recover', 'phoenix', 'lotus', 'additional', 'ide', 'apparently', 'parity', 'mother', 'ram', 'leaves', 'dark', 'paint', 'shop', 'truly', 'eric', 'obtain', 'grey', 'obscure', 'zero', 'dig', 'gray', 'vat', 'tracing', 'democracy', 'savior', 'cross', 'pure', 'mel', 'commit', 'ist', 'absolute', 'morality', 'theism', 'correlated', 'irrational', 'tab', 'productive', 'poor', 'infected', 'sake', 'indirectly', 'unique', 'creature', 'behave', 'saint', 'mortal', 'progression', 'earthly', 'evil', 'casting', 'tail', 'revelation', 'speaking', 'thou', 'laid', 'scenario', 'sheep', 'theology', 'harmony', 'sarcasm', 'convinced', 'oriental', 'terminology', 'theological', 'acknowledge', 'faculty', 'da', 'intellectually', 'cap', 'stove', 'revolver', 'pistol', 'trigger', 'cock', 'hammer', 'slide', 'capacity', 'sphere', 'radius', 'circle', 'distant', 'infinity', 'diameter', 'intersection', 'algorithm', 'fly', 'sand', 'semi', 'qualified', 'valve', 'cylinder', 'specs', 'indirect', 'wire', 'banning', 'willingly', 'professional', 'trip', 'rubber', 'beneath', 'brilliant', 'headed', 'crowd', 'ball', 'ignition', 'tune', 'allan', 'painful', 'execution', 'punishment', 'electric', 'chair', 'integral', 'wet', 'distorted', 'tale', 'cracking', 'examining', 'capacitor', 'roughly', 'metal', 'cage', 'numerous', 'elect', 'yale', 'hopefully', 'rich', 'expand', 'youth', 'chemistry', 'water', 'chemical', 'laser', 'dry', 'printer', 'yesterday', 'goalie', 'chin', 'cool', 'awesome', 'panther', 'conflicting', 'rocky', 'horror', 'carl', 'slot', 'scanner', 'adapter', 'connector', 'expansion', 'plugged', 'immoral', 'cancer', 'floating', 'greed', 'ruin', 'ascii', 'broadcast', 'prone', 'ethic', 'corrected', 'intend', 'dale', 'murphy', 'june', 'ut', 'paradise', 'divinity', 'truelove', 'leftover', 'flaming', 'pizza', 'hut', 'ken', 'valuable', 'column', 'cooling', 'blessed', 'notion', 'legitimate', 'wont', 'titled', 'translation', 'booklet', 'minor', 'extraordinary', 'authority', 'ye', 'wind', 'shine', 'warm', 'palm', 'daily', 'king', 'mere', 'suicide', 'absence', 'tank', 'thirty', 'smoke', 'weather', 'balloon', 'cleaner', 'evangelical', 'precious', 'consensus', 'terribly', 'waving', 'habit', 'magic', 'medieval', 'wedding', 'fresh', 'movie', 'fascinating', 'survival', 'relevance', 'holocaust', 'racist', 'fought', 'vast', 'espionage', 'fifth', 'atlantic', 'alarm', 'clock', 'wasted', 'microwave', 'zip', 'farm', 'profit', 'huge', 'suspicious', 'blinking', 'overhead', 'enable', 'active', 'distributed', 'feedback', 'attached', 'forgetting', 'collect', 'silly', 'react', 'differently', 'thread', 'phenomenon', 'sir', 'swapping', 'temporarily', 'parallel', 'confused', 'pass', 'excessive', 'gravity', 'curve', 'finite', 'crossing', 'geometry', 'analogous', 'deter', 'warren', 'goddard', 'teel', 'concrete', 'everyday', 'legally', 'sufficiently', 'burden', 'merit', 'applicable', 'employee', 'ruling', 'thereof', 'confess', 'thoroughly', 'favor', 'promptly', 'invoke', 'amendment', 'evasion', 'framework', 'outlaw', 'plate', 'wallet', 'salt', 'prejudice', 'ing', 'refute', 'jail', 'amend', 'filing', 'delta', 'clipper', 'orbital', 'atmosphere', 'nose', 'mistake', 'initially', 'acceptable', 'dual', 'overtime', 'tied', 'garage', 'dad', 'charging', 'basement', 'dirt', 'station', 'jump', 'discharge', 'moisture', 'cell', 'composition', 'tendency', 'slowly', 'subjected', 'stress', 'comfortable', 'powder', 'pine', 'oak', 'maple', 'magnitude', 'removal', 'sink', 'corner', 'hello', 'viper', 'fancy', 'sensor', 'radar', 'independently', 'zone', 'walk', 'neighbor', 'roll', 'amin', 'construction', 'hat', 'arrest', 'interestingly', 'canal', 'weird', 'rent', 'membership', 'cryptography', 'break', 'classified', 'crack', 'approve', 'surely', 'bond', 'pull', 'tiny', 'northern', 'circular', 'comet', 'levy', 'switched', 'vertical', 'motion', 'uniform', 'smoothly', 'dependent', 'plant', 'extend', 'frank', 'premise', 'virgin', 'patently', 'mistaken', 'pertaining', 'capital', 'adultery', 'qualify', 'preaching', 'manipulate', 'verify', 'obey', 'weight', 'selfish', 'consequence', 'dispute', 'ranch', 'cleansing', 'aid', 'immune', 'believer', 'dial', 'tony', 'credit', 'sports', 'ballot', 'socket', 'campus', 'experimental', 'bulletin', 'sport', 'pit', 'discriminate', 'cynical', 'impression', 'spectacular', 'sky', 'mag', 'arrive', 'alignment', 'spec', 'dramatic', 'norm', 'central', 'handling', 'improvement', 'premium', 'ought', 'sola', 'ceremonial', 'binding', 'backing', 'disagreement', 'genius', 'sporting', 'beg', 'propose', 'equally', 'republican', 'tyranny', 'cop', 'exhaust', 'raw', 'destroy', 'span', 'yard', 'transmission', 'converter', 'tu', 'outright', 'falsehood', 'useless', 'solely', 'restrict', 'resent', 'accelerator', 'quadra', 'arms', 'pilot', 'lucky', 'san', 'fashion', 'estimate', 'beth', 'ama', 'restoration', 'manufacturer', 'developer', 'grand', 'testify', 'sequence', 'celebrate', 'convention', 'palace', 'banquet', 'payment', 'intensive', 'veteran', 'strategy', 'platform', 'shoot', 'pledge', 'compromise', 'ceremony', 'dragon', 'inn', 'fiction', 'smith', 'famous', 'sam', 'drum', 'comic', 'dining', 'tie', 'celebration', 'housing', 'admission', 'match', 'federalist', 'submission', 'casual', 'movement', 'lamb', 'sandy', 'dodge', 'rand', 'upcoming', 'audio', 'adoption', 'vice', 'judicial', 'scare', 'ga', 'substance', 'fanatic', 'accepted', 'pile', 'playback', 'nicely', 'dynamic', 'capture', 'clarify', 'arm', 'fuzzy', 'breakdown', 'gathering', 'clips', 'compressed', 'archer', 'photography', 'purely', 'organic', 'dimensional', 'covering', 'iron', 'mystery', 'complex', 'taste', 'pad', 'sol', 'streets', 'revenge', 'golden', 'dropping', 'jay', 'counter', 'condemnation', 'chastity', 'intellect', 'shameful', 'surrender', 'bone', 'massive', 'goal', 'scored', 'walsh', 'snow', 'aggressive', 'tournament', 'approximately', 'vaginal', 'optical', 'wright', 'gee', 'laughter', 'guessing', 'tract', 'shrink', 'dogs', 'trained', 'damn', 'leaf', 'weekend', 'glad', 'jerry', 'brown', 'condemned', 'crucial', 'invisible', 'corporate', 'revenue', 'constitutional', 'raising', 'investment', 'marginal', 'fell', 'veal', 'lately', 'label', 'echo', 'literal', 'prompt', 'satellite', 'fuel', 'streak', 'moderate', 'calculated', 'ai', 'schematic', 'yea', 'worn', 'blasting', 'firing', 'bother', 'tactics', 'attorney', 'blowing', 'intercept', 'reversed', 'verification', 'operation', 'protecting', 'missing', 'subtle', 'competitive', 'conventional', 'enforce', 'eliminate', 'accomplish', 'automatic', 'pump', 'shotgun', 'neck', 'detect', 'dim', 'flow', 'ohm', 'inflammation', 'accurately', 'trick', 'slave', 'beta', 'distance', 'leaning', 'detector', 'ta', 'briefing', 'dee', 'camp', 'unclear', 'desk', 'lifting', 'embargo', 'potentially', 'announcement', 'humanitarian', 'relief', 'distinguished', 'privately', 'recommendation', 'complicated', 'cabinet', 'conclusive', 'option', 'exception', 'conduct', 'vulnerable', 'outline', 'meant', 'announce', 'happening', 'advisory', 'formal', 'outrage', 'confirmation', 'routinely', 'dozen', 'retired', 'personnel', 'difficulty', 'ranger', 'bullet', 'investigation', 'overview', 'legislative', 'flying', 'garden', 'wagon', 'wheel', 'arbitrary', 'bicycle', 'widespread', 'domestic', 'touring', 'interstate', 'depression', 'steering', 'cam', 'touched', 'shaft', 'racing', 'handled', 'regulated', 'transformer', 'transistor', 'failing', 'switching', 'pulse', 'linear', 'regulation', 'inductive', 'stretch', 'gross', 'fort', 'unaware', 'comply', 'crawl', 'historically', 'compassion', 'confuse', 'alternate', 'declaration', 'guarantee', 'consent', 'civilization', 'academy', 'dignity', 'territory', 'abroad', 'defamation', 'allegedly', 'conflict', 'founding', 'leadership', 'neighboring', 'skin', 'democrat', 'remarkable', 'massacre', 'flew', 'briefly', 'helicopter', 'militia', 'sue', 'surprise', 'damage', 'facing', 'roger', 'talent', 'pitch', 'offense', 'shifter', 'gate', 'em', 'rice', 'parking', 'dirty', 'absurd', 'flexible', 'shack', 'novel', 'resistance', 'microphone', 'distortion', 'measurement', 'leg', 'expose', 'consist', 'relativism', 'straw', 'preferable', 'absurdity', 'tactical', 'escrow', 'steal', 'cipher', 'hostage', 'discovery', 'encrypt', 'stolen', 'listening', 'aircraft', 'backup', 'desert', 'navy', 'fold', 'enlighten', 'reliability', 'promiscuous', 'mutual', 'scanning', 'impressive', 'obsolete', 'rumor', 'classes', 'acquire', 'continually', 'regulate', 'adjective', 'labor', 'expense', 'succeed', 'modify', 'harsh', 'grammar', 'caliber', 'firearm', 'joining', 'flip', 'forth', 'animated', 'zoom', 'touch', 'memorial', 'scheme', 'wonderful', 'eh', 'wage', 'pace', 'hour', 'club', 'silicon', 'offensive', 'spare', 'trunk', 'compatibility', 'reverse', 'engineer', 'rime', 'tempest', 'supplier', 'asp', 'arbor', 'grade', 'apologize', 'intelligent', 'upset', 'contradict', 'attendance', 'nail', 'nowadays', 'locked', 'tape', 'television', 'legend', 'beast', 'objection', 'decode', 'preclude', 'mandate', 'successfully', 'runner', 'shade', 'butt', 'asleep', 'channel', 'batter', 'ted', 'relate', 'bloody', 'ammunition', 'explode', 'bulk', 'velocity', 'wound', 'ar', 'ya', 'lewis', 'dram', 'victor', 'symbolic', 'destination', 'beck', 'hacker', 'deluxe', 'printed', 'spelling', 'methodology', 'electromagnetic', 'magnetic', 'elaborate', 'tracer', 'incompatible', 'priest', 'atheist', 'wit', 'integrity', 'scriptural', 'deserve', 'marry', 'alert', 'individually', 'remotely', 'orchid', 'unhappy', 'bitch', 'graphite', 'hash', 'rep', 'vector', 'testing', 'blessing', 'searching', 'ti', 'fantastic', 'rolling', 'port', 'sit', 'regime', 'slavery', 'settle', 'modeling', 'knowledgeable', 'slick', 'genie', 'das', 'dull', 'rubbed', 'wooden', 'studio', 'opposing', 'clark', 'offset', 'secondly', 'scoring', 'handler', 'render', 'sac', 'convex', 'pyramid', 'notebook', 'diverse', 'lisp', 'avenue', 'suite', 'maxima', 'batch', 'numerical', 'grove', 'derive', 'corp', 'specialized', 'recovery', 'computational', 'gnu', 'theoretical', 'mi', 'fraction', 'elementary', 'usable', 'turbo', 'anon', 'pleasant', 'arithmetic', 'informal', 'matrix', 'rank', 'jordan', 'characteristic', 'manipulation', 'evaluation', 'calculation', 'abandoned', 'bag', 'marc', 'tea', 'registered', 'intestinal', 'lan', 'kernel', 'troy', 'suspected', 'wow', 'scope', 'tobacco', 'lance', 'writer', 'moon', 'painted', 'booster', 'marketing', 'mar', 'pollution', 'seldom', 'pastor', 'baptism', 'validity', 'teeth', 'surviving', 'hired', 'heavily', 'mormon', 'luxury', 'es', 'river', 'adaptor', 'rebuild', 'jimmy', 'concealed', 'billing', 'triumph', 'veto', 'bullock', 'floor', 'bodily', 'rush', 'boss', 'kelly', 'compression', 'mounting', 'forgot', 'teaching', 'consultant', 'static', 'introduce', 'eternity', 'torture', 'reconcile', 'moderator', 'hierarchy', 'temporary', 'manually', 'preferably', 'ge', 'redirect', 'seemingly', 'unlimited', 'likewise', 'permanent', 'powered', 'loan', 'combine', 'maximize', 'spark', 'shaped', 'coil', 'propulsion', 'diesel', 'torque', 'ideal', 'trek', 'beam', 'radioactive', 'reactor', 'converted', 'steam', 'naval', 'unified', 'distinct', 'continuous', 'boundary', 'economics', 'decline', 'harmful', 'rain', 'mining', 'quantity', 'gasoline', 'captain', 'rotate', 'beloved', 'tiger', 'decade', 'treating', 'attitude', 'randomly', 'graphic', 'threat', 'nervous', 'afraid', 'trail', 'dust', 'heresy', 'mixed', 'walking', 'danger', 'tyre', 'wounded', 'bomb', 'explosion', 'sank', 'affiliation', 'abu', 'village', 'marine', 'shortly', 'flee', 'extensive', 'constant', 'fishing', 'illegally', 'authoritative', 'collected', 'compensation', 'alpha', 'bottle', 'gut', 'ah', 'mechanical', 'ni', 'discover', 'medium', 'ross', 'objectively', 'eclipse', 'testimony', 'grave', 'tomb', 'reward', 'billion', 'inexpensive', 'encourage', 'dream', 'liter', 'horsepower', 'whats', 'jack', 'roof', 'teacher', 'award', 'riley', 'senator', 'stage', 'join', 'funds', 'bailey', 'innovative', 'cutting', 'molecular', 'formally', 'honor', 'tremendous', 'redesign', 'ultimate', 'accord', 'wa', 'mo', 'pitching', 'winter', 'tribe', 'pi', 'liberation', 'episode', 'sig', 'carter', 'michigan', 'plot', 'dishonest', 'openly', 'ignorance', 'district', 'estate', 'expert', 'compelling', 'butler', 'precise', 'ward', 'crap', 'fraud', 'distribute', 'trivial', 'subscribe', 'arrogance', 'pointing', 'reasoning', 'judgment', 'grounds', 'suppress', 'affair', 'arose', 'ludicrous', 'rejection', 'pretend', 'conceivable', 'audience', 'proving', 'baker', 'objectivity', 'subjectively', 'attach', 'helping', 'essay', 'validate', 'rotating', 'popularity', 'nut', 'weapon', 'operator', 'unreasonable', 'pet', 'toss', 'toilet', 'flammable', 'lawyer', 'washed', 'drinking', 'exotic', 'exciting', 'receiver', 'probe', 'voyager', 'trajectory', 'cosmic', 'antibiotic', 'paradox', 'cure', 'bacteria', 'medication', 'myth', 'species', 'disaster', 'airplane', 'ruth', 'philosophy', 'dynamics', 'nearby', 'clever', 'loop', 'silver', 'toner', 'desirable', 'gold', 'interior', 'cellular', 'prohibit', 'steer', 'acceleration', 'hawk', 'sheet', 'football', 'classical', 'thesis', 'interrupt', 'io', 'directional', 'inspiration', 'task', 'apostle', 'righteousness', 'rex', 'unnecessary', 'ala', 'crying', 'lethal', 'inning', 'infamous', 'catalogue', 'libertarianism', 'forbidden', 'satanic', 'sampling', 'laugh', 'pants', 'sermon', 'simplicity', 'smoking', 'stomach', 'entertaining', 'fundamentalist', 'younger', 'meat', 'dubious', 'morally', 'instinctive', 'interfering', 'manufacture', 'hunting', 'inherently', 'nye', 'resident', 'alien', 'prize', 'mentally', 'marriage', 'locally', 'replay', 'slight', 'struggling', 'corvette', 'nickname', 'shielded', 'sticker', 'documentary', 'pot', 'bowl', 'wod', 'anger', 'lust', 'pride', 'secular', 'agent', 'walter', 'fake', 'corrupt', 'quest', 'cellar', 'phase', 'adjustment', 'confirm', 'thief', 'intellectual', 'global', 'elite', 'ego', 'satisfaction', 'theft', 'proprietary', 'controversial', 'actively', 'reputation', 'creative', 'crop', 'relay', 'impedance', 'grounding', 'duration', 'snail', 'prime', 'sweep', 'stick', 'racial', 'tiff', 'hasan', 'shouting', 'cook', 'emergency', 'apartment', 'husband', 'kitchen', 'soccer', 'awful', 'dressed', 'mamma', 'balcony', 'frightened', 'sticks', 'courtyard', 'uncle', 'ambulance', 'tan', 'calm', 'bury', 'surrounded', 'coat', 'stayed', 'investigator', 'baku', 'intentional', 'bare', 'relative', 'border', 'busted', 'remark', 'increasingly', 'contract', 'supporter', 'ignite', 'pushing', 'stupidity', 'carrier', 'thy', 'freeze', 'sunlight', 'acquired', 'killer', 'exercise', 'intentionally', 'occupation', 'ignorant', 'violence', 'achieve', 'disregard', 'covenant', 'translate', 'lasting', 'contradiction', 'cute', 'ashamed', 'condemning', 'traditionally', 'significance', 'stream', 'intensity', 'brightness', 'el', 'blaster', 'liturgy', 'tactic', 'evidently', 'satisfied', 'neighborhood', 'stack', 'inferior', 'incarnation', 'dogma', 'behold', 'possessed', 'mystical', 'invent', 'passage', 'spoke', 'commandment', 'spoken', 'exodus', 'lean', 'advised', 'daughter', 'naked', 'gather', 'resist', 'knife', 'consciousness', 'cloth', 'wounds', 'confrontation', 'tipped', 'suspended', 'peacefully', 'strength', 'lighter', 'boost', 'fired', 'magnum', 'antenna', 'timer', 'beware', 'vacuum', 'scaled', 'proceeds', 'extract', 'ink', 'scholarship', 'valued', 'approximate', 'convincing', 'theist', 'agnostic', 'void', 'junk', 'camera', 'gore', 'troop', 'landed', 'earl', 'rub', 'cod', 'lousy', 'confusion', 'formula', 'momentum', 'removed', 'prince', 'nerve', 'compliance', 'dimension', 'unfair', 'structural', 'refusal', 'fixing', 'threatening', 'voting', 'barry', 'enjoyment', 'acceptance', 'personality', 'enjoying', 'obligation', 'equality', 'discrimination', 'odometer', 'maintenance', 'humble', 'paraphrase', 'blindly', 'overwhelming', 'behalf', 'mix', 'nope', 'passive', 'acquisition', 'customer', 'gant', 'beef', 'umpire', 'instructed', 'shoulder', 'score', 'ninth', 'constructive', 'blamed', 'defensive', 'puck', 'feeding', 'contribution', 'cordially', 'envelope', 'attractive', 'baud', 'sector', 'wash', 'glass', 'tour', 'seal', 'settlement', 'sought', 'terrible', 'deputy', 'gunfire', 'fled', 'assault', 'noble', 'observable', 'washer', 'spike', 'peripheral', 'rookie', 'firm', 'hepatitis', 'repair', 'underestimate', 'possess', 'composed', 'reserved', 'lastly', 'grow', 'invade', 'shutout', 'whichever', 'ref', 'evolutionary', 'theme', 'creationism', 'yo', 'involvement', 'queen', 'speculate', 'liver', 'elevated', 'serum', 'gilbert', 'diagram', 'synchronous', 'asynchronous', 'advise', 'reaching', 'hypotheses', 'abstract', 'sexuality', 'gulf', 'begging', 'debt', 'cheating', 'forwards', 'graph', 'chart', 'iso', 'booth', 'kingdom', 'cartridge', 'publish', 'viking', 'log', 'generalization', 'finder', 'viewpoint', 'mounted', 'scaling', 'texture', 'impulse', 'academic', 'concise', 'geometric', 'spline', 'vertices', 'vertex', 'header', 'tar', 'pen', 'nearest', 'visualization', 'slice', 'availability', 'transform', 'contour', 'iris', 'pacific', 'conditional', 'cad', 'bye', 'modification', 'compute', 'infinitely', 'excel', 'encounter', 'astronomical', 'enhancement', 'fluid', 'transport', 'macro', 'partition', 'film', 'approval', 'airport', 'rod', 'promising', 'filling', 'analyze', 'proton', 'compiler', 'grass', 'miscellaneous', 'principal', 'component', 'median', 'suffice', 'infrared', 'rodney', 'winner', 'bure', 'trophy', 'celestial', 'informative', 'correcting', 'hub', 'accidental', 'bedroom', 'construct', 'repository', 'skipjack', 'triple', 'mailbox', 'rising', 'rev', 'govern', 'draft', 'smokeless', 'marijuana', 'dip', 'incidentally', 'illusion', 'penalty', 'portable', 'amplifier', 'detection', 'balance', 'grounded', 'empirical', 'relativist', 'hatching', 'definite', 'stiff', 'deer', 'sho', 'curt', 'giant', 'adjacent', 'trident', 'ho', 'permit', 'inflated', 'civic', 'golf', 'jake', 'founder', 'sleeping', 'operate', 'pal', 'beach', 'grab', 'eating', 'angry', 'milk', 'brains', 'earn', 'deliver', 'salary', 'ownership', 'governor', 'acknowledged', 'employment', 'corruption', 'hooked', 'bobby', 'pie', 'aluminum', 'ruined', 'armored', 'blast', 'substitute', 'aero', 'buck', 'divide', 'permanently', 'puzzle', 'howl', 'starter', 'buyer', 'cargo', 'thumb', 'forgive', 'horn', 'pickup', 'dick', 'treaty', 'ethnic', 'utterly', 'artillery', 'rental', 'ceiling', 'deck', 'tennis', 'recreational', 'vacation', 'jersey', 'delegation', 'refuge', 'hoped', 'immaculate', 'whatsoever', 'asthma', 'tommy', 'tone', 'efficiency', 'protestant', 'telescope', 'sheer', 'timing', 'volt', 'shorter', 'blaming', 'emission', 'quarter', 'liquid', 'conscience', 'susceptible', 'distinguish', 'radiation', 'yield', 'industrial', 'colt', 'contention', 'foreground', 'disturbing', 'wade', 'infield', 'roster', 'fielder', 'chlorine', 'dominance', 'darn', 'flaw', 'accounting', 'brutal', 'restore', 'minded', 'execute', 'persecution', 'sum', 'pregnant', 'practically', 'trinity', 'inner', 'bowman', 'rating', 'evident', 'misleading', 'disappear', 'reflected', 'lazy', 'pleasure', 'righteous', 'psalm', 'wicked', 'fisher', 'damned', 'forever', 'supernatural', 'temp', 'entertainment', 'inability', 'babe', 'billy', 'rickey', 'morgan', 'mediocre', 'researcher', 'doc', 'brad', 'stern', 'boots', 'ladies', 'dragged', 'skull', 'sticking', 'publicity', 'additionally', 'seth', 'digest', 'cripple', 'conductor', 'coin', 'deadline', 'aka', 'dominated', 'deserved', 'octopus', 'den', 'frankly', 'congregation', 'profound', 'simpler', 'barely', 'marvel', 'stadium', 'freshman', 'firstly', 'siege', 'improper', 'justification', 'bull', 'artist', 'neutral', 'governing', 'ethics', 'wealthy', 'eve', 'headache', 'cooking', 'flavor', 'officer', 'quarterly', 'transaction', 'ride', 'farther', 'brake', 'unbreakable', 'cryptographic', 'combat', 'threaten', 'automotive', 'preliminary', 'pedal', 'modest', 'flush', 'cease', 'reliably', 'exceed', 'sliding', 'panic', 'stickers', 'induced', 'hart', 'warrior', 'lens', 'dominant', 'yeast', 'infection', 'bogus', 'fungal', 'diarrhea', 'therapy', 'psychological', 'placebo', 'systemic', 'distress', 'budget', 'barlow', 'allocation', 'surgical', 'universally', 'di', 'contest', 'sixth', 'resistor', 'discrete', 'minimize', 'abandon', 'fin', 'referee', 'slap', 'skate', 'razor', 'welfare', 'peaceful', 'collective', 'respective', 'brush', 'senior', 'patriot', 'nights', 'evening', 'fork', 'tall', 'unfortunate', 'complaint', 'intact', 'perceive', 'punish', 'factual', 'emerge', 'grateful', 'wrapped', 'buddy', 'inconsistent', 'funded', 'micro', 'helpless', 'ribbon', 'shalt', 'compress', 'extreme', 'charity', 'relativity', 'tor', 'cryptanalysis', 'bent', 'complexity', 'correlation', 'issuing', 'laying', 'inserted', 'gender', 'oral', 'hull', 'beneficial', 'assembly', 'consortium', 'leak', 'hanging', 'pipe', 'transparent', 'allocate', 'treasury', 'periodically', 'seminar', 'accessible', 'publicly', 'subscription', 'locate', 'administrative', 'variant', 'naming', 'sensitivity', 'frog', 'secrecy', 'constitute', 'feasible', 'shelf', 'mainly', 'ear', 'technically', 'tragic', 'deadly', 'enormous', 'restrictive', 'abort', 'disclosure', 'ruler', 'joy', 'carbon', 'navigation', 'craft', 'breath', 'civilized', 'strive', 'rational', 'outrageous', 'irony', 'swing', 'tongue', 'fame', 'handgun', 'proposition', 'fitted', 'infante', 'ample', 'landing', 'sponsor', 'midnight', 'kyle', 'engaging', 'polite', 'inquiry', 'altitude', 'tuned', 'horse', 'parkway', 'cheese', 'shock', 'rolled', 'bow', 'illness', 'suspension', 'yep', 'trap', 'shield', 'luckily', 'coherent', 'mack', 'sinful', 'bend', 'fantasy', 'wealth', 'hazard', 'toll', 'museum', 'corrupted', 'toy', 'mysterious', 'char', 'swear', 'knight', 'infant', 'ambiguous', 'implicitly', 'idiot', 'courage', 'limitation', 'mineral', 'doesnt', 'bore', 'forced', 'pose', 'bearing', 'naive', 'token', 'mice', 'screaming', 'embassy', 'royal', 'turk', 'drill', 'mixture', 'rapid', 'solvent', 'valley', 'belonging', 'graham', 'promise', 'storm', 'cardinal', 'exempt', 'compilation', 'verdict', 'lend', 'deity', 'paranoia', 'cruel', 'sail', 'wi', 'courier', 'dramatically', 'web', 'willie', 'gator', 'kindly', 'hero', 'col', 'determination', 'neutron', 'ammo', 'forecast', 'heavens', 'jumper', 'assets', 'chicken', 'telephony', 'hood', 'educate', 'opponent', 'desperate', 'breast', 'sympathy', 'unauthorized', 'lawfully', 'negotiate', 'kirk', 'providence', 'weakness', 'philosopher', 'macroevolution', 'galaxy', 'bread', 'gentile', 'mat', 'tenth', 'circumcision', 'abolish', 'motto', 'boulevard', 'twin', 'dividing', 'assign', 'spatial', 'sacrifice', 'possession', 'concussion', 'shading', 'counting', 'overcome', 'postal', 'permitted', 'moderately', 'trace', 'synthesis', 'alias', 'madman', 'mechanics', 'brute', 'insulation', 'franklin', 'glucose', 'psychology', 'continental', 'publisher', 'oscillator', 'handbook', 'excited', 'obliged', 'homicide', 'attacker', 'tortured', 'felony', 'discredit', 'quack', 'dentist', 'organism', 'arise', 'happiness', 'lawsuit', 'invariably', 'virtue', 'surplus', 'sided', 'destructive', 'spy', 'arena', 'scrutiny', 'costing', 'retail', 'pioneer', 'lesser', 'reluctant', 'thyroid', 'minus', 'apology', 'neal', 'goddess', 'easter', 'transition', 'facilitate', 'trading', 'vague', 'utter', 'loudly', 'cobra', 'holder', 'frost', 'confined', 'album', 'jerk', 'jeep', 'coalition', 'ordnance', 'baseman', 'hose', 'entity', 'dictate', 'concede', 'invalid', 'folk', 'examination', 'mosque', 'accuse', 'emotionally', 'oath', 'fortune', 'rationale', 'cream', 'unworthy', 'ritual', 'chunk', 'compass', 'partial', 'simplistic', 'karma', 'denial', 'pursuant', 'sweeping', 'junior', 'nonetheless', 'willingness', 'bumper', 'rescue', 'assassination', 'dance', 'separately', 'suspicion', 'guitar', 'rack', 'pan', 'controversy', 'benjamin', 'heading', 'cope', 'championship', 'venture', 'strawberry', 'orientation', 'rhetoric', 'foam', 'counsel', 'prohibition', 'sinner', 'circa', 'awe', 'sect', 'fruit', 'seeking', 'patience', 'manifest', 'bridge', 'reed', 'foolish', 'herd', 'muscle', 'dyer', 'mitre', 'accused', 'criticize', 'standoff', 'preference', 'eighty', 'urge', 'identity', 'astrophysics', 'racism', 'lecture', 'educated', 'prong', 'breaker', 'duke', 'eligible', 'abusive', 'bath', 'soup', 'sinus', 'axes', 'axis', 'extremist', 'bathroom', 'clement', 'powerless', 'aviation', 'tip', 'bold', 'contempt', 'generating', 'interfere', 'outstanding', 'cal', 'consulting', 'sustained', 'lied', 'doctrinal', 'creed', 'theoretically', 'contradictory', 'eighth', 'fence', 'solder', 'maria', 'spin', 'franchise', 'cape', 'tension', 'dell', 'divorce', 'specialist', 'cruiser', 'motivation', 'junction', 'lung', 'deficiency', 'bind', 'homer', 'faithful', 'persuade', 'perish', 'colored', 'measured', 'sec', 'organ', 'stroke', 'copper', 'warsaw', 'dock', 'drunk', 'skill', 'ak', 'fleet', 'spinning', 'arrangement', 'inevitable', 'deficit', 'freeman', 'examiner', 'tables', 'asteroid', 'servant', 'shred', 'inclination', 'dress', 'bench', 'fleury', 'otto', 'howe', 'schneider', 'depressed', 'needing', 'exclude', 'amusing', 'bitter', 'lovely', 'launcher', 'lone', 'precedent', 'pity', 'closet', 'monster', 'certified', 'lo', 'reporter', 'entrance', 'swallow', 'emotion', 'uprising', 'ghetto', 'polish', 'respectable', 'tag', 'disguised', 'proclaim', 'meal', 'hatred', 'bid', 'grandmother', 'strap', 'corolla', 'node', 'emulation', 'ether', 'weasel', 'newly', 'saga', 'vincent', 'rabid', 'spider', 'incredible', 'hulk', 'omega', 'wolverine', 'hobgoblin', 'bagged', 'mint', 'mason', 'lighting', 'unlawful', 'traps', 'escort', 'continuously', 'creator', 'priesthood', 'shelling', 'goods', 'philosophical', 'chase', 'warfare', 'removable', 'brent', 'dislike', 'interstellar', 'crown', 'confidential', 'conveniently', 'propane', 'catcher', 'whiten', 'bite', 'bass', 'limiting', 'neural', 'bloom', 'sanders', 'cluster', 'pig', 'demon', 'refusing', 'defective', 'bishop', 'rotational', 'midst', 'cracked', 'throughput', 'throttle', 'nelson', 'dominate', 'sa', 'seed', 'guidance', 'equate', 'twist', 'bigotry', 'transferring', 'lemon', 'pork', 'extracted', 'restaurant', 'segment', 'shake', 'cord', 'resign', 'breathing', 'cooler', 'adda', 'wainwright', 'mae', 'overdrive', 'thee', 'rigorous', 'passionate', 'redraw', 'ton', 'bang', 'lame', 'designer', 'wolf', 'occasion', 'retrieve', 'descent', 'heritage', 'assess', 'smuggling', 'deg', 'cement', 'pole', 'dawn', 'inspector', 'bo', 'inference', 'scorer', 'jean', 'clockwise', 'almanac', 'halo', 'adjustable', 'intercourse', 'neb', 'prosecution', 'crush', 'modular', 'disappointment', 'shamir', 'cubic', 'phi', 'gradually', 'incoming', 'defensively', 'consume', 'jury', 'las', 'frightening', 'approaching', 'hath', 'hypocritical', 'insulting', 'inspection', 'outward', 'pending', 'ow', 'septuagint', 'thrust', 'overseas', 'survivor', 'basketball', 'surgeon', 'polar', 'twisted', 'chromium', 'diabetes', 'weaver', 'frontier', 'trillion', 'petty', 'faulty', 'fossil', 'bayonet', 'thine', 'spence', 'sensed', 'omniscient', 'gauge', 'griffin', 'unconditional', 'zinc', 'shower', 'hawking', 'analyst', 'trapped', 'hemisphere', 'malaria', 'coli', 'malpractice', 'bait', 'ocean', 'wrath', 'swift', 'quantitative', 'boxer', 'conner', 'anonymity', 'onset', 'migraine', 'noll', 'pale', 'diagonal', 'iniquity', 'timor', 'argentine', 'superman', 'retinol', 'fetus', 'evolve', 'secession', 'vaccine', 'pom', 'crossroads', 'magi']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD8CAYAAACcjGjIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIVlBxERKTC/wfv4ueBslo/vgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bd81499198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load master dictionary\n",
    "words_df = pd.DataFrame(pd.read_csv(\"all_words.csv\"))\n",
    "\n",
    "words_df.head()\n",
    "\n",
    "all_words = words_df['word']\n",
    "freq = words_df['frequency']\n",
    "\n",
    "# rebuild master dictionary object\n",
    "master_dictionary = {all_words[i] : freq[i] for i in range(len(freq))}\n",
    "\n",
    "print(max(freq))\n",
    "\n",
    "# feature frequency range to be set here\n",
    "max_allowed_freq = max(freq)\n",
    "min_allowed_freq = 20\n",
    "\n",
    "# plot histogram just for fun\n",
    "filtered_freq = [f for f in freq if (f <= max_allowed_freq and f >= min_allowed_freq)]\n",
    "print(len(filtered_freq))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(filtered_freq, 50)\n",
    "plt.show()\n",
    "\n",
    "# ignore\n",
    "too_common_words = [word for word in master_dictionary if master_dictionary[word] > max_allowed_freq]\n",
    "print(\"No. of common words : \", len(too_common_words))\n",
    "\n",
    "\n",
    "# ignore\n",
    "too_rare_words = [word for word in master_dictionary if master_dictionary[word] < min_allowed_freq]\n",
    "print(\"No. of rare words : \", len(too_rare_words))\n",
    "#print(too_rare_words)\n",
    "\n",
    "\"\"\"\n",
    "Visualize the range of frequencies of selected words \n",
    "\"\"\"\n",
    "import matplotlib.pyplot as plt\n",
    "Y_freq = freq[freq >= min_allowed_freq]\n",
    "Y_freq = Y_freq[Y_freq <= max_allowed_freq]\n",
    "plt.plot(np.sort(Y_freq))\n",
    "plt.show()\n",
    "\n",
    "selected_words = [word for word in all_words \n",
    "                  if master_dictionary[word] >= min_allowed_freq \n",
    "                  and master_dictionary[word] <= max_allowed_freq \n",
    "                  and type(word) == str \n",
    "                  and len(word) > 1]\n",
    "\n",
    "#for word in keys:\n",
    "#    if freq\n",
    "print(len(selected_words))\n",
    "print(selected_words)\n",
    "\n",
    "selected_words_freq = [master_dictionary[word] for word in selected_words]\n",
    "plt.plot(np.sort(selected_words_freq))\n",
    "plt.show()\n",
    "\n",
    "selected_words_df = pd.DataFrame()\n",
    "selected_words_df['word'] = selected_words\n",
    "selected_words_df['frequency'] = selected_words_freq\n",
    "\n",
    "\"\"\"\n",
    "selected words are words chosen as features from the master dictionary\n",
    "\"\"\"\n",
    "selected_words_df.to_csv('selected_words.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 Files Processed in 5.654 sec\n",
      "2000 Files Processed in 5.748 sec\n",
      "3000 Files Processed in 5.086 sec\n",
      "4000 Files Processed in 5.518 sec\n",
      "5000 Files Processed in 7.31 sec\n",
      "6000 Files Processed in 6.513 sec\n",
      "7000 Files Processed in 5.832 sec\n",
      "8000 Files Processed in 6.113 sec\n",
      "9000 Files Processed in 6.313 sec\n",
      "10000 Files Processed in 6.166 sec\n",
      "11000 Files Processed in 6.309 sec\n",
      "12000 Files Processed in 6.4 sec\n",
      "13000 Files Processed in 6.273 sec\n",
      "14000 Files Processed in 7.615 sec\n",
      "(14997, 5427)\n",
      "(14997,)\n",
      "1000 Files Processed in 4.692 sec\n",
      "2000 Files Processed in 4.993 sec\n",
      "3000 Files Processed in 5.651 sec\n",
      "4000 Files Processed in 6.395 sec\n",
      "5000 Files Processed in 6.832 sec\n",
      "(5000, 5427)\n",
      "(5000,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "Build Dataset of word counts as features\n",
    "\"\"\"\n",
    "def prepare_dataset(selected_words_file_path, data_files_path):\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    \n",
    "    # load class dict\n",
    "    class_dict_df = pd.DataFrame(pd.read_csv(\"class_dict.csv\"))\n",
    "    #class_dict_df.head()\n",
    "\n",
    "    # load selected words dictionary\n",
    "    #selected_words_df = pd.DataFrame(pd.read_csv('all_words.csv'))\n",
    "    selected_words_df = pd.DataFrame(pd.read_csv(selected_words_file_path))\n",
    "    #selected_words_df.head()\n",
    "\n",
    "    selected_words = selected_words_df['word'].values\n",
    "    \n",
    "    selected_words_dictionary = {word : True for word in selected_words}\n",
    "    \n",
    "    \n",
    "    #number of selected words\n",
    "    num_selected_words = len(selected_words)\n",
    "\n",
    "    #load file containing document paths\n",
    "    data_file_paths_df = pd.DataFrame(pd.read_csv(data_files_path))\n",
    "    #data_file_paths_df.head()\n",
    "\n",
    "    data_file_paths = data_file_paths_df['path'].values\n",
    "    \n",
    "    #directly used as target Y\n",
    "    data_file_class = data_file_paths_df['class'].values\n",
    "\n",
    "    import time\n",
    "    matrix = []\n",
    "    st = time.time()\n",
    "    for i in range(len(data_file_paths)) :\n",
    "        #if i == 2000:\n",
    "        #    break\n",
    "    \n",
    "        if (i+1) % 1000 == 0 :\n",
    "            et = time.time()\n",
    "            print( i+1, \"Files Processed in\", round((time.time() - st), 3) , \"sec\")\n",
    "            st = time.time()    \n",
    "        path = data_file_paths[i]\n",
    "        target = data_file_class[i]\n",
    "        with open(path) as file :\n",
    "            X = []\n",
    "            count = {}\n",
    "            data = file.readlines()\n",
    "            words_in_file = (''.join(data)).split(' ')\n",
    "            for word in words_in_file:\n",
    "                try:\n",
    "                    if selected_words_dictionary[word]:\n",
    "                        # try catch approach for fast search\n",
    "                        try:\n",
    "                            count[word] += 1\n",
    "                        except:\n",
    "                            count[word] = 1\n",
    "                except:\n",
    "                    continue\n",
    "            for word in selected_words:\n",
    "                # try catch approach for fast search\n",
    "                try :\n",
    "                    X = count[word] \n",
    "                except :\n",
    "                    count[word] = 0 \n",
    "            #print(X)\n",
    "            X = [count[word] for word in selected_words if word in count] \n",
    "            #print(len(X))\n",
    "            matrix.append(X)\n",
    "            #X_train_df.iloc[i, :] = \n",
    "            file.close()\n",
    "    #print(len(matrix))\n",
    "    #print(len(matrix[0]))\n",
    "\n",
    "    X_df = pd.DataFrame(matrix, columns = selected_words)\n",
    "\n",
    "    #X_df.describe()\n",
    "\n",
    "    import copy\n",
    "    X = X_df.values\n",
    "    Y = copy.deepcopy(data_file_class)\n",
    "    print(X.shape)\n",
    "    print(Y.shape)\n",
    "\n",
    "    dataset_df = pd.DataFrame(X_df)\n",
    "    dataset_df['target'] = Y\n",
    "    return dataset_df\n",
    "\n",
    "train_files_path = \"train_files.csv\"\n",
    "test_files_path = \"test_files.csv\"\n",
    "\n",
    "selected_words_file_path = 'selected_words.csv'\n",
    "\n",
    "train_dataset_df = prepare_dataset(selected_words_file_path, train_files_path)\n",
    "train_dataset_df.to_csv(\"20_newsgroups_dataset_min_freq_20.csv\", index = False)\n",
    "\n",
    "test_dataset_df = prepare_dataset(selected_words_file_path, test_files_path)\n",
    "test_dataset_df.to_csv(\"20_newsgroups_test_dataset_min_freq_20.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Time for Training Set: 14226 millisecond\n",
      "Loading Time for Test Set: 4568 millisecond\n",
      "Training Time: 8739 millisecond\n",
      "Prediction Time for Training Set: 8215 millisecond\n",
      "Confusion Matrix for Training Dataset\n",
      "array([[640,   2,   5,  13,   5,   5,   4,   6,   3,   3,   8,  10,   7,\n",
      "          5,   3,   8,   3,   5,  20,  12],\n",
      "       [  1, 676,   3,   8,   6,   6,  11,   7,   1,   4,   4,   5,   5,\n",
      "         11,   1,   4,   5,   4,   3,   1],\n",
      "       [  0,   2, 625,   7,   1, 111,   2,   2,   7,  17,   0,   3,   3,\n",
      "          8,   3,   2,  18,   5,   3,   1],\n",
      "       [  0,   2,   3, 625,   2,   7,   5,   3,   4,   7,   5,   2,   5,\n",
      "          1,   0,   3,   7,   6,   2,   2],\n",
      "       [ 10,   3,   3,   3, 591,   5,  23,  11,   1,   0,  31,  41,   3,\n",
      "          0,   1,  34,   2,  31,   8,   7],\n",
      "       [  2,   4,  54,  10,   1, 484,   2,   5,  59,  12,   3,   2,   5,\n",
      "         14,   0,   3,  10,   1,   3,   2],\n",
      "       [  5,   3,   1,   8,  14,   3, 609,   9,   2,   1,   9,   4,   5,\n",
      "          3,   2,   5,   2,   8,  13,   2],\n",
      "       [  1,   6,   4,   4,  12,   3,  12, 577,   0,   3,   7,   5,   4,\n",
      "          6,   0,  27,   3,  46,   2,   0],\n",
      "       [  2,   8,  10,   4,   0,  49,   2,   3, 566,   7,   1,   6,   9,\n",
      "         19,   2,   2,  24,   2,   3,   1],\n",
      "       [  3,   3,  14,   5,   1,  15,   0,   3,   4, 661,   0,   3,   3,\n",
      "          1,   1,   2,   5,   2,   1,   2],\n",
      "       [  7,   5,   2,   6,  39,   2,  25,  16,   3,   2, 618,  28,   5,\n",
      "          2,   4,  20,   5,  16,   4,   5],\n",
      "       [ 12,   5,   2,   7,  24,   2,  11,  20,   4,   2,  20, 565,   9,\n",
      "          4,   5,  15,   5,  21,  10,   6],\n",
      "       [  2,   0,   4,   5,   3,   5,   5,   6,   4,   2,   5,   5, 651,\n",
      "          4,   2,   6,   3,   8,   7,   1],\n",
      "       [  4,   9,  11,   6,   3,  35,   0,   1,  35,   4,   1,   3,   2,\n",
      "        650,   2,   4,  10,   4,   6,   7],\n",
      "       [  5,   6,   6,  10,   4,   6,   5,   7,   6,   6,   6,  15,   5,\n",
      "          7, 709,  14,   7,   7,   8,  31],\n",
      "       [  1,  12,   1,   3,  20,   3,  11,  35,   1,   5,  25,  15,   7,\n",
      "          2,   2, 572,   3,  47,   0,   2],\n",
      "       [  3,   3,  10,   4,   2,  11,   3,   0,  30,   5,   2,   2,   3,\n",
      "          6,   1,   1, 591,   1,   1,   3],\n",
      "       [  3,  12,   2,  11,  20,   5,  11,  47,   2,   1,  11,   6,   9,\n",
      "          0,   2,  24,   1, 522,   3,   6],\n",
      "       [  9,   1,   1,   2,   5,   3,   8,   1,   4,   2,   4,  12,   9,\n",
      "          4,   1,   2,   4,   1, 626,   4],\n",
      "       [  6,   5,   6,   3,   7,   4,   7,   1,   5,   1,   4,   7,   5,\n",
      "          4,  28,   3,  11,  10,   8, 657]], dtype=int64)\n",
      "classification Report for Training Dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.83      0.86       767\n",
      "          1       0.88      0.88      0.88       766\n",
      "          2       0.81      0.76      0.79       820\n",
      "          3       0.84      0.90      0.87       691\n",
      "          4       0.78      0.73      0.75       808\n",
      "          5       0.63      0.72      0.67       676\n",
      "          6       0.81      0.86      0.83       708\n",
      "          7       0.76      0.80      0.78       722\n",
      "          8       0.76      0.79      0.77       720\n",
      "          9       0.89      0.91      0.90       729\n",
      "         10       0.81      0.76      0.78       814\n",
      "         11       0.76      0.75      0.76       749\n",
      "         12       0.86      0.89      0.88       728\n",
      "         13       0.87      0.82      0.84       797\n",
      "         14       0.92      0.81      0.87       870\n",
      "         15       0.76      0.75      0.75       767\n",
      "         16       0.82      0.87      0.84       682\n",
      "         17       0.70      0.75      0.72       698\n",
      "         18       0.86      0.89      0.87       703\n",
      "         19       0.87      0.84      0.86       782\n",
      "\n",
      "avg / total       0.82      0.81      0.81     14997\n",
      "\n",
      "Prediction Time for Testing Set: 2967 millisecond\n",
      "2.9670658111572266\n",
      "Confusion Matrix for Test Dataset\n",
      "array([[205,   3,   4,   5,   3,   0,   7,   0,   2,   1,   1,  12,   4,\n",
      "          0,   1,   6,   3,   5,  17,   6],\n",
      "       [  5, 190,   2,   3,   4,   1,   4,   9,   4,   1,   4,   1,   0,\n",
      "          5,   0,  10,   5,   3,   3,   0],\n",
      "       [  1,   2, 132,   3,   0,  61,   1,   1,   3,  15,   0,   1,   3,\n",
      "          4,   2,   1,  12,   3,   3,   1],\n",
      "       [  3,   2,   2, 192,   0,   2,   2,   4,   4,   2,   0,   0,   6,\n",
      "          1,   2,   2,   2,   4,   2,   3],\n",
      "       [  2,   0,   1,   1, 144,   3,  14,   6,   4,   1,  34,  13,   0,\n",
      "          0,   2,  24,   2,  12,   4,   1],\n",
      "       [  1,   2,  45,   6,   1,  85,   1,   1,  28,  22,   2,   0,   4,\n",
      "          9,   1,   0,   9,   2,   3,   0],\n",
      "       [  8,   1,   1,   2,  11,   0, 140,   4,   1,   1,   6,  13,   8,\n",
      "          0,   1,   4,   0,   1,  16,   1],\n",
      "       [  1,   1,   1,   1,   3,   1,   3, 134,   0,   1,   3,   0,   3,\n",
      "          0,   0,  19,   1,  12,   2,   2],\n",
      "       [  6,  11,  11,   7,   0,  28,   1,   0, 140,   6,   0,   6,   5,\n",
      "         34,   4,   2,  31,   1,   7,   6],\n",
      "       [  1,   0,   6,   0,   0,  20,   1,   0,   4, 182,   0,   0,   0,\n",
      "          2,   1,   1,   4,   0,   1,   1],\n",
      "       [  4,   2,   1,   3,  27,   2,  16,   8,   2,   1, 145,  19,   2,\n",
      "          0,   1,  18,   3,   8,   8,   0],\n",
      "       [  7,   2,   2,   5,  11,   3,  11,   8,   2,   3,  16, 130,   1,\n",
      "          3,   2,   8,   6,   6,   6,   6],\n",
      "       [  2,   2,   3,   7,   0,   2,  10,   7,   4,   4,   1,   6, 184,\n",
      "          0,   0,   4,   0,   7,   0,   3],\n",
      "       [  5,   8,   8,   5,   0,  13,   0,   0,  25,   1,   0,   6,   3,\n",
      "        171,   3,   0,   4,   1,   6,   3],\n",
      "       [  2,   1,   1,   2,   2,   1,   2,   6,   3,   3,   3,   9,   2,\n",
      "          5, 183,   5,   1,   5,   2,  23],\n",
      "       [  2,   3,   1,   1,  22,   2,   5,  16,   1,   1,  16,   5,   2,\n",
      "          2,   2, 126,   2,  30,   2,   1],\n",
      "       [  2,   1,   8,   6,   1,   6,   0,   1,  26,   4,   0,   4,   3,\n",
      "          7,   1,   1, 194,   0,   1,   3],\n",
      "       [  0,   2,   1,   4,   9,   1,  14,  29,   2,   1,   3,  13,   5,\n",
      "          0,   1,  18,   0, 148,   1,   2],\n",
      "       [ 22,   0,   2,   3,   1,   3,   8,   4,   4,   1,   1,  16,   5,\n",
      "          4,   3,   0,   0,   1, 182,   1],\n",
      "       [  5,   0,   1,   0,   1,   2,   4,   2,   0,   1,   1,   7,   6,\n",
      "          2,  21,   0,   2,   4,   3, 185]], dtype=int64)\n",
      "classification Report for Test Dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72       285\n",
      "          1       0.82      0.75      0.78       254\n",
      "          2       0.57      0.53      0.55       249\n",
      "          3       0.75      0.82      0.78       235\n",
      "          4       0.60      0.54      0.57       268\n",
      "          5       0.36      0.38      0.37       222\n",
      "          6       0.57      0.64      0.60       219\n",
      "          7       0.56      0.71      0.63       188\n",
      "          8       0.54      0.46      0.50       306\n",
      "          9       0.72      0.81      0.76       224\n",
      "         10       0.61      0.54      0.57       270\n",
      "         11       0.50      0.55      0.52       238\n",
      "         12       0.75      0.75      0.75       246\n",
      "         13       0.69      0.65      0.67       262\n",
      "         14       0.79      0.70      0.74       261\n",
      "         15       0.51      0.52      0.51       242\n",
      "         16       0.69      0.72      0.71       269\n",
      "         17       0.58      0.58      0.58       254\n",
      "         18       0.68      0.70      0.69       261\n",
      "         19       0.75      0.75      0.75       247\n",
      "\n",
      "avg / total       0.64      0.64      0.64      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# coding: utf-8\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# load training dataset\n",
    "import time\n",
    "st = time.time()\n",
    "train_dataset_df = pd.read_csv(\"20_newsgroups_dataset_min_freq_20.csv\")\n",
    "et = time.time()\n",
    "\n",
    "print(\"Loading Time for Training Set:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "train_dataset_df.describe()\n",
    "\n",
    "X_train_df = train_dataset_df.drop('target', axis = 1) \n",
    "Y_train_df = train_dataset_df['target']\n",
    "\n",
    "# X_train_df.describe()\n",
    "\n",
    "# Y_train_df.describe()\n",
    "\n",
    "# load testing dataset\n",
    "import time\n",
    "st = time.time()\n",
    "test_dataset_df = pd.read_csv(\"20_newsgroups_test_dataset_min_freq_20.csv\")\n",
    "et = time.time()\n",
    "\n",
    "print(\"Loading Time for Test Set:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "test_dataset_df.describe()\n",
    "\n",
    "X_test_df = test_dataset_df.drop('target', axis = 1)\n",
    "Y_test_df = test_dataset_df['target']\n",
    "\n",
    "# X_test_df.describe()\n",
    "\n",
    "# Y_test_df.describe()\n",
    "\n",
    "words = X_train_df.columns\n",
    "#print(words)\n",
    "possible_classes = list(set(Y_train_df.values))\n",
    "#print(possible_classes)\n",
    "\n",
    "# predict class for single document\n",
    "def predict_single(X, model) :\n",
    "    \n",
    "    # initial max class probablity, and assigned class\n",
    "    max_class_prob = -np.inf\n",
    "    max_class = None\n",
    "    # all possible classes\n",
    "    possible_classes = model.keys()\n",
    "    # find probablities of this document belonging to each of the possible classes \n",
    "    for y in possible_classes :\n",
    "        # convert input array to numpy array in case it isn't\n",
    "        X = np.array(X)\n",
    "        \n",
    "        # assign class prior\n",
    "        prob_X_equals_x_given_Y_equals_y = model[y]['class_prior']\n",
    "        # multinomial feature probability addition to get probability \n",
    "        # that this document belongs to current class\n",
    "        prob_X_equals_x_given_Y_equals_y += (X * model[y]['log_prob_sum']).sum()\n",
    "        \n",
    "        # if prob is max update max_class variables\n",
    "        if prob_X_equals_x_given_Y_equals_y > max_class_prob :\n",
    "            max_class_prob = prob_X_equals_x_given_Y_equals_y\n",
    "            max_class = y\n",
    "    return max_class\n",
    "\n",
    "\"\"\"\n",
    "Internal function\n",
    "generate_model takes as input a dictionary and \n",
    "a tuning parameter alpha that accounts for probability correction(similar to the inbuilt classifer)\n",
    "\"\"\"\n",
    "def generate_model(dictionary, alpha) :\n",
    "    model = {}\n",
    "    possible_classes = dictionary['possible_classes']\n",
    "    num_words = dictionary[\"vocabulary_size\"]\n",
    "    \n",
    "    range_words = range(num_words)\n",
    "    \n",
    "    for y in possible_classes :\n",
    "        #class_prior\n",
    "        model[y] = {}\n",
    "        prob_Y_equals_y = np.log(dictionary[y][\"class_count\"]/dictionary[\"total_data\"])\n",
    "        prob_X_equals_x_given_Y_equals_y = 0 \n",
    "        prob_X_equals_x_given_Y_equals_y += prob_Y_equals_y\n",
    "        total_words_in_class_y_docs = dictionary[y][\"total_words\"]        \n",
    "        count_f_class_y = np.array([dictionary[y][f] for f in range_words])\n",
    "        prob_f_class_y = (count_f_class_y+alpha)/(total_words_in_class_y_docs + alpha*num_words) \n",
    "        \n",
    "        model[y]['class_prior'] = prob_Y_equals_y\n",
    "        model[y]['log_prob_sum'] = np.log(prob_f_class_y)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "\n",
    "def predict(X, model) :\n",
    "    #if not isinstance(X[0], list) :\n",
    "    #    return None #predict_single(X, model)\n",
    "    Y_pred = []\n",
    "    for x in X :\n",
    "        Y_pred.append(predict_single(x, model))\n",
    "    return Y_pred\n",
    "\n",
    "\"\"\"\n",
    "fit function takes as input the trainig dataset and alpha, the tuning parameter\n",
    "\"\"\"\n",
    "def fit(X, Y, alpha) :\n",
    "    # check if alpha is in range of [0, 1]\n",
    "    # if not set alpha to 1\n",
    "    if alpha > 1 or alpha < 0 :\n",
    "        print(\"Alpha parameter not in range [0,1]...\")\n",
    "        print(\"setting alpha = 1\")\n",
    "        alpha = 1\n",
    "    num_words = len(X[0])\n",
    "    possible_classes = list(set(Y))\n",
    "    \n",
    "    #dictionary with keys as possible classes, total number of training documents, vocabulary size\n",
    "    dictionary = {}\n",
    "    dictionary[\"total_data\"] = len(Y)\n",
    "    dictionary[\"vocabulary_size\"] = num_words\n",
    "    dictionary[\"possible_classes\"] = possible_classes\n",
    "    \n",
    "    # build internal dictionaries for each of the possible classes\n",
    "    # dict mapped to each class contains keys: \n",
    "    # total words and \n",
    "    # a class count that is the total number of training documents belonging to current class \n",
    "    \n",
    "    for y in possible_classes :\n",
    "        y_dict = {i : X[Y == y, i].sum() for i in range(num_words)}\n",
    "        y_dict['total_words'] = sum(y_dict.values())\n",
    "        y_dict['class_count'] = sum(Y == y)\n",
    "        #print(y_dict['total_count'])\n",
    "        dictionary[y] = y_dict\n",
    "    # call is made to generate model function that uses the \"dictionary\" and \n",
    "    # alpha \n",
    "    # to find effect on probabilities of a document belonging to a particular class\n",
    "    # separate function for simplicity\n",
    "    return generate_model(dictionary, alpha)\n",
    "\n",
    "# fit the model\n",
    "import time\n",
    "st = time.time()\n",
    "model = fit(X_train_df.values, Y_train_df.values, 0.01)\n",
    "et = time.time()\n",
    "\n",
    "print(\"Training Time:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "#print(model)\n",
    "\n",
    "\"\"\"\n",
    "Train Data Evaluation\n",
    "\"\"\"\n",
    "import time\n",
    "st = time.time()\n",
    "Y_train_pred = predict(X_train_df.values, model)\n",
    "et = time.time()\n",
    "\n",
    "print(\"Prediction Time for Training Set:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "#print(Y_train_pred)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"Confusion Matrix for Training Dataset\")\n",
    "pprint(confusion_matrix(Y_train_pred, Y_train_df.values))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"classification Report for Training Dataset\")\n",
    "print(classification_report(Y_train_pred, Y_train_df.values))\n",
    "\n",
    "\"\"\"\n",
    "Test Data Evaluation\n",
    "\"\"\"\n",
    "import time\n",
    "st = time.time()\n",
    "Y_test_pred = predict(X_test_df.values, model)\n",
    "et = time.time()\n",
    "\n",
    "print(\"Prediction Time for Testing Set:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "training_time = (et-st)\n",
    "print(training_time)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from pprint import pprint\n",
    "print(\"Confusion Matrix for Test Dataset\")\n",
    "pprint(confusion_matrix(Y_test_pred, Y_test_df.values))\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"classification Report for Test Dataset\")\n",
    "print(classification_report(Y_test_pred, Y_test_df.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Time: 842 millisecond\n",
      "Prediction Time for Training Set: 631 millisecond\n",
      "Confusion Matrix for Training Dataset\n",
      "array([[640,   2,   5,  13,   5,   5,   4,   6,   3,   3,   8,  10,   7,\n",
      "          5,   3,   8,   3,   5,  20,  12],\n",
      "       [  1, 676,   3,   8,   6,   6,  11,   7,   1,   4,   4,   5,   5,\n",
      "         11,   1,   4,   5,   4,   3,   1],\n",
      "       [  0,   2, 625,   7,   1, 111,   2,   2,   7,  17,   0,   3,   3,\n",
      "          8,   3,   2,  18,   5,   3,   1],\n",
      "       [  0,   2,   3, 625,   2,   7,   5,   3,   4,   7,   5,   2,   5,\n",
      "          1,   0,   3,   7,   6,   2,   2],\n",
      "       [ 10,   3,   3,   3, 591,   5,  23,  11,   1,   0,  31,  41,   3,\n",
      "          0,   1,  34,   2,  31,   8,   7],\n",
      "       [  2,   4,  54,  10,   1, 484,   2,   5,  59,  12,   3,   2,   5,\n",
      "         14,   0,   3,  10,   1,   3,   2],\n",
      "       [  5,   3,   1,   8,  14,   3, 609,   9,   2,   1,   9,   4,   5,\n",
      "          3,   2,   5,   2,   8,  13,   2],\n",
      "       [  1,   6,   4,   4,  12,   3,  12, 577,   0,   3,   7,   5,   4,\n",
      "          6,   0,  27,   3,  46,   2,   0],\n",
      "       [  2,   8,  10,   4,   0,  49,   2,   3, 566,   7,   1,   6,   9,\n",
      "         19,   2,   2,  24,   2,   3,   1],\n",
      "       [  3,   3,  14,   5,   1,  15,   0,   3,   4, 661,   0,   3,   3,\n",
      "          1,   1,   2,   5,   2,   1,   2],\n",
      "       [  7,   5,   2,   6,  39,   2,  25,  16,   3,   2, 618,  28,   5,\n",
      "          2,   4,  20,   5,  16,   4,   5],\n",
      "       [ 12,   5,   2,   7,  24,   2,  11,  20,   4,   2,  20, 565,   9,\n",
      "          4,   5,  15,   5,  21,  10,   6],\n",
      "       [  2,   0,   4,   5,   3,   5,   5,   6,   4,   2,   5,   5, 651,\n",
      "          4,   2,   6,   3,   8,   7,   1],\n",
      "       [  4,   9,  11,   6,   3,  35,   0,   1,  35,   4,   1,   3,   2,\n",
      "        650,   2,   4,  10,   4,   6,   7],\n",
      "       [  5,   6,   6,  10,   4,   6,   5,   7,   6,   6,   6,  15,   5,\n",
      "          7, 709,  14,   7,   7,   8,  31],\n",
      "       [  1,  12,   1,   3,  20,   3,  11,  35,   1,   5,  25,  15,   7,\n",
      "          2,   2, 572,   3,  47,   0,   2],\n",
      "       [  3,   3,  10,   4,   2,  11,   3,   0,  30,   5,   2,   2,   3,\n",
      "          6,   1,   1, 591,   1,   1,   3],\n",
      "       [  3,  12,   2,  11,  20,   5,  11,  47,   2,   1,  11,   6,   9,\n",
      "          0,   2,  24,   1, 522,   3,   6],\n",
      "       [  9,   1,   1,   2,   5,   3,   8,   1,   4,   2,   4,  12,   9,\n",
      "          4,   1,   2,   4,   1, 626,   4],\n",
      "       [  6,   5,   6,   3,   7,   4,   7,   1,   5,   1,   4,   7,   5,\n",
      "          4,  28,   3,  11,  10,   8, 657]], dtype=int64)\n",
      "classification Report for Training Dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.89      0.83      0.86       767\n",
      "          1       0.88      0.88      0.88       766\n",
      "          2       0.81      0.76      0.79       820\n",
      "          3       0.84      0.90      0.87       691\n",
      "          4       0.78      0.73      0.75       808\n",
      "          5       0.63      0.72      0.67       676\n",
      "          6       0.81      0.86      0.83       708\n",
      "          7       0.76      0.80      0.78       722\n",
      "          8       0.76      0.79      0.77       720\n",
      "          9       0.89      0.91      0.90       729\n",
      "         10       0.81      0.76      0.78       814\n",
      "         11       0.76      0.75      0.76       749\n",
      "         12       0.86      0.89      0.88       728\n",
      "         13       0.87      0.82      0.84       797\n",
      "         14       0.92      0.81      0.87       870\n",
      "         15       0.76      0.75      0.75       767\n",
      "         16       0.82      0.87      0.84       682\n",
      "         17       0.70      0.75      0.72       698\n",
      "         18       0.86      0.89      0.87       703\n",
      "         19       0.87      0.84      0.86       782\n",
      "\n",
      "avg / total       0.82      0.81      0.81     14997\n",
      "\n",
      "Prediction Time for Test Set: 235 millisecond\n",
      "Confusion Matrix for Test Dataset\n",
      "array([[205,   3,   4,   5,   3,   0,   7,   0,   2,   1,   1,  12,   4,\n",
      "          0,   1,   6,   3,   5,  17,   6],\n",
      "       [  5, 190,   2,   3,   4,   1,   4,   9,   4,   1,   4,   1,   0,\n",
      "          5,   0,  10,   5,   3,   3,   0],\n",
      "       [  1,   2, 132,   3,   0,  61,   1,   1,   3,  15,   0,   1,   3,\n",
      "          4,   2,   1,  12,   3,   3,   1],\n",
      "       [  3,   2,   2, 192,   0,   2,   2,   4,   4,   2,   0,   0,   6,\n",
      "          1,   2,   2,   2,   4,   2,   3],\n",
      "       [  2,   0,   1,   1, 144,   3,  14,   6,   4,   1,  34,  13,   0,\n",
      "          0,   2,  24,   2,  12,   4,   1],\n",
      "       [  1,   2,  45,   6,   1,  85,   1,   1,  28,  22,   2,   0,   4,\n",
      "          9,   1,   0,   9,   2,   3,   0],\n",
      "       [  8,   1,   1,   2,  11,   0, 140,   4,   1,   1,   6,  13,   8,\n",
      "          0,   1,   4,   0,   1,  16,   1],\n",
      "       [  1,   1,   1,   1,   3,   1,   3, 134,   0,   1,   3,   0,   3,\n",
      "          0,   0,  19,   1,  12,   2,   2],\n",
      "       [  6,  11,  11,   7,   0,  28,   1,   0, 140,   6,   0,   6,   5,\n",
      "         34,   4,   2,  31,   1,   7,   6],\n",
      "       [  1,   0,   6,   0,   0,  20,   1,   0,   4, 182,   0,   0,   0,\n",
      "          2,   1,   1,   4,   0,   1,   1],\n",
      "       [  4,   2,   1,   3,  27,   2,  16,   8,   2,   1, 145,  19,   2,\n",
      "          0,   1,  18,   3,   8,   8,   0],\n",
      "       [  7,   2,   2,   5,  11,   3,  11,   8,   2,   3,  16, 130,   1,\n",
      "          3,   2,   8,   6,   6,   6,   6],\n",
      "       [  2,   2,   3,   7,   0,   2,  10,   7,   4,   4,   1,   6, 184,\n",
      "          0,   0,   4,   0,   7,   0,   3],\n",
      "       [  5,   8,   8,   5,   0,  13,   0,   0,  25,   1,   0,   6,   3,\n",
      "        171,   3,   0,   4,   1,   6,   3],\n",
      "       [  2,   1,   1,   2,   2,   1,   2,   6,   3,   3,   3,   9,   2,\n",
      "          5, 183,   5,   1,   5,   2,  23],\n",
      "       [  2,   3,   1,   1,  22,   2,   5,  16,   1,   1,  16,   5,   2,\n",
      "          2,   2, 126,   2,  30,   2,   1],\n",
      "       [  2,   1,   8,   6,   1,   6,   0,   1,  26,   4,   0,   4,   3,\n",
      "          7,   1,   1, 194,   0,   1,   3],\n",
      "       [  0,   2,   1,   4,   9,   1,  14,  29,   2,   1,   3,  13,   5,\n",
      "          0,   1,  18,   0, 148,   1,   2],\n",
      "       [ 22,   0,   2,   3,   1,   3,   8,   4,   4,   1,   1,  16,   5,\n",
      "          4,   3,   0,   0,   1, 182,   1],\n",
      "       [  5,   0,   1,   0,   1,   2,   4,   2,   0,   1,   1,   7,   6,\n",
      "          2,  21,   0,   2,   4,   3, 185]], dtype=int64)\n",
      "classification Report for Test Dataset\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.72      0.72       285\n",
      "          1       0.82      0.75      0.78       254\n",
      "          2       0.57      0.53      0.55       249\n",
      "          3       0.75      0.82      0.78       235\n",
      "          4       0.60      0.54      0.57       268\n",
      "          5       0.36      0.38      0.37       222\n",
      "          6       0.57      0.64      0.60       219\n",
      "          7       0.56      0.71      0.63       188\n",
      "          8       0.54      0.46      0.50       306\n",
      "          9       0.72      0.81      0.76       224\n",
      "         10       0.61      0.54      0.57       270\n",
      "         11       0.50      0.55      0.52       238\n",
      "         12       0.75      0.75      0.75       246\n",
      "         13       0.69      0.65      0.67       262\n",
      "         14       0.79      0.70      0.74       261\n",
      "         15       0.51      0.52      0.51       242\n",
      "         16       0.69      0.72      0.71       269\n",
      "         17       0.58      0.58      0.58       254\n",
      "         18       0.68      0.70      0.69       261\n",
      "         19       0.75      0.75      0.75       247\n",
      "\n",
      "avg / total       0.64      0.64      0.64      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from pprint import pprint\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "sklearn_model = MultinomialNB(alpha = 0.01)\n",
    "sklearn_model.fit(X_train_df.values, Y_train_df.values)\n",
    "et = time.time()\n",
    "print(\"Training Time:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "Y_train_pred = sklearn_model.predict(X_train_df.values)\n",
    "et = time.time()\n",
    "print(\"Prediction Time for Training Set:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "print(\"Confusion Matrix for Training Dataset\")\n",
    "pprint(confusion_matrix(Y_train_pred, Y_train_df.values))\n",
    "\n",
    "print(\"classification Report for Training Dataset\")\n",
    "print(classification_report(Y_train_pred, Y_train_df.values))\n",
    "\n",
    "import time\n",
    "st = time.time()\n",
    "Y_test_pred = sklearn_model.predict(X_test_df.values)\n",
    "et = time.time()\n",
    "print(\"Prediction Time for Test Set:\", round((et-st)*1000), \"millisecond\")\n",
    "\n",
    "print(\"Confusion Matrix for Test Dataset\")\n",
    "pprint(confusion_matrix(Y_test_pred, Y_test_df.values))\n",
    "\n",
    "print(\"classification Report for Test Dataset\")\n",
    "print(classification_report(Y_test_pred, Y_test_df.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of results obtained from own implementation and the inbuilt classifier in sklearn \n",
    "\n",
    "(referring to inbuilt classifier as MultinomialNB)\n",
    "\n",
    "1. With the same dataset and alpha parameter, MultinomialNB and my own implementation give exactly the same results.\n",
    "2. The speed of MultinomialNB is around 10 times, since its implemented with cython.\n",
    "3. Without removing headers, I got an F1 Score of 0.89, MultinomialNB performed likewise.\n",
    "4. Increasing the number of features boosts the score till a minimum frequency only"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
