{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Feedback\n",
    "Titanic dataset is one of the datasets available in sklearn.\n",
    "You are given:\n",
    "    1. A Training dataset csv file with X train and Y train data\n",
    "    2. A X test File and you have to predict and submit predictions for this file.\n",
    "Your task is to:\n",
    "    1. Use Logistic Regression and come with predictions.\n",
    "Read Instructions carefully -\n",
    "    1. Use Logistic Regression as a training algorithm and submit results predicted.\n",
    "    2. Files are in csv format.\n",
    "    3. Submit a csv file with only predictions for X test data. File should not have any headers and should only have one column i.e. predictions.\n",
    "    4. Your score is based on number of accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Dataset\n",
    "dataframe = pd.read_csv(\"training_titanic_x_y_train.csv\", delimiter = \",\")\n",
    "dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = dataframe.copy()\n",
    "sex = df['Sex'].values\n",
    "sex_int = []\n",
    "for s in sex :\n",
    "    sex_int.append(1 if s == 'male' else 0)\n",
    "df['Sex'] = sex_int\n",
    "df.drop('Name', axis = 1, inplace = True)\n",
    "df.drop('Ticket', axis = 1, inplace = True)\n",
    "df.drop('Cabin', axis = 1, inplace = True)\n",
    "\n",
    "embarked_counts = { i :(df['Embarked'] == i).sum() for i in set(df['Embarked'])}\n",
    "\n",
    "def embarked_int(s):\n",
    "    return embarked_counts[s]\n",
    "df['Embarked'] = [embarked_int(i) for i in df['Embarked']]\n",
    "#df.drop('Embarked', axis = 1, inplace = True)\n",
    "\n",
    "ages = df['Age'].fillna(0).values\n",
    "ages_nonzero = ages[np.nonzero(ages)]\n",
    "\n",
    "mean_age = np.array(ages_nonzero).mean()\n",
    "\n",
    "\n",
    "survived_female_ages = np.array(df['Survived'] * (1-df['Sex']) * ages )\n",
    "indices_sfa = np.nonzero(survived_female_ages)\n",
    "count_sfa = len(survived_female_ages[indices_sfa])\n",
    "sum_sfa = np.sum(survived_female_ages)\n",
    "mean_sfa = sum_sfa/count_sfa\n",
    "\n",
    "not_survived_female_ages = np.array((1 - df['Survived']) * (1-df['Sex']) * ages )\n",
    "indices_nsfa = np.nonzero(not_survived_female_ages)\n",
    "count_nsfa = len(not_survived_female_ages[indices_nsfa])\n",
    "sum_nsfa = np.sum(not_survived_female_ages)\n",
    "mean_nsfa = sum_nsfa/count_nsfa\n",
    "\n",
    "survived_male_ages = np.array(df['Survived'] * (df['Sex']) * ages )\n",
    "indices_sma = np.nonzero(survived_male_ages)\n",
    "\n",
    "count_sma = len(survived_male_ages[indices_sma])\n",
    "sum_sma = np.sum(survived_male_ages)\n",
    "mean_sma = sum_sma/count_sma\n",
    "\n",
    "not_survived_male_ages = np.array((1 - df['Survived']) * (df['Sex']) * ages )\n",
    "indices_nsma = np.nonzero(not_survived_male_ages)\n",
    "\n",
    "count_nsma = len(not_survived_male_ages[indices_nsma])\n",
    "sum_nsma = np.sum(not_survived_male_ages)\n",
    "mean_nsma = sum_nsma/count_nsma\n",
    "\n",
    "print(mean_sma, mean_sfa, mean_nsma, mean_nsfa)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(training_final_df.shape)\n",
    "#print(df.shape)\n",
    "values = np.empty((0,8))\n",
    "for row in df.values :\n",
    "    #print(row[2])\n",
    "    if np.isnan(row[2]) : \n",
    "        if row[1] == 1.0 : # male\n",
    "            if row[-1] == 1.0: # survived \n",
    "                row[2] = mean_sma\n",
    "            else:\n",
    "                row[2] = mean_nsma\n",
    "        else: # female\n",
    "            if row[-1] == 1: # survived\n",
    "                row[2] = mean_sfa\n",
    "            else:\n",
    "                row[2] = mean_nsfa\n",
    "    values = np.insert(values,0, row, axis = 0) \n",
    "    #training_final_df.append(row)\n",
    "training_final_df = pd.DataFrame(values, columns = df.columns)\n",
    "\n",
    "print(training_final_df.describe())\n",
    "#print(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X_train = training_final_df.values\n",
    "print(final_X_train.shape)\n",
    "X_train = training_final_df.drop('Survived', axis = 1).values\n",
    "Y_train = training_final_df['Survived'].values\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.fillna(mean_age, inplace = True)\n",
    "print(df)\n",
    "df.describe()\n",
    "\n",
    "X_df = df.drop('Survived', axis = 1)\n",
    "X_train = X_df.values\n",
    "Y_train = df['Survived'].values\n",
    "\n",
    "print(\"Shape of X_train \", X_train.shape)\n",
    "print(\"Shape of Y_train \", Y_train.shape)\n",
    "\n",
    "test_dataframe = pd.read_csv(\"test_titanic_x_test.csv\", delimiter = \",\")\n",
    "\n",
    "\n",
    "test_df = test_dataframe.copy()\n",
    "sex = test_df['Sex'].values\n",
    "sex_int = []\n",
    "for s in sex :\n",
    "    sex_int.append(1 if s == 'male' else 0)\n",
    "test_df['Sex'] = sex_int\n",
    "test_df.drop('Name', axis = 1, inplace = True)\n",
    "test_df.drop('Ticket', axis = 1, inplace = True)\n",
    "test_df.drop('Cabin', axis = 1, inplace = True)\n",
    "\n",
    "test_df['Embarked'] = [embarked_int(i) for i in test_df['Embarked']]\n",
    "\n",
    "#df.drop('Embarked', axis = 1, inplace = True)\n",
    "\n",
    "ages = test_df['Age'].fillna(0).values\n",
    "ages_nonzero = ages[np.nonzero(ages)]\n",
    "\n",
    "X_test = test_df.values\n",
    "\n",
    "print(\"Shape of X_test \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_fa = (mean_sfa * count_sfa + mean_nsfa * count_nsfa)/(count_nsfa + count_sfa)\n",
    "mean_ma = (mean_sma * count_sma + mean_nsma * count_nsma)/(count_nsma + count_sma)\n",
    "\n",
    "values = np.empty((0,7))\n",
    "for row in test_df.values :\n",
    "    #print(row[2])\n",
    "    if np.isnan(row[2]) : \n",
    "        if row[1] == 1.0 : # male\n",
    "            row[2] = mean_ma\n",
    "        else: # female\n",
    "            row[2] = mean_fa\n",
    "    values = np.insert(values,0, row, axis = 0) \n",
    "    #training_final_df.append(row)\n",
    "testing_final_df = pd.DataFrame(values, columns = test_df.columns)\n",
    "\n",
    "print(testing_final_df.describe())\n",
    "#print(values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = testing_final_df.values\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as pps\n",
    "\n",
    "def add_more_features (X_train, imp_cols_indices = []):\n",
    "    \n",
    "    X_train_df = pd.DataFrame(X_train)\n",
    "    num_f = len(X_train_df.columns)\n",
    "    col_names = X_train_df.columns\n",
    "    \n",
    "    if len(imp_cols_indices) == 0 :\n",
    "        imp_cols_indices = np.arange(num_f)\n",
    "    new_df = X_train_df.copy()\n",
    "    num_imp_cols = len(imp_cols_indices)\n",
    "    \n",
    "    pow = 3\n",
    "    \n",
    "    while pow < 10 :\n",
    "        for i1 in range(num_imp_cols) :\n",
    "            i = imp_cols_indices[i1]\n",
    "            new_df[ str(col_names[i]) + \"_pow_\" + str(pow) ] = X_train_df[i] ** pow\n",
    "        pow += 1\n",
    "    \n",
    "    for i1 in range(num_imp_cols) :\n",
    "        for j1 in range(i1, num_imp_cols):\n",
    "            i = imp_cols_indices[i1]\n",
    "            j = imp_cols_indices[j1]\n",
    "            new_df[ str(col_names[i]) + \"_\" + str(col_names[j])] = X_train_df[i] * X_train_df[j]\n",
    "            new_df[ str(col_names[i])*2 + \"_\" + str(col_names[j])] = X_train_df[i]**2 * X_train_df[j]\n",
    "            new_df[ str(col_names[i]) + \"_\" + str(col_names[j])*2 ] = X_train_df[i] * X_train_df[j]**2\n",
    "            new_df[ str(col_names[i])*2 + \"_\" + str(col_names[j])*2 ] = X_train_df[i]**2 * X_train_df[j]**2\n",
    "            \n",
    "            new_df[ str(col_names[i])*3 + \"_\" + str(col_names[j])] = X_train_df[i]**3 * X_train_df[j]\n",
    "            new_df[ str(col_names[i])*3 + \"_\" + str(col_names[j])*2] = X_train_df[i]**3 * X_train_df[j]**2\n",
    "            new_df[ str(col_names[i])*3 + \"_\" + str(col_names[j])*3 ] = X_train_df[i]**3 * X_train_df[j]**3\n",
    "            new_df[ str(col_names[i])*2 + \"_\" + str(col_names[j])*3 ] = X_train_df[i]**2 * X_train_df[j]**3\n",
    "            new_df[ str(col_names[i]) + \"_\" + str(col_names[j])*3 ] = X_train_df[i] * X_train_df[j]**3\n",
    "            \n",
    "            \n",
    "            \n",
    "    print(new_df.describe())\n",
    "    return new_df.values\n",
    "\n",
    "\n",
    "X_train_new = add_more_features(X_train)\n",
    "X_test_new = add_more_features(X_test)\n",
    "\n",
    "std_scaler = pps.StandardScaler()\n",
    "std_scaler.fit(X_train_new)\n",
    "\n",
    "X_train_scaled = std_scaler.transform(X_train_new)\n",
    "X_test_scaled = std_scaler.transform(X_test_new)\n",
    "\n",
    "import copy\n",
    "X_train_original = copy.deepcopy(X_train)\n",
    "X_test_original = copy.deepcopy(X_test)\n",
    "\n",
    "X_train = X_train_scaled\n",
    "X_test = X_test_scaled\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t_df = pd.DataFrame(X_train)\n",
    "X_t_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "model = GradientBoostingClassifier(loss = 'exponential', subsample = 1, n_estimators = 100, max_depth =  8, warm_start = True, max_leaf_nodes=None, min_samples_leaf=1)\n",
    "model.fit(X_train, Y_train)\n",
    "print(\"Training Score: \", model.score(X_train, Y_train))\n",
    "Y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-644ed6673bda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavetxt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_pred.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfmt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"%d\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.savetxt(\"y_pred.csv\", Y_pred.astype(int), fmt = \"%d\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
