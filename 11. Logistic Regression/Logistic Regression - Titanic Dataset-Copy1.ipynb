{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send Feedback\n",
    "Titanic dataset is one of the datasets available in sklearn.\n",
    "You are given:\n",
    "    1. A Training dataset csv file with X train and Y train data\n",
    "    2. A X test File and you have to predict and submit predictions for this file.\n",
    "Your task is to:\n",
    "    1. Use Logistic Regression and come with predictions.\n",
    "Read Instructions carefully -\n",
    "    1. Use Logistic Regression as a training algorithm and submit results predicted.\n",
    "    2. Files are in csv format.\n",
    "    3. Submit a csv file with only predictions for X test data. File should not have any headers and should only have one column i.e. predictions.\n",
    "    4. Your score is based on number of accurate predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23.8315868263\n",
      "     Pclass  Sex        Age  SibSp  Parch      Fare  Survived\n",
      "0         2    0  29.000000      1      0   26.0000         1\n",
      "1         3    1  23.831587      0      0    8.0500         0\n",
      "2         2    1  39.000000      0      0   26.0000         0\n",
      "3         3    0  29.000000      0      4   21.0750         0\n",
      "4         3    1  25.000000      0      0    7.0500         0\n",
      "5         3    1  34.500000      0      0    6.4375         0\n",
      "6         1    0  35.000000      1      0   53.1000         1\n",
      "7         3    1  23.000000      0      0    7.8958         0\n",
      "8         2    1  23.831587      0      0   13.0000         1\n",
      "9         3    1  50.000000      0      0    8.0500         0\n",
      "10        3    0  23.000000      0      0    7.5500         1\n",
      "11        3    1  23.831587      0      0    7.2292         0\n",
      "12        2    1  36.000000      0      0   13.0000         0\n",
      "13        3    1  23.831587      1      0   15.5000         0\n",
      "14        3    0  23.831587      0      0    7.7500         1\n",
      "15        3    1  28.000000      2      0    7.9250         0\n",
      "16        3    1  32.000000      0      0    7.8542         1\n",
      "17        3    1  42.000000      0      0    7.5500         0\n",
      "18        1    1  38.000000      0      1  153.4625         0\n",
      "19        3    0  23.831587      0      0    7.7500         1\n",
      "20        1    1  38.000000      0      0    0.0000         0\n",
      "21        3    0  23.831587      0      2   15.2458         0\n",
      "22        2    0  40.000000      0      0   15.7500         1\n",
      "23        3    1  24.500000      0      0    8.0500         0\n",
      "24        3    0  23.831587      0      0    7.2250         1\n",
      "25        3    0  23.831587      8      2   69.5500         0\n",
      "26        1    1  39.000000      0      0    0.0000         0\n",
      "27        1    1  22.000000      0      0  135.6333         0\n",
      "28        3    1  16.000000      0      0    7.7750         0\n",
      "29        2    1  30.000000      0      0   13.0000         0\n",
      "..      ...  ...        ...    ...    ...       ...       ...\n",
      "638       3    1  24.000000      2      0   24.1500         0\n",
      "639       2    0  22.000000      1      2   41.5792         1\n",
      "640       3    0  23.831587      3      1   25.4667         0\n",
      "641       3    1  32.000000      0      0    7.9250         1\n",
      "642       1    1  42.000000      0      0   26.2875         1\n",
      "643       3    1  17.000000      0      0    7.1250         0\n",
      "644       1    1  23.831587      0      0   25.9250         0\n",
      "645       2    1   0.830000      1      1   18.7500         1\n",
      "646       3    0   9.000000      2      2   34.3750         0\n",
      "647       1    1  58.000000      0      0   29.7000         0\n",
      "648       2    1  28.000000      0      1   33.0000         0\n",
      "649       3    1  26.000000      0      0    8.0500         0\n",
      "650       3    1  47.000000      0      0    9.0000         0\n",
      "651       3    1  23.831587      1      0   16.1000         0\n",
      "652       2    0  33.000000      1      2   27.7500         1\n",
      "653       3    0  47.000000      1      0   14.5000         0\n",
      "654       3    1  23.831587      0      0    7.8958         0\n",
      "655       1    1  42.000000      1      0   52.5542         1\n",
      "656       3    1  36.000000      0      0    7.8958         0\n",
      "657       3    1  38.000000      0      0    8.6625         0\n",
      "658       3    0  38.000000      1      5   31.3875         1\n",
      "659       3    1  23.831587      0      0    7.8292         0\n",
      "660       2    1   1.000000      2      1   39.0000         1\n",
      "661       1    0  23.831587      1      0   82.1708         1\n",
      "662       1    1  47.000000      0      0   34.0208         0\n",
      "663       2    0  17.000000      0      0   10.5000         1\n",
      "664       3    1  23.831587      0      0    7.7500         0\n",
      "665       3    1  32.000000      0      0   56.4958         1\n",
      "666       3    0  22.000000      0      0    9.8375         0\n",
      "667       3    0  23.831587      1      0   15.5000         1\n",
      "\n",
      "[668 rows x 7 columns]\n",
      "Shape of X_train  (668, 6)\n",
      "Shape of Y_train  (668,)\n",
      "23.7025560538\n",
      "     Pclass  Sex        Age  SibSp  Parch      Fare\n",
      "0         2    1   8.000000      1      1   36.7500\n",
      "1         1    0  49.000000      0      0   25.9292\n",
      "2         3    1  23.702556      0      0    7.7375\n",
      "3         2    0  24.000000      2      1   27.0000\n",
      "4         1    1  36.000000      0      0   26.2875\n",
      "5         1    1  71.000000      0      0   49.5042\n",
      "6         3    1  16.000000      0      0    9.5000\n",
      "7         3    1  23.702556      0      0    7.7250\n",
      "8         3    0  18.000000      0      0    7.7750\n",
      "9         3    1  23.702556      0      0    8.6625\n",
      "10        1    0  63.000000      1      0   77.9583\n",
      "11        3    1  23.702556      0      0    7.8958\n",
      "12        1    0  24.000000      0      0   83.1583\n",
      "13        3    0  23.000000      0      0    7.9250\n",
      "14        1    1  71.000000      0      0   34.6542\n",
      "15        2    1  21.000000      1      0   11.5000\n",
      "16        3    1  21.000000      0      0    8.4333\n",
      "17        3    1   4.000000      1      1   11.1333\n",
      "18        3    1  22.000000      0      0    7.5208\n",
      "19        3    0  18.000000      0      0    6.7500\n",
      "20        3    0  23.702556      1      0   24.1500\n",
      "21        3    1  32.000000      0      0    7.7500\n",
      "22        1    0  58.000000      0      0   26.5500\n",
      "23        2    0  24.000000      1      2   65.0000\n",
      "24        3    1  23.702556      0      0    7.2500\n",
      "25        1    1  23.702556      0      0   35.0000\n",
      "26        2    1  28.000000      0      0   10.5000\n",
      "27        1    1  42.000000      1      0   52.0000\n",
      "28        3    0   0.750000      2      1   19.2583\n",
      "29        2    0  50.000000      0      0   10.5000\n",
      "..      ...  ...        ...    ...    ...       ...\n",
      "193       3    1  23.702556      0      0    8.0500\n",
      "194       3    1  38.000000      0      0    7.8958\n",
      "195       3    0  26.000000      0      0    7.9250\n",
      "196       1    0  16.000000      0      1   57.9792\n",
      "197       3    0  37.000000      0      0    9.5875\n",
      "198       2    0  28.000000      1      0   26.0000\n",
      "199       1    0  33.000000      0      0   86.5000\n",
      "200       3    1  23.702556      0      0    7.7500\n",
      "201       1    1  32.000000      0      0   30.5000\n",
      "202       3    1  22.000000      0      0    7.2500\n",
      "203       1    1  47.000000      0      0   38.5000\n",
      "204       3    1  23.702556      0      0    7.7500\n",
      "205       3    1  23.702556      1      0   19.9667\n",
      "206       3    1  32.000000      0      0   56.4958\n",
      "207       3    1  26.000000      0      0    7.8958\n",
      "208       1    0  62.000000      0      0   80.0000\n",
      "209       3    0   9.000000      3      2   27.9000\n",
      "210       3    1  23.702556      2      0   21.6792\n",
      "211       3    0  22.000000      0      0    7.7750\n",
      "212       2    1  25.000000      0      0   13.0000\n",
      "213       1    1  55.000000      0      0   30.5000\n",
      "214       3    0  14.000000      0      0    7.8542\n",
      "215       2    0  23.702556      0      0   12.3500\n",
      "216       3    1  21.000000      0      0    8.6625\n",
      "217       3    1  23.702556      0      0    8.0500\n",
      "218       3    1  20.000000      1      0    7.9250\n",
      "219       1    1  45.000000      0      0   26.5500\n",
      "220       1    0  17.000000      1      0  108.9000\n",
      "221       3    1  43.000000      0      0    6.4500\n",
      "222       2    1  36.500000      0      2   26.0000\n",
      "\n",
      "[223 rows x 6 columns]\n",
      "Shape of X_test  (223, 6)\n"
     ]
    }
   ],
   "source": [
    "# Loading Dataset\n",
    "dataframe = pd.read_csv(\"training_titanic_x_y_train.csv\", delimiter = \",\")\n",
    "\n",
    "\n",
    "df = dataframe.copy()\n",
    "sex = df['Sex'].values\n",
    "sex_int = []\n",
    "for s in sex :\n",
    "    sex_int.append(1 if s == 'male' else 0)\n",
    "df['Sex'] = sex_int\n",
    "df.drop('Name', axis = 1, inplace = True)\n",
    "df.drop('Ticket', axis = 1, inplace = True)\n",
    "df.drop('Cabin', axis = 1, inplace = True)\n",
    "df.drop('Embarked', axis = 1, inplace = True)\n",
    "ages = df['Age'].fillna(0)\n",
    "mean_age = np.array(ages).mean()\n",
    "print(mean_age)\n",
    "df.fillna(mean_age, inplace = True)\n",
    "print(df)\n",
    "df.describe()\n",
    "\n",
    "X_df = df.drop('Survived', axis = 1)\n",
    "X_train = X_df.values\n",
    "Y_train = df['Survived'].values\n",
    "\n",
    "print(\"Shape of X_train \", X_train.shape)\n",
    "print(\"Shape of Y_train \", Y_train.shape)\n",
    "\n",
    "test_dataframe = pd.read_csv(\"test_titanic_x_test.csv\", delimiter = \",\")\n",
    "\n",
    "\n",
    "test_df = test_dataframe.copy()\n",
    "sex = test_df['Sex'].values\n",
    "sex_int = []\n",
    "for s in sex :\n",
    "    sex_int.append(1 if s == 'male' else 0)\n",
    "test_df['Sex'] = sex_int\n",
    "test_df.drop('Name', axis = 1, inplace = True)\n",
    "test_df.drop('Ticket', axis = 1, inplace = True)\n",
    "test_df.drop('Cabin', axis = 1, inplace = True)\n",
    "test_df.drop('Embarked', axis = 1, inplace = True)\n",
    "ages = test_df['Age'].fillna(0)\n",
    "mean_age = np.array(ages).mean()\n",
    "print(mean_age)\n",
    "test_df.fillna(mean_age, inplace = True)\n",
    "print(test_df)\n",
    "test_df.describe()\n",
    "\n",
    "X_test = test_df.values\n",
    "\n",
    "print(\"Shape of X_test \", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  Training Score :  0.980538922156\n",
      "1  Training Score :  0.980538922156\n",
      "2  Training Score :  0.980538922156\n",
      "3  Training Score :  0.980538922156\n",
      "4  Training Score :  0.980538922156\n",
      "5  Training Score :  0.980538922156\n",
      "6  Training Score :  0.980538922156\n",
      "7  Training Score :  0.980538922156\n",
      "8  Training Score :  0.980538922156\n",
      "9  Training Score :  0.980538922156\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(tol = 0.000001, solver = 'saga', max_iter = 10000000, C = 0.1, warm_start = True)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "#Y_pred = model.predict(X_test)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn import model_selection\n",
    "def train_n_models(X_train, Y_train, X_test):\n",
    "    n = 10\n",
    "    sub_Size = 1\n",
    "    Y_pred = np.zeros(len(X_test))\n",
    "    Y_train_pred = np.zeros(int(sub_Size * len(X_train)))\n",
    "    num_s = 0\n",
    "    for i in range(n):\n",
    "        X1, X2, Y1, Y2 = model_selection.train_test_split(X_train, Y_train, test_size = 1 - sub_Size)\n",
    "        #model = LogisticRegression(tol = 0.000001, solver = 'saga', max_iter = 10000000, C = 0.1, warm_start = True)\n",
    "        model = GradientBoostingClassifier(loss = 'exponential', n_estimators = 1000, subsample = 1,  warm_start = True)      \n",
    "        model.fit(X1, Y1)\n",
    "        #print(\"Training Score : \", model.score(X_train, Y_train))\n",
    "        score = model.score(X1, Y1)\n",
    "        if score > 0:   \n",
    "            print(num_s, \" Training Score : \", score)\n",
    "            Y_i_pred = model.predict(X_test)\n",
    "            Y_pred += Y_i_pred\n",
    "            Y_train_i_pred = model.predict(X1)\n",
    "            Y_train_pred += Y_train_i_pred\n",
    "            num_s += 1\n",
    "    Y_pred /= num_s\n",
    "    Y_train_pred /= num_s          \n",
    "    \n",
    "    #error = Y_train_pred - Y_pred\n",
    "    \n",
    "    pred = Y_pred.round()\n",
    "    train_pred = Y_train_pred.round()\n",
    "    \n",
    "    #print(Y_pred, pred)\n",
    "    return train_pred, pred\n",
    "\n",
    "Y_train_pred, Y_pred = train_n_models(X_train, Y_train, X_test)\n",
    "\n",
    "\n",
    "\n",
    "#print(\"Training Score : \", model.score(X_train, Y_train))\n",
    "\n",
    "#Training Score :  0.784431137725 \n",
    "#Training Score :  0.790419161677 (tol = 0.000001, solver = 'saga', max_iter = 10000000, C = 1, warm_start = True)\n",
    "# (tol = 0.000001, solver = 'saga', max_iter = 10000000, C = 0.5, warm_start = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.savetxt(\"y_pred.csv\", Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method BaseEstimator.get_params of LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=10000000, multi_class='ovr',\n",
       "          n_jobs=1, penalty='l2', random_state=None, solver='saga',\n",
       "          tol=1e-06, verbose=0, warm_start=True)>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[332  67]\n",
      " [220  49]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(Y_train, Y_train_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
